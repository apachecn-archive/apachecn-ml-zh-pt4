# 10.目标检测

![../images/489446_1_En_10_Chapter/489446_1_En_10_Figa_HTML.png](../images/489446_1_En_10_Chapter/489446_1_En_10_Figa_HTML.png)

## 介绍

可以想象，自动检测图像中的静态对象或来自恒定视频捕获源的对象有许多应用。以下只是其中的一小部分:

*改进的照片搜索功能*

我们都通过短语之类的东西来搜索照片。有时，这些短语可以用来从互联网上查找已经标记的照片。然而，有时什么都没有，搜索引擎使用图像搜索算法从视频帧或照片档案中找到它们，这些算法采用某种对象检测和分类。如果这些返回的图像对最终用户有用，它们会相应地标记上搜索短语，以便将来的查找变得更快。

*视频监控(实时物体检测)*

有了像 YOLO 及其变体这样的现代快速算法，现在在实时视频帧上运行对象检测变得非常容易和快速(更重要的是)。我鼓励你去看 YOLO 网站上的视频: [`https://pjreddie.com/darknet/yolov2/`](https://pjreddie.com/darknet/yolov2/) 。

*物体计数*

经常需要找出照片中存在的对象的近似计数(在百分比的容许损失/增加范围内)。一个例子是数人头数；这有助于在活动中自动估计人群密度，以找出受欢迎程度或衡量活动的社会成功。另一个例子可以是自动医疗诊断。物体计数的另一个例子是改善初学走路的孩子计数学习体验的过程。想象一张照片，照片上有一些瓶子，一个蹒跚学步的孩子被要求数瓶子。如果孩子给出的数字与模型中的数字相符，那么这个孩子就会得到一个分数和一个建议或暗示。这种自学能力可以很容易地建立，并且可以被个性化以更好地达到。

*照片的自动字幕*

想象一张照片，有多辆自行车，几辆火车，很多人；这张照片可以加上标题“在繁忙的车站”。

## 目标

ML.NET 提供从 ONNX 和 TensorFlow 运行预训练模型的能力，允许从照片/图像中检测对象。由于对象检测是一个计算量很大的训练模型的活动，你需要大量的数据和时间来训练一个模型。然而，使用预训练模型从图像中检测几个对象可能很简单。在本章中，你将看到如何使用 ONNX model zoo 中的 YOLO 来检测图像中的物体。我希望这一章能给你留下足够的灵感和知识来使用 ONNX 模型动物园的其他模型。

## YOLO 是如何运作的

YOLO 代表你只看一眼(YOLO)。该算法采用输入图像(称为“图像”，由 3 ✕ 416 ✕ 416 张量表示)。算法的输出是一个 125 ✕ 13 ✕ 13 维的张量，称为“网格”。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig1_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig1_HTML.jpg)

图 10-1

示出了 YOLO 如何将输入图像分割成 13 个✕ 13 单元

YOLO 将给定的图像分割成 13 个✕ 13(或 169 个单元)。每个单元格产生或必定产生五个边界框。每个边界框由 25 个变量表示。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig2_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig2_HTML.jpg)

图 10-2

(摘自微软的 ML.NET 文档)

*   `x`是边界框中心相对于与其相关的网格单元的 x 位置。

*   `y`是边界框中心相对于与其相关的网格单元的 y 位置。

*   `w`是边界框的宽度。

*   `h`是边界框的高度。

*   `o`是物体存在于包围盒内的置信度值，也称为*物体性*得分。

*   `p1-p20`是模型预测的 20 个类别中每个类别的概率。

边界框是在其中检测到对象的感兴趣区域。每个边界框获得 20 个值的概率分布，这些值代表每个类/类型的置信度得分。默认情况下，该算法会忽略置信度得分小于 0.3 或 30%的任何内容。被调用者(你作为 YOLO 的调用者)的工作是确定边界框和类型。

预测的边界框可能如下所示。边界框越宽，某个预定义对象在该区域的可信度就越高。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig3_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig3_HTML.jpg)

图 10-3

显示边界框

获得边界框细节后的下一步是通过某种方式将置信度得分(客观性得分)和概率分布得分粘合在一起，按照计算的得分对边界框进行分类。例如，下图显示，YOLO 算法几乎可以确定左下边界框的颜色为“黄色”，其中有物体“狗”(图 [10-4](#Fig4) )。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig4_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig4_HTML.jpg)

图 10-4

显示所有边界框

很明显，前三个边界框(具有最粗的边界)脱颖而出(图 [10-5](#Fig5) )。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig5_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig5_HTML.jpg)

图 10-5

展示了 YOLO 模型的最终结果

有 169 个单元，每个单元有 5 个边界框，所以总共有 845 个边界框。这些边界框中的大多数都有非常低的客观性分数(或者置信度分数，如果你愿意的话)。但是神经网络同时看到并预测了每个边界框的结果。这就是为什么名字叫 YOLO(你只看一次！).

## 正在移除重叠的框…

从前面的例子可以看出，预测中会有很多重叠的框。但显然，我们需要一种方法来抵消那些不太好的。去除重叠边界框的算法是“非最大抑制”(又名 NMS)。

正如他们所说，一张图片胜过一百个单词，所以这里是 NMS 对一堆重叠的边界框所做的。它消除了置信度较低的重叠包围盒。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig6_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig6_HTML.jpg)

图 10-6

NMS 对重叠边界框做了什么

### 非最大抑制算法步骤

***第一步***

首先，选择具有最高置信度得分的边界框，并将其添加到建议边界框的最终列表中。此框已从 YOLO 提供的建议清单中删除。

***第二步***

对于这个当前的边界框，用 YOLO 提出的所有其它边界框计算 IOU。并且如果所计算的 IOU 大于阈值，则需要从该组框中移除其他边界框。

***第三步***

挑选下一个具有最高置信度得分的边界框，并继续步骤 2，直到所有的边界框都被触摸或移除。最后，你将只剩下那些感兴趣的边界框。

### 两个边界框的 IOU 是什么？

IOU 是两个边界框的交集和并集的面积比。图 [10-7](#Fig7) 直观地显示了这一点。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig7_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig7_HTML.jpg)

图 10-7

直观显示交集和并集的比例

## NMS 虚拟代码...

这里，B 表示包围盒的集合，c 是置信度得分阈值，λ <sub>*n* ms</sub> 是重叠的阈值。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig8_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig8_HTML.jpg)

图 10-8

NMS 伪码

## 通过 model 消费微小的 YOLO V2 模型

使用 ML.NET 体验 YOLO 最简单的方法是从 GitHub 下载示例。最好的下载方式是克隆回购。

定位

```py
https://github.com/dotnet/machinelearning-samples.

```

通过 git 将其克隆为

```py
git clone https://github.com/dotnet/machinelearning-samples.git

```

一旦你把它放在磁盘上，进入`\machinelearning-samples\samples\csharp\end-to-end-apps\ObjectDetection-Onnx`文件夹，用 Visual Studio 2019 打开解决方案。

项目加载后，尝试构建它。请确保您连接到互联网，因为它将不得不恢复几个 NuGet 包。

一旦一切顺利运行，您应该会看到这样的解决方案浏览器(图 [10-9](#Fig9) )。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig9_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig9_HTML.jpg)

图 10-9

解决方案会是什么样子

注意，两个端到端应用程序(一个桌面和一个 web)依赖于`OnnxObjectDetection`项目。

如果您想要查看模型在实时设置上的执行情况，请选择 OnnxDetectionApp 作为启动项目。

下面是我实验的截图(图 [10-10](#Fig10) )。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig10_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig10_HTML.jpg)

图 10-10

物体检测的结果

在这里，我和一只斑点狗坐在我的办公桌前。模型正确地将我识别为人，将玩具狗识别为狗。

## 脱机试验图像

Tiny YOLOV2 要快得多(5 倍左右)。微小的 YOLOV2 达到了 244 FPS(每秒帧数)，而 YOLOV2 大约为 45 FPS。微小的 YOLOV2 通过牺牲一些精度来实现这一点。

这个实验展示了模型是如何错过狗头上的猫的。

## 永远记住，尺寸很重要…

要使用图像，请始终记住输入尺寸必须是 416 ✕ 416。因此，无论你想在什么图像上试用 YOLOV2 小模型，在 MS Paint 中打开它，并将尺寸更改为 416 ✕416.记得不要勾选“保持长宽比”。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig11_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig11_HTML.jpg)

图 10-11

设置输入尺寸

现在，选择`OnnxObjectDetectionWeb`作为启动项目。它会弹出一个页面，你可以在上面上传你的图片。一旦上传完成，模型就会接管并绘制边界框和置信度得分。对于我的猫和狗的图片，它完全错过了狗头顶上的猫。

![../images/489446_1_En_10_Chapter/489446_1_En_10_Fig12_HTML.jpg](../images/489446_1_En_10_Chapter/489446_1_En_10_Fig12_HTML.jpg)

图 10-12

上传图像用于对象检测的示例

## 尝试不同的模型…

如果您想使用不同的模型，您可以在 ONNX 模型动物园( [`https://github.com/onnx/models`](https://github.com/onnx/models) )中找到模型，并记住替换 ONNXModels 文件夹中的模型。

## 摘要

ML.NET 提供了使用预训练 ONNX 和 TensorFlow 模型的功能，因此您可以轻松地为许多不同类型的机器学习活动试验几种深度学习模型。我希望，在未来，ML.NET 也将提供训练模型的能力，并将其改造成 ONNX 模型。