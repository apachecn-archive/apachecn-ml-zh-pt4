# 13.解释文本分类模型

文本文档可以用几个抽象的概念来描述，比如语义类别、写作风格或情感。机器学习(ML)模型已经被训练成自动将文档映射到这些抽象概念，允许注释非常大的文本集合，比人类一生所能处理的还要多。除了非常准确地预测文本的类别之外，还非常需要理解分类过程是如何以及为什么发生的。

在自然语言处理模型领域，特征的维数总是很大，因此使用特征重要性来解释模型变得更加复杂。像莱姆和 SHAP 这样的技术向最终用户和数据科学从业者解释了 NLP 模型是如何工作和做出决策的。本章用几个例子来说明我们如何利用上述两种方法来解释建立在文本数据上的模型。

首先，让我们快速构建一个文本分类模型。我们不讨论这个模型，因为它超出了本章的范围。我们构建模型，然后快速地生成解释来解释模型决策。

我们使用堆栈溢出标签分类数据集。以下是对数据集的简要描述。

*   问题 ID

*   编成日期

*   结束日期(如果适用)

*   得分

*   所有者用户 ID

*   回答的数量

*   标签

该数据集是从堆栈溢出数据库中提取的。它包含 12，583，347 个未删除问题和 3，654，954 个已删除问题。

这是堆栈交换数据转储中的所有公共数据，这些数据更加全面(包括问题和答案文本)，并且需要更多的计算开销来下载和处理。这个数据集被设计成易于读入和开始分析。

## 数据预处理、特征工程和数据的逻辑回归模型

下面是构建这个模型所需的不同导入。

```
import pandas as pd
import numpy as np
import sklearn
import sklearn.ensemble
import sklearn.metrics
from sklearn.utils import shuffle
from __future__ import print_function
from io import StringIO
import re
from bs4 import BeautifulSoup
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import lime
from lime import lime_text
from lime.lime_text import LimeTextExplainer
from sklearn.pipeline import make_pipeline

```

现在，读取数据集，并执行模型特定所需的一些数据修改。您可以按照相同的代码在您自己的系统或环境中重现结果。

```
df = pd.read_csv('stack-overflow-data.csv')

df = df[pd.notnull(df['tags'])]
df = df.sample(frac=0.5, random_state=99).reset_index(drop=True)
df = shuffle(df, random_state=22)
df = df.reset_index(drop=True)
df['class_label'] = df['tags'].factorize()[0]
class_label_df = df[['tags', 'class_label']].drop_duplicates().sort_values('class_label')
label_to_id = dict(class_label_df.values)
id_to_label = dict(class_label_df[['class_label', 'tags']].values)

REPLACE_BY_SPACE_RE = re.compile('[/(){}\[\]\|@,;]')
BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')
# STOPWORDS = set(stopwords.words('english'))

def clean_text(text):
         """
             text: a string

             return: modified initial string
         """
         text = BeautifulSoup(text, "lxml").text # HTML decoding. BeautifulSoup's text attribute return a string stripped of any HTML tags and metadata.
         text = text.lower() # lowercase text
         text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.
         text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing.
     #    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text
         return text

df['post'] = df['post'].apply(clean_text)

list_corpus = df["post"].tolist()
list_labels = df["class_label"].tolist()
X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.2, random_state=40)

vectorizer = CountVectorizer(analyzer='word',token_pattern=r'\w{1,}', ngram_range=(1, 3), stop_words = 'english', binary=True)
train_vectors = vectorizer.fit_transform(X_train)
test_vectors = vectorizer.transform(X_test)

logreg = LogisticRegression(n_jobs=1, C=1e5)
logreg.fit(train_vectors, y_train)
pred = logreg.predict(test_vectors)
accuracy = accuracy_score(y_test, pred)
precision = precision_score(y_test, pred, average='weighted')
recall = recall_score(y_test, pred, average='weighted')
f1 = f1_score(y_test, pred, average='weighted')

```

## 用 LIME 解释文本预测

这一节解释了一个文本模型，它使用了一种叫做 LIME 的流行技术，您在第 [9](09.html) 章中学习了这种技术。它是一个用于黑盒模型的可解释性代理模型(与模型无关)。它为单个观测预测(局部)提供了可解释性。概括地说，让我们看看石灰是如何工作的。

1.  选择单项预测。

2.  LIME 在这种情况下创建数据的排列，并收集黑盒模型结果。

3.  然后，根据新样本与原始预测数据的匹配程度，对新样本进行加权。

4.  一个新的、不太复杂的、可解释的模型被训练在使用附加到每个变量的权重创建的数据变量上。

5.  这个局部可解释模型可以解释这个预测。

使用 LIME，您可以创建如下可视化效果，帮助您理解文本中的哪些单词对模型的最终预测影响最大。在图 [13-1](#Fig1) 中，*遇难*、*坠机*、*直升机*这几个词都贡献了 0.89 的最终预测得分，使得该模型对其灾害等级预测相当有信心。

![../images/511613_1_En_13_Chapter/511613_1_En_13_Fig1_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Fig1_HTML.jpg)

图 13-1

对 LIME 如何处理文本数据的描述

既然您已经理解了 LIME 如何处理文本数据，那么让我们继续看一下可以帮助实现 LIME 的代码片段。

```
c = make_pipeline(vectorizer, logreg)
class_names=list(df.tags.unique())
explainer = LimeTextExplainer(class_names=class_names)

idx = 1877
exp = explainer.explain_instance(X_test[idx], c.predict_proba, num_features=6, labels=[4, 8])
print('Document id: %d' % idx)
print('Predicted class =', class_names[logreg.predict(test_vectors[idx]).reshape(1, 1)[0,0]])
print('True class: %s' % class_names[y_test[idx]])

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Figa_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Figa_HTML.jpg)

我们在测试集中随机选择一个文档，这个文档恰好被标记为 SQL，模型预测它也是 SQL。使用这个文档，我们为标签 SQL)和标签 Python)生成解释。

```
print ('Explanation for class %s' % class_names[4])
print ('\n'.join(map(str, exp.as_list(label=4))))

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Figb_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Figb_HTML.jpg)

```
print ('Explanation 

for class %s' % class_names[8])
print ('\n'.join(map(str, exp.as_list(label=8))))

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Figc_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Figc_HTML.jpg)

本文档对标签 *sql 有最高的解释。*我们还注意到，正负符号是关于特定的标签；例如， *sql* 这个词对 *sql* 类是正的，而对 *python* 类是负的，反之亦然。

我们将为这个文档的前两个类生成标签。

```
exp = explainer.explain_instance(X_test[idx], c.predict_proba, num_features=6, top_labels=2)
print(exp.available_labels())

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Figd_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Figd_HTML.jpg)

它给出了 *sql* 和 *python。*

```
exp.show_in_notebook(text=False)

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Fig2_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Fig2_HTML.jpg)

图 13-2

模型的石灰输出

下面解释图 [13-2](#Fig2) 中的可视化。

*   对于这个文档，单词 *sql* 对于 ***sql*** 类具有最高的正面得分。

*   我们的模型预测这个文档应该以 100%的概率被标记为 ***sql*** 。

*   如果我们从文档中删除单词 *sql* ，我们期望模型以 100%–65% = 35%的概率预测 ***sql*** 标签。

*   另一方面，单词 *sql* 对于 ***python*** 类来说是负的，模型已经了解到单词 *range* 对于 ***python*** 类来说有一个小的正分数。

我们可能想要放大并研究对 ***sql*** 类的解释，以及文档本身。

```
exp.show_in_notebook(text=y_test[idx], labels=(4,))

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Fig3_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Fig3_HTML.jpg)

图 13-3

石灰产量

当使用石灰进行 NLP 时，主要缺点是它不稳定。围绕同一本地数据的不同采样可能导致非常不同的解释结果，而 LIME 仅提供本地可解释性。此外，由于 LIME 在感兴趣的实例周围创建了线性局部模型，所以它假设局部实例可以被线性地解释，但情况并非总是如此。第一个问题在使用石灰进行可解释性方面可能相当令人气馁，因为很难相信一个模型在对变异变化进行采样时会对同一解释产生不同的结果。

然而，就局部可解释性而言，大多数特征权重在我们自己对灾害相关词的理解中是有意义的。LIME explainer 本身的运行时间很短，这意味着如果需要的话，很容易在很短的时间内为不同的局部预测产生许多解释。

### 用 SHAP 解释文本预测

你在第九章学习了 SHAP。现在让我们看看如何使用 SHAP 生成对文本数据的解释。为了理解模型分类，您可以使用 SHAP 创建几种不同类型的可视化效果。

使用 SHAP 可返回模型中每个要素的属性值，表明该要素对预测的贡献大小。对于结构化数据来说，这非常简单，但是对于文本来说，它是如何工作的呢？在单词包模型中(下面的示例中提供了示例实现)，SHAP 将词汇表中的每个单词视为一个单独的特征。然后，我们可以将属性值映射到词汇表中的索引，以查看对模型预测贡献最大(和最小)的单词。在下一节中，我们将创建一个 SHAP 解释器对象。有几种类型的解释者。我们使用 DeepExplainer，因为我们有一个深度模型。我们通过向它传递模型和训练数据的子集来实例化它。

以下是必要的导入。

```
from sklearn.preprocessing import MultiLabelBinarizer
import tensorflow as tf
from tensorflow.keras.preprocessing import text
import keras.backend.tensorflow_backend as K
K.set_session
import shap

tags_split = [tags.split(',') for tags in df['tags'].values]
tag_encoder = MultiLabelBinarizer()
tags_encoded = tag_encoder.fit_transform(tags_split)
num_tags = len(tags_encoded[0])
train_size = int(len(df) * .8)

y_train = tags_encoded[: train_size]
y_test = tags_encoded[train_size:]

class TextPreprocessor(object):
    def __init__(self, vocab_size):
        self._vocab_size = vocab_size
        self._tokenizer = None
    def create_tokenizer(self, text_list):
        tokenizer = text.Tokenizer(num_words = self._vocab_size)
        tokenizer.fit_on_texts(text_list)
        self._tokenizer = tokenizer
    def transform_text(self, text_list):
        text_matrix = self._tokenizer.texts_to_matrix(text_list)
        return text_matrix

VOCAB_SIZE = 500
train_post = df['post'].values[: train_size]
test_post = df['post'].values[train_size: ]
processor = TextPreprocessor(VOCAB_SIZE)
processor.create_tokenizer(train_post)
X_train = processor.transform_text(train_post)
X_test = processor.transform_text(test_post)

def create_model(vocab_size, num_tags):
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Dense(50, input_shape = (VOCAB_SIZE,), activation='relu'))
    model.add(tf.keras.layers.Dense(25, activation='relu'))
    model.add(tf.keras.layers.Dense(num_tags, activation='sigmoid'))
    model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])
    return model
model = create_model(VOCAB_SIZE, num_tags)
model.fit(X_train, y_train, epochs = 2, batch_size=128, validation_split=0.1)
print('Eval loss/accuracy:{}'.format(model.evaluate(X_test, y_test, batch_size = 128)))

```

在模型被训练之后，我们使用前 200 个训练文档作为我们的背景数据集来集成和创建 SHAP 解释器对象。

*   我们在测试集的子集上得到个体预测的属性值。

*   将索引转换为单词。

*   使用 SHAP 的 summary_plot 方法显示影响模型预测的主要特征。

```
attrib_data = X_train[:200]
explainer = shap.DeepExplainer(model, attrib_data)
num_explanations = 20
shap_vals = explainer.shap_values(X_test[:num_explanations])words = processor._tokenizer.word_index
word_lookup = list()
for i in words.keys():
  word_lookup.append(i)word_lookup = [''] + word_lookup
shap.summary_plot(shap_vals, feature_names=word_lookup, class_names=tag_encoder.classes_)

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Fig4_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Fig4_HTML.jpg)

图 13-4

文本分类模型的 SHAP 输出

*   单词 *want* 是模型中使用的最大信号词，对 ***jquery*** 类预测贡献最大。

*   单词 *php* 是模型中使用的第四大信号单词，对 ***php*** 类贡献最大。

*   另一方面，单词 *php* 很可能对另一个类产生负面信号，因为它不太可能在 ***python*** 文档中出现 *php* 。

这就是我们如何用 SHAP 来解释文本模型。在示例中，我们突出显示了模型中最重要的单词。

### 用句子高亮解释文本模型

句子强调包括根据单词在最终预测中的重要性给每个单词打分。在形式上，句子突出显示(SH)被建模为向量 s，该向量解释 x 上黑盒 b 的分类 y = b(x)。s 的维数是我们想要解释的句子 x 中存在的单词，si 值是单词 *i* 的显著性值。si 的值越大，该词的重要性就越大。正值表示对 y 的贡献为正，而负值表示该单词的贡献为负。

ELI5 是一个 Python 库，允许使用统一的 API 可视化和调试各种机器学习模型。它内置了对几种 ML 框架的支持，并提供了一种解释黑盒模型的方法。

我们正在使用堆栈溢出数据集来解释 ELI5 如何处理文本数据。这个数据集包含文章和文章的相应标签。

图 [13-5](#Fig5) 显示了数据集。

![../images/511613_1_En_13_Chapter/511613_1_En_13_Fig5_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Fig5_HTML.jpg)

图 13-5

文本建模的示例数据

这是一个平衡的数据集，因此非常适合我们理解的目的。

首先，使用一个简单的 scikit-learn 管道来构建一个文本分类器，我们将在后面进行解释。这个管道使用一个简单的计数矢量器和逻辑回归。

```
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegressionCV
from sklearn.pipeline import make_pipeline# Creating train-test Split
X = sodata[['post']]
y = sodata[['tags']]X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)# fitting the classifier
vec = CountVectorizer()
clf = LogisticRegressionCV()
pipe = make_pipeline(vec, clf)
pipe.fit(X_train.post, y_train.tags)

```

以下是结果(另见图 [13-6](#Fig6) )。

```
from sklearn import metricsdef print_report(pipe):
    y_actuals = y_test['tags']
    y_preds = pipe.predict(X_test['post'])
    report = metrics.classification_report(y_actuals, y_preds)
    print(report)
    print("accuracy: {:0.3f}".format(metrics.accuracy_score(y_actuals, y_preds)))print_report(pipe)

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Fig6_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Fig6_HTML.jpg)

图 13-6

模型的输出

图 [13-6](#Fig6) 是一个简单的逻辑回归模型，表现良好。您可以使用下面的函数检查它的重量。

```
for i, tag in enumerate(clf.classes_):
    coefficients = clf.coef_[i]
    weights = list(zip(vec.get_feature_names(),coefficients))
    print('Tag:',tag)
    print('Most Positive Coefficients:')
    print(sorted(weights,key=lambda x: -x[1])[:10])
    print('Most Negative Coefficients:')
    print(sorted(weights,key=lambda x: x[1])[:10])
    print("------------------------")-------------------------------------

OUTPUT:
------------------------------------------------------------Tag: python
Most Positive Coefficients:
[('python', 6.314761719932758), ('def', 2.288467823831321), ('import', 1.4032539284357077), ('dict', 1.1915110448370732), ('ordered', 1.1558015932799253), ('print', 1.1219958415166653), ('tuples', 1.053837204818975), ('elif', 0.9642251085198578), ('typeerror', 0.9595246314353266), ('tuple', 0.881802590839166)]
Most Negative Coefficients:
[('java', -1.8496383139251245), ('php', -1.4335540858871623), ('javascript', -1.3374796382615586), ('net', -1.2542682749949605), ('printf', -1.2014123042575882), ('objective', -1.1635960146614717), ('void', -1.1433460304246827), ('var', -1.059642972412936), ('end', -1.0498078813349798), ('public', -1.0134828865993966)]
--------------------------------------
Tag: ruby-on-rails
Most Positive Coefficients:
[('rails', 6.364037640161158), ('ror', 1.804826792986176), ('activerecord', 1.6892552000017307), ('ruby', 1.41428459023012), ('erb', 1.3927336940889532), ('end', 1.3650227017877463), ('rb', 1.2280121863441906), ('gem', 1.1988196865523322), ('render', 1.1035255831838242), ('model', 1.0813278895692746)]
Most Negative Coefficients:
[('net', -1.5818801311532575), ('php', -1.3483618692617583), ('python', -1.201167422237274), ('mysql', -1.187479885113293), ('objective', -1.1727511956332588), ('sql', -1.1418573958542007), ('messageform', -1.0551060751109618), ('asp', -1.0342831159678236), ('ios', -1.0319120624686084), ('iphone', -0.9400116321217807)]
--------------------------------------

```

这一切都很好。这些系数是有意义的，我们可以利用这些信息改进模型。但是这有很多代码。ELI5 使这个练习变得简单。您使用以下命令(参见图 [13-7](#Fig7) 中的输出)。

```
import eli5
eli5.show_weights(clf, vec=vec, top=20)

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Fig7_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Fig7_HTML.jpg)

图 13-7

解释模型的 ELI5 输出

Python 的权重值与我们从手动编写的函数中获得的值相同。探索它会更加美丽和有益健康。但这只是冰山一角。ELI5 还可以调试模型。现在让我们找出为什么一个特定的例子被错误分类。我们使用的例子最初来自 Python 类，但被误归类为 Java(见图 [13-8](#Fig8) )。

```
y_preds = pipe.predict(sodata['post'])sodata['predicted_label'] = y_predsmisclassified_examples = sodata[(sodata['tags']!=sodata['predicted_label'])&(sodata['tags']=='python')&(sodata['predicted_label']=='java')]eli5.show_prediction(clf, misclassified_examples['post'].values[1], vec=vec)

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Fig8_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Fig8_HTML.jpg)

图 13-8

抽样输出

图 [13-8](#Fig8) 中，分类器低概率预测 Java。您可以检查示例中发生的许多事情来改进模型。以下是一些例子。

*   分类器考虑了很多数字(不好)，这让我们得出了清理数字的结论——或者用 DateTime 标记替换 DateTime 对象。

*   对于 Java 来说，字典的权重为负，而单词 dictionary 的权重为正。所以也许词干也有帮助。

*   像

    ```
     这样的词影响了量词。清洗的时候要把这些字去掉。
    ```

*   为什么单词*日期*会影响结果？一些值得思考的事情。

我们可以看看更多的例子来获得更多这样的想法。让我们为这个简单的任务创建一个深度模型。这一切都很好，但是如果我们的模型不能像 LSTM 那样为个体特征提供权重呢？在这些模型中，可解释性扮演了非常重要的角色。

为了理解如何做到这一点，我们首先在数据上创建一个 TextCNN 模型。从我们的角度来看，当我们有一个经过训练的黑盒模型对象时，事情就变得有趣了。ELI5 提供了 eli5.lime.TextExplainer 调试我们的预测，以检查文档中哪些内容是重要的，从而做出预测决策。

为了使用 TextExplainer 实例，我们向 fit()方法传递一个要解释的文档和一个黑盒分类器(一个返回概率的预测函数)。根据文档，预测函数应该如下所示。

*预测(可调用)——黑盒分类流水线。* predict *应该是一个函数，它接受一个字符串(文档)列表，并返回一个具有概率值的形状矩阵(n_samples，n _ classes)——每个文档一行，每个输出标签一列。*

要使用 ELI5，我们需要定义自己的函数，该函数将字符串(文档)列表作为输入，并返回一个形状矩阵(n_samples，n_classes) *。你可以看到我们如何先预处理，然后预测。*

```
def predict_complex(docs):
# preprocess the docs as required by our model
val_X = tokenizer.texts_to_sequences(docs)
val_X = pad_sequences(val_X, maxlen=maxlen)
y_preds = model.predict([val_X], batch_size=1024, verbose=0)
return y_preds

```

下面展示了如何使用 TextExplainer(见图 [13-9](#Fig9) )。在我们的简单分类器中使用与之前相同的错误分类示例。

```
import eli5
from eli5.lime import TextExplainerte = TextExplainer(random_state=2019)
te.fit(sodata['post'].values[0], predict_complex)
te.show_prediction(target_names=list(encoder.classes_))

```

![../images/511613_1_En_13_Chapter/511613_1_En_13_Fig9_HTML.jpg](../images/511613_1_En_13_Chapter/511613_1_En_13_Fig9_HTML.jpg)

图 13-9

使用 TextExplainer 输出

你可以看到关键字 dict 和 list 的出现正在影响我们的分类器的决策。在这个例子中，TextExplainer 通过删除一些单词来生成许多与文档相似的文本，然后训练一个白盒分类器，该白盒分类器预测黑盒分类器的输出，而不是真正的标签。我们看到的解释是针对这个白盒分类器的。 [`www.kaggle.com/mlwhiz/interpreting-text-classification-models-with-eli5`](http://www.kaggle.com/mlwhiz/interpreting-text-classification-models-with-eli5) 处的代码参考笔记本。

## 摘要

我们在这一章中没有讨论任何理论，因为大多数文本分类模型可以用像莱姆、SHAP 和 ELI5 这样的技术来解释。这些方法在前面的章节中已经介绍过了。通过这一章，我们希望你对文本数据的可解释性有所了解。