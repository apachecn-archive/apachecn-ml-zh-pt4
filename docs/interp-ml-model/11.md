# 11.详述反事实方法

前两章讨论了特征重要性方法和基于规则的方法。尽管基于规则的方法使人类利益相关者的生活变得更加容易，但是在模型解释中仍有一些空白可以填补。特征重要性方法和基于规则的方法的输出对于模型都是好的。这些方法有助于确定分类模型场景中特定类的行为。反事实解释是描述性信息之上的一个步骤，提供了使利用模型结果有意义的行动。本章讨论了反事实提供的行为，以及如何通过实现反事实解释从模型解释中获得更多的价值。我们希望你记住单词*可操作的*与反事实解释相关。反事实的输出可以帮助从模型决策的输出中得出有意义的行动，这比只有模型决策的描述性解释要好得多。

## 反事实的解释

一个反事实的解释以这样的形式描述了一个因果关系:“如果 X 没有发生，Y 也不会发生。”比如，“如果我没有喝一口这种热咖啡，我就不会烫到舌头。”事件 Y 是我烫了舌头；因为 X 是我喝了一杯热咖啡。反事实要求想象一个与观察到的事实相矛盾的假设现实(例如，一个没有热咖啡的世界)；因此，名字*反事实*。与其他动物相比，反事实思考的能力使人类如此聪明。

在可解释的机器学习中，反事实解释解释了个体实例的预测。“事件”是实例的预测结果。“原因”是输入到模型中并“导致”某个预测的该实例的特征值。

即使输入和预测结果之间的关系可能不是因果关系，我们也可以将模型的输入视为预测的原因。

为了模拟机器学习模型预测的反事实，我们在进行预测之前简单地改变实例的特征值，并且我们分析预测如何改变。我们感兴趣的是预测以相关方式变化的场景，比如预测类别的翻转(例如，接受或拒绝信贷申请)，或者预测达到某个阈值(例如，患癌症的概率达到 10%)。预测的反事实解释描述了将预测变为预定义输出的特征值的最小变化。

有模型不可知和模型特定的反事实解释方法。这一章主要关注模型无关的方法，这些方法只处理模型的输入和输出(而不是特定模型的内部结构)。

与原型不同，反事实不必是来自训练数据的实际实例，而可以是特征值的新组合。

在讨论如何创建反事实之前，让我们讨论一些用例。

## 用例 1:银行软件

在第一个例子中，Shankar 申请贷款，但被(机器学习驱动的)银行软件拒绝了。他想知道为什么他的申请被拒绝，以及他如何提高获得贷款的机会。为什么的问题可以表述为一个反事实:特征(收入、信用卡数量、年龄等)的最小变化是什么？)这会将预测从拒绝更改为批准？一个可能的答案是:如果 Shankar 每年多赚 10，000 美元，他将获得贷款。或者，如果 Shankar 有更少的信用卡，并且在五年前没有拖欠贷款，他将获得贷款。Shankar 永远不会知道拒绝的原因，因为银行对透明度不感兴趣，但那是另一回事了。

## 用例 2:持续的结果

第二个例子解释了一个用反事实解释预测连续结果的模型。Garima 希望出租她的公寓，但她不确定要收取多少费用，所以她训练了一个机器学习模型来预测租金。当然，由于加里玛是一名数据科学家，这就是她解决问题的方式。在输入了所有关于大小、位置、是否允许养宠物等细节后，模特告诉她可以收费 900 美元。她期望 1000 美元或更多，但她相信她的模型，并决定发挥公寓的功能价值，看看她如何才能提高公寓的价值。她发现，如果公寓再大 15 m <sup>2</sup> 的话，租金可以超过 1000 美元。有趣但不可操作的知识，因为她不能扩大她的公寓。最后，在她的控制下只调整特征值(内置厨房——是/否，允许养宠物——是/否，地板类型，等等。)，她发现如果允许养宠物并安装隔热性能更好的窗户，她可以收取 1000 美元。加里玛凭直觉用反事实来改变结果。

## 反事实解释一览

反事实是对人类友好的解释，因为它们通常专注于少量的特征变化。每一个反事实都讲述了一个不同的“故事”,讲述了一个特定的结果是如何达成的。一个反事实可能会说改变特征 A。另一个反事实可能会说保持 A 不变，但改变特征 B，这是一个矛盾。这个多重事实的问题可以通过报告所有反事实的解释或者通过制定标准来评估反事实并选择最好的一个来解决。

说到标准，我们如何定义一个好的反事实解释？首先，反事实解释的使用者定义了一个实例的预测中的相关变化(=替代现实)。

一个显而易见的首要要求是，反事实实例产生的预定义预测要尽可能接近。用预先定义的预测并不总是可能找到反事实的。例如，在具有两个类(稀有类和频繁类)的分类设置中，模型可能总是将实例分类为频繁类。更改特征值以使预测的标注从频繁类切换到罕见类可能是不可能的。因此，我们希望放宽对反事实的预测必须与预先定义的结果完全匹配的要求。在分类示例中，我们可以寻找一个反事实，其中稀有类的预测概率增加到 10%，而不是当前的 2%。使预测概率从 2%变化到 10%(或接近 10%)的最小特征变化是什么？

另一个质量标准是，一个反事实在特征值方面应该尽可能地与实例相似。两个实例之间的距离可以测量，例如，如果我们同时具有离散和连续特征，则可以使用曼哈顿距离或高尔距离。反事实不仅应该接近原始实例，而且应该尽可能少地改变特征。我们可以简单地计算变化特征的数量，来衡量反事实的解释在这个度量中有多好。

第三，经常希望产生多种不同的反事实解释，以便决策主体获得产生不同结果的多种可行方法。例如，继续贷款的例子，一个反事实的解释可能是只有双倍的收入才能获得贷款。相反，另一个反事实可能会建议搬到附近的城市，增加少量收入以获得贷款。可以指出的是，虽然第一个反事实对某些人来说是可能的，但后者对某些人来说可能更具可诉性。因此，除了为决策主体提供不同的方式来获得期望的结果，多样性还使“多样化”的个人能够改变对他们来说方便的特征。

最后一个要求是反事实实例应该有可能的特征值。如果公寓的面积为负，或者房间数设置为 200，那么为租金示例生成反事实的解释是没有意义的。当根据数据的联合分布可能出现反事实时更好；比如一套 20 米 <sup>2</sup> 的公寓，有十个房间，不应该算是反事实的解释。理想情况下，如果增加平米数，也要提出房间数。

下一节着眼于如何使用简单的理论产生反事实的解释。

## 产生反事实的解释

产生反事实解释的一个简单而天真的方法是通过试错法进行搜索。这种方法包括随机改变感兴趣的实例的特征值，并在预测到期望的输出时停止。比如安娜试图找到她的公寓的一个版本来收取更多的租金。但是有比试错法更好的方法。首先，我们根据上述标准定义一个损失函数。这种损失将兴趣实例、反事实和期望(反事实)结果作为输入。然后，我们可以使用优化算法找到使这种损失最小化的反事实解释。许多方法都以这种方式进行，但在损失函数的定义和优化方法上有所不同。

为了生成反事实，建议尽量减少以下损失。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figa_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figa_HTML.jpg)

让我们看看公式的每个组成部分。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figb_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figb_HTML.jpg)

第一项是反事实的模型预测 *x* 和期望结果 *y* 之间的平方距离，用户必须提前定义。第二项是待解释的实例 *x* 和反事实 *x* 之间的距离 *d* 。损失测量反事实的预测结果离预定义结果有多远，以及反事实离感兴趣的实例有多远。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figc_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figc_HTML.jpg)

距离函数 *d* 被定义为用每个特征的反向中值绝对偏差(MAD)加权的曼哈顿距离。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figd_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figd_HTML.jpg)

总距离是所有 p 个特征间距离的总和，即实例 *x* 和反事实 *x* 之间特征值的绝对差。基于特征的距离由数据集上特征 *j* 的中值绝对偏差的倒数来缩放，定义如下。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Fige_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Fige_HTML.jpg)

向量的中值是一半向量值较大而另一半较小时的值。MAD 相当于特征的方差。但是，我们没有使用平均值作为中心并对平方距离求和，而是使用中位数作为中心并对绝对距离求和。所提出的距离函数具有优于欧几里德距离的优点，因为它对异常值更鲁棒。使用 MAD 进行缩放对于将所有要素调整到相同的比例是必要的。不管你是用平方米还是平方英尺来衡量一套公寓的大小，都没有关系。

参数λ平衡预测中的距离(第一项)和特征值中的距离(第二项)。对给定的λ求解损失，并返回一个反事实*x*’。λ值越高，意味着我们更喜欢预测接近预期结果的反事实*y*’。较低的值意味着我们更喜欢与特征值中的 *x* 非常相似的反事实*x*’。如果λ非常大，则选择预测最接近*y*’的实例，而不管它离 x 有多远。最终，用户必须决定如何平衡反事实的预测与期望结果相匹配的要求和反事实与 x 相似的要求。

为了最小化这个损失函数，可以使用任何合适的优化算法。如果你可以访问机器学习模型的梯度，你可以使用像 Adam 这样基于梯度的方法。必须预先设置要解释的实例 *x* 、期望输出 *y* 和公差参数ϵ。损失函数对于 *x* 被最小化，并且(局部)最佳反事实 *x* 被返回，同时增加λ，直到找到足够接近的解(=在容差参数内)。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figf_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figf_HTML.jpg)

总的来说，制造反事实的方法很简单。

1.  选择要解释的实例 *x* 、期望的结果*y*’、公差、ϵ和λ的(低)初始值。

2.  随机抽取一个例子作为最初的反事实。

3.  以最初采样的反事实为起点，优化损失。

4.  而|*f*(*x*’)*y*’|>ϵ，
    1.  增加λ。

    2.  以当前反事实为起点优化损失。

    3.  返回使损失最小化的反事实。

5.  重复第 2 步到第 4 步，并返回反事实列表或最小化损失的列表。

所提出的方法有一些缺点。它只考虑第一个和第二个标准，不考虑最后两个(“产生只有少量特征变化和可能的特征值的反事实”)。 *d* 不喜欢稀疏解决方案，因为增加 10 个特征与增加 10 个特征到 *x* 的距离相同。不现实的特征组合不会被扣分。

该方法不能很好地处理具有许多不同级别的分类特征。作者建议对分类特征的特征值的每个组合分别运行该方法，但是如果您有多个具有许多值的分类特征，这将导致组合爆炸。例如，具有十个独特级别的六个分类特征将意味着一百万次运行。

现在让我们来看看解决这些问题的另一种方法。

在这种方法中，下列损失被最小化。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figg_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figg_HTML.jpg)

四个目标 *o* <sub>1</sub> 到*o*T6】4 中的每一个都对应于上述四个标准中的一个。第一个目标 *o* <sub>1</sub> 反映了反事实 *x* 预测应该尽可能接近我们期望的预测*y*’。因此，我们想要最小化 f(*x*′)和*y*′)之间的距离，这是通过曼哈顿度量(L1 范数)计算的。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figh_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figh_HTML.jpg)

第二个目标 *o* <sub>2</sub> 反映了反事实应该尽可能地与实例 *x* 相似。它将 *x* 和 *x* 之间的距离量化为高尔距离。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figi_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figi_HTML.jpg)

*p* 是特征的数量。 *δ* <sub>*G*</sub> 的值取决于 *x* <sub>*j*</sub> 的特征类型。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figj_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figj_HTML.jpg)

将数值特征 *j* 的距离除以*R*<sub>T5】j</sub>，观察值范围，将所有特征的 *δ* <sub>*G*</sub> 缩放到 0 到 1 之间。

高尔距离可以处理数字和分类特征，但不计算有多少特征发生了变化。因此，我们使用 L0 范数来计算第三个目标中的特征数，*o*T2 3。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figk_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figk_HTML.jpg)

通过最小化 o <sub>3</sub> ，我们的目标是我们的第三个标准——稀疏特征变化。

第四个目标 o <sub>4</sub> 反映了反事实应该具有可能的特征值/组合。我们可以推断一个数据点使用训练数据或另一个数据集的“可能性”有多大。我们将这个数据集表示为 X <sup>obs</sup> 。为了估计可能性，o <sub>4</sub> 测量 *x* 和最近的观察数据点 X<sup>【1】</sup>∈X<sup>OBS</sup>之间的平均高尔距离。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figl_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figl_HTML.jpg)

这两个是产生反事实解释的最普遍的理论。除此之外，我们想介绍各种从数据中产生反事实的实用方法。这些算法将在下一节讨论。

*   原型引导的反事实

*   骰子

*   多目标反事实

### 原型引导的反事实

该算法是反事实解释算法的扩展。它使用类原型生成反事实。

这个公式的关键是需要设计一个目标函数，允许你生成高质量的反事实实例。

一个反事实的实例应该具有以下理想的特性。

*   模型预测应该接近预定义的输出。

*   将原始实例 *x* 改变为 *x* 的扰动应该是稀疏的。

*   反事实需要是可解释的。

*   反事实需要足够快地被发现，以便它能被应用在现实生活中。

### 骰子

骰子可以生成多个互不相同但尽可能接近原始实例的反事实。因此，在损失函数中，添加了以下组件。

*   反事实的期望类和模型类之间的距离

*   不同反事实之间的距离，以确保它们之间的多样性

*   反事实和原始实例之间的距离，以确保反事实的可行性

在这种情况下，稀疏性是在特定的基础上控制的。因此，在该算法中，您可以选择需要更改的特征来生成反事实。

### 多目标反事实

该算法试图优化大多数重要属性。它的损失函数包括以下几个部分。

*   反事实的期望类和模型类之间的距离

*   反事实和原始实例之间的相似性

*   被改变的特征的数量或稀疏度

*   反事实是否具有可能的特征值或值的组合

由于该算法在其损失函数中具有所有重要的性质，所以它产生非常逼真的反事实。然而，为每个实例生成反事实所花费的时间对于该算法来说是最长的，因为目标函数太复杂而无法求解。

## 算法之间的比较

本节比较了各种算法，以确定并向用户建议一种方法来生成他们数据的反事实。通过各种度量进行比较，如所用时间、输出的稀疏性、生成的解释的百分比、分类变量的方法、相似性等。表 [11-1](#Tab1) 中提到了这些指标。

这些算法在同一个在线购物者意向数据集上进行了测试，在第 [9](09.html) 章的开头提到过。这台机器是一台 8 GB 内存的苹果 MacBook。没有应用并行化。结果是逐例生成的。

注意事项:

*   在不同的概率范围内测试时间(总共测试了 6 到 10 个实例)

*   稀疏性:高意味着改变的变量数量较少，反之亦然

*   根据用于测试的 10 个观察样本报告的百分比

*   指示函数:分类变量的值的任何变化都被认为是距离 1

根据评估，我们认为 DiCE 是一种可以在许多用例中使用的算法。接下来是骰子。

## 骰子

有效的反事实解释应该满足两个性质。

*   给定用户情境和约束的反事实行为的可行性

*   呈现的反事实的多样性

因此，产生和评估各种反事实解释的框架是基于决定性的点过程。为了评估反事实的可操作性，度量应该将基于反事实的方法与其他本地解释方法进行比较。

输入是经过训练的机器学习模型 f 和实例 *x* 。我们想生成一组 *k* 反事实例子，{*c*T6】1，*c*T10】2，。。。、*c*<sub>*k*</sub>}，这样它们都导致不同于 *x* 的决策。

实例( *x* )和所有 CF 实例({ *c* <sub>1</sub> ， *c* <sub>2</sub> ，)。。。、*c*<sub>*k*</sub>})都是*d*-量纲。机器学习模型被假设为可微分的和静态的(不随时间改变),并且输出是二进制的。

我们的目标是生成一个可操作的反事实集；也就是说，用户应该找到他们可以采取行动的 CF 示例。要做到这一点，我们需要单个 CF 例子对于原始输入是可行的，但也需要生成的反事实之间的多样性，以提供改变结果类的不同方式。生成不同反事实的多样性度量可以为用户提供多种选择。

同时，该方法结合了使用邻近约束的可行性，并引入了其他用户定义的约束。

### 多样性和可行性限制

尽管不同的 CF 示例增加了至少一个示例对用户是可操作的机会，但是示例可以改变大量特征或者通过考虑来自原始输入的大的改变来最大化多样性。当特征是高维时，这种情况可能会恶化。

经由决定性点过程的多样性。该方法通过建立在用于解决具有多样性约束的子集选择问题的决定性点过程(DPP)上来捕获多样性。以下是基于给定反事实的核矩阵的行列式的度量。

dpp_diversity = det(K)，

Ki，j = 1 1+dist(ci，c j)和 dist(ci，cj)表示两个反事实例子之间的距离度量。在实践中，为了避免定义不明确的行列式，我们在计算行列式的对角线元素上增加了小的随机扰动。

### 接近度

直观上，最接近原始输入的 CF 示例可能对用户最有用。该方法将接近度量化为原始输入和 CF 示例特征之间的(负)矢量距离。这可以通过距离度量来指定，例如ℓ1-distance(可选地通过用户为每个要素提供的自定义权重来加权)。一组反事实例子的接近度是这个集合的平均接近度。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Figm_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Figm_HTML.jpg)

### 稀少

与接近度密切相关的是稀疏度的可行性属性:用户需要改变的特征数量，以过渡到反事实类。直觉上，如果一个反事实的例子对少数几个特征做了改变，它就更可行。一个反事实的例子在特征空间中可能是接近的，但是由于现实世界的限制可能是不可行的。因此，允许用户对特征操作提供约束是有意义的。它们可以用两种方式指定。首先，作为对每个特征的可行范围的框约束，需要搜索 CF 例子。这种约束的一个例子是“收入不能超过 200，000 美元。”或者，用户可以指定可以改变的变量。

### 最佳化

基于多样性和邻近性的定义，该方法考虑了一个组合损失函数总体生成的反事实。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Fign_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Fign_HTML.jpg)

*c* <sub>*i*</sub> 是一个反事实的例子(CF)。 *k* 是要生成的 CFs 总数。f(。)是 ML 模型(终端用户的黑匣子)。yloss(。)是使 f(.)对 cis 和期望结果的预测 *y* (在我们的实验中通常为 1)。 *d* 是输入特征的总数。 *x* 为原始输入。dpp _ 多样性(。)是分集度量。λ1 和λ2 是平衡损失函数的三个部分的超参数。该方法使用梯度下降来优化前面的损失函数。理想情况下，我们可以对每个反事实实现 f(*c*<sub>*I*</sub>)= y，但这并不总是可能的，因为目标是非凸的。运行这些步骤，直到损失函数收敛，并且生成的反事实是有效的(属于期望的类)。

### 优势

反事实解释的解释非常清楚**。**如果实例的特征值根据反事实而改变，则预测改变为预定义的预测。没有额外的假设，也没有后台的魔术。这也意味着它不像 LIME 等方法那样危险，在 LIME 等方法中，我们还不清楚可以在多大程度上推断出用于解释的本地模型。

反事实方法创建了一个新的实例，但是我们也可以通过报告哪些特征值发生了变化来总结一个反事实。这为报告结果提供了两个选项。您可以报告反事实实例，也可以突出显示感兴趣的实例和反事实实例之间发生了哪些变化。

反事实方法不需要访问数据或模型。它只需要访问模型的预测功能，该功能也可以通过 web API 工作。这对于由第三方审计或在不披露模型或数据的情况下为用户提供解释的公司来说很有吸引力。由于商业秘密或数据保护的原因，公司有兴趣保护模型和数据。反事实解释提供了解释模型预测和保护模型所有者利益之间的平衡。

该方法也适用于不使用机器学习的系统。我们可以为任何接收输入并返回输出的系统创建反事实。预测公寓租金的系统也可以由手写的规则组成，反事实的解释仍然有效。

反事实解释方法相对容易实现，因为它本质上是一个损失函数(具有单个或多个目标),可以用标准优化器库进行优化。必须考虑其他细节，例如将特征值限制在有意义的范围内(例如，只有正的公寓大小)。

### 不足之处

对于每一个例子，你通常会找到多种反事实的解释(罗生门效应)。这很不方便:大多数人更喜欢简单的解释，而不是复杂的现实世界。这也是一个实际的挑战。假设我们为一个实例生成了 23 个反事实的解释。我们要全部上报吗？只有最好的？如果都是相对“好”但是差别很大怎么办？每个项目都必须重新回答这些问题。拥有多个反事实的解释也可能是有利的，因为人类可以选择与他们以前的知识相对应的解释。

让我们看一个例子。假设一位酒店经理分析客户预订，并希望分析哪些客户更有可能取消预订。图 [11-1](#Fig1) 显示了一个客户没有取消酒店预订的例子。根据这个案例，客户属于**线下 TA/TO** 细分市场。客户类型为**合同**，分销渠道为 **TA/TO** ，所需停车位为 **0** 。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Fig1_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Fig1_HTML.jpg)

图 11-1

样本反事实输出

表 11-1

从模型产生反事实解释的各种方法的比较

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"></colgroup> 
| 

度量/算法

 | 

反事实的解释

 | 

原型引导的反事实

 | 

MOCCASIN 的简称

 | 

骰子

 | 

细胞

 |
| --- | --- | --- | --- | --- | --- |
| 每个实例的时间 | 7-12 分钟 | 4 分钟 | 30 分钟 | 1 分钟 | 3-65 分钟 |
| 稀少 | 高的 | 高的 | 中等 | 低的 | 高的 |
| 产生的反事实百分比 | 28% | 80% | 70% | 100% | 100% |
| 它如何处理分类变量？ | 没有任何解决的方法 | 有办法解决 | 指示器功能 | 指示器功能 | 没有任何解决的方法 |
| 在数据流形中？ | 不 | 是 | 是 | 不 | 不 |
| 扰动的特征选择 | 不 | 不 | 不 | 是 | 是 |
| 原始实例和反事实实例之间的相似性 | 因情况而异 | 类似的 | 类似的 | 不相似 | 类似的 |
| 产生真实的反事实 | 不 | 是 | 是 | 不 | 不 |
| 生成多个反事实 | 不 | 不 | 是 | 是 | 不 |

然而，一个希望最大限度地减少取消预订的酒店经理最好能够确定哪些类型的客户可能会取消预订。这就是骰子的用武之地。

下面是观察反事实解释时观察到的情况——顾客取消预订的例子。

*   **提前期**在四个示例中明显更长。

*   一个客户仍然属于**线下 TA/TO** 细分市场。

*   四个取消的客户之一仍然是**合同**客户。

*   **分销渠道**和**所需停车位数量**保持不变。

图 [11-2](#Fig2) 是数据集的样本。

![../images/511613_1_En_11_Chapter/511613_1_En_11_Fig2_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Fig2_HTML.jpg)

图 11-2

示例代码的数据集

定义了数据集中的连续特征。

```
# Data set for training an ML model
d = dice_ml.Data(dataframe=data set,
continuous_features=['LeadTime','RequiredCarParkingSpaces'],
outcome_name='IsCanceled')

```

骰子可以从 [`https://github.com/interpretml/DiCE`](https://github.com/interpretml/DiCE) 回购安装。

使用**二元交叉熵**损失和 Adam 优化器，跨 **30** 个时期训练神经网络模型。使用 TensorFlow 版本 2.3.1。

```
from tensorflow.keras.models import Sequential
from tensorflow.python.keras.layers import Dense
from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressorsess = tf.InteractiveSession()
# Generating train and test data
train, _ = d.split_data(d.normalize_data(d.one_hot_encoded_data))
X_train = train.loc[:, train.columns != 'IsCanceled']
y_train = train.loc[:, train.columns == 'IsCanceled']# Fitting a dense neural network model
ann_model = Sequential()
ann_model.add(Dense(6, input_shape=(X_train.shape[1],), activation=tf.nn.relu))
ann_model.add(Dense(1, activation=tf.nn.sigmoid))
ann_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history=ann_model.fit(X_train, y_train, validation_split=0.20, epochs=30, verbose=0, class_weight={0:1,1:2})
history

```

![../images/511613_1_En_11_Chapter/511613_1_En_11_Fig4_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Fig4_HTML.jpg)

图 11-4

训练和验证准确性的图表

![../images/511613_1_En_11_Chapter/511613_1_En_11_Fig3_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Fig3_HTML.jpg)

图 11-3

模型损失图

出于解释目的，该模型现在存储为骰子模型。这些特征现在以与 DiCE 兼容的特殊格式存储，以生成 DiCE 解释实例。

```
new_d = dice_ml.Data(features={
'LeadTime':[0, 737],
'MarketSegment': ['Complementary', 'Corporate', 'Direct', 'Groups', 'Offline TA/TO', 'Online TA'],
'CustomerType': ['Contract', 'Group', 'Transient', 'Transient-Party'],
'DistributionChannel':['Corporate', 'Direct', 'TA/TO', 'Undefined'],
'RequiredCarParkingSpaces': [0, 8]},
outcome_name='IsCanceled')

```

形成骰子解释实例。

```
>>> exp = dice_ml.Dice(new_d,m)
>>> exp<dice_ml.dice_interfaces.dice_tensorflow1.DiceTensorFlow1 at 0x7f22fb2da630>

```

让我们以具有以下属性的客户为例，这些属性包含在所谓的*查询实例*中。

```
query_instance = {'LeadTime': 68,
'MarketSegment': 'Online TA',
'CustomerType': 'Transient',
'DistributionChannel': 'TA/TO',
'RequiredCarParkingSpaces': 0}

```

反事实的例子产生如下。

```
# Generate counterfactual examples
dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=4, desired_class="opposite")
# Visualize counterfactual explanation
dice_exp.visualize_as_dataframe()

```

![../images/511613_1_En_11_Chapter/511613_1_En_11_Fig5_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Fig5_HTML.jpg)

图 11-5

输出样本

这里，生成原始结果为 **1** (即，取消)的案例。还观察到顾客不取消他们的酒店预订的反例也产生了。相反，这里有一个查询实例，客户**取消了他们的酒店预订。**

```
query_instance_2 = {'LeadTime': 93,
'MarketSegment': 'Offline TA/TO',
'CustomerType': 'Contract',
'DistributionChannel': 'TA/TO',
'RequiredCarParkingSpaces': 0}

```

再次，产生了反事实的例子。

```
# Generate counterfactual examples
dice_exp_2 = exp.generate_counterfactuals(query_instance_2, total_CFs=4, desired_class="opposite")
# Visualize counterfactual explanation
dice_exp_2.visualize_as_dataframe()

```

![../images/511613_1_En_11_Chapter/511613_1_En_11_Fig6_HTML.jpg](../images/511613_1_En_11_Chapter/511613_1_En_11_Fig6_HTML.jpg)

图 11-6

输出样本

这些只是一些如何产生反事实解释的例子。

## 摘要

本章涵盖了反事实的解释。当企业查看模型以产生可操作的见解时，反事实解释的重要性开始发挥作用。在业务问题场景中，模型结果并不总是直观的。大多数结果是描述性的(例如，有好处)。反事实有助于衍生行动。保险公司经理建立了一个模型来预测下一个保费周期的客户流失，可以利用反事实来了解每个客户的变化，以促使他们支付保费。在这种情况下，反事实发现了很多好处。然而，反事实并不总是给出合理的解释。

你需要明白，反事实是在模型数据上运行的。各种数据集中的大多数功能不受业务部门的控制。例如，在构建客户流失模型时，特征是年龄、收入、pin 码、财务状况、以前支付的保费、与客户服务部的对话、销售保单的代理人的姓名或其他保单。即使我们建立了一个客户流失模型，并且理解了这个模型对每个实例的作用，我们也无法改变客户的年龄和收入。

但是，像与客户服务中心的对话这样的因素是我们可以控制的几个特征。在对这些数据进行反事实分析之后，公司经理得到了“更改客户服务满意度分数”的输出。这表明要将该客户分配给最佳执行官。这可能会增加客户在下一个周期支付保费的机会。反事实领域并不新鲜；但是，它在行业中的实现非常稀少。我们建议您在他们的组织中寻找用例，或者实现并测试反事实的用例。