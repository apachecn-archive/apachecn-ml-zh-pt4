# 14.数据在可解释性中的作用

现在，让我们试着理解方法和建模技术之外的东西。本章试图找到下列问题的答案。

*   数据复杂性如何影响模型的可解释性？

*   如果不同的工具产生不同的解释，它们是相同的还是不同的？

在前几章中，我们研究了建立在特征重要性框架上的方法。我们评估了 CIU、戴立克斯、埃利 5、SHAP 和溜冰者等方法。这些方法中的每一种都在一些共同的主题上工作，以生成用于对模型的特征进行排序的全局重要性度量。

我们来阐述一下前面两个问题。前面提到的工具解释了黑盒模型。是否可以推断它们类似地生成相同数据集的全局特征重要性，或者在为相同数据集生成的解释之间存在不匹配？类似地，相似解释的产生是否与数据集的特定属性有关？

本章回答了前两个问题，以及数据集的复杂性是否对可解释性有影响。这是通过选择表格数据集、基于各种预定义属性对数据集进行聚类、在这些数据集上构建模型和可解释方法，然后计算不同方法对之间的相关性来分析结果来完成的。

数据集 <sup>[1](#Fn1)</sup> 分别是澳大利亚、钓鱼网站、spec、卫星、anal-catdata 诉讼、钞票认证、输血服务中心、churn、气候模型模拟崩溃、credit-g、delta 副翼、糖尿病、eeg-eye-state、haberman、heart-statlog、ilpd、电离层、jEdit-4.0-4.2、kc1、kc2、kc3、kr-vs-kp、mc1、monks-problems-1、monks-problems-2、monks-problems-3、moz

下面的预处理步骤是为建模目的准备数据集。

1.  基于频率将分类特征转换为序数值。

2.  将布尔特征转换为数字特征(0 和 1)。

3.  对 0 和 1 之间的值使用最小-最大归一化。

分析不同的数据集使您能够根据它们的相似性和差异对它们进行分组，即使数据集是不同的主题。例如，可以基于类熵值创建一个组，然后分离具有或多或少信息的数据集，从而使得数据集复杂性能够影响未来模型解释的关系。本章分析了数据集的 15 个不同属性，然后使用 k-means 聚类算法来识别数据集组。

这 15 个属性是要素数、实例数、维数、二进制要素百分比、属性不同值的标准偏差标称值、平均标称属性不同值、二进制要素数、符号要素百分比、数值要素百分比、类熵、自相关、数值要素数、符号要素数、多数类百分比和少数类百分比。

让我们分析基于随机森林和梯度推进的结果，因为两者都是基于树的集成，并且提供较低的模型可解释性。

对每个模型执行标准的训练-测试分割:70%的数据用于训练，剩余的 30%用于测试。然后，在每个模型上，生成诸如准确度、精确度和召回率之类的度量来定义所创建的模型的度量。

对于 41 个数据集的每一个，都创建了两个模型:一个基于随机森林算法，另一个基于梯度推进，总共生成了 82 个模型。对于每个模型，通过六种不同的特征重要性方法产生了全局可解释性特征重要性等级，总共产生了 492 种不同类型的等级。基于 k-means 聚类，41 个数据集被分成三个不同的组。

为了分析全局特征重要性的等级对，使用了 Spearman 等级相关。这度量等级对之间的相关性，考虑不同值可能出现的等级的想法(在这种情况下，它们是数据集属性)。

在该步骤中，为每个数据集生成两个秩相关对的比较矩阵。结果按组(每个随机森林和梯度增强一个)和聚类(三个不同的数据集聚类)进行计算。

每个聚类分别有 21、17 和 3 个数据集。为了理解数据集的影响，我们需要研究这些集群的行为。本章不讨论最后一个集群，因为它只有很少的数据集(只有三个)。

在总共 15 个属性中，我们讨论了最能描述所分析集群行为的四个属性。

所显示的数据集的四个属性是从 15 个属性中选择的，因为它们是最能区分两个被分析的聚类的属性。然而，我们并不是说其他 11 个性质不能解释这些团簇。唯一不同的是，其余 11 个国家在较小程度上这样做。

*   **集群 0** :该集群以更高数量的特征、更低等级的熵(更少的信息)、更高的自相关和更高的不平衡来表征数据集。

*   **集群 1** :该集群的数据集具有更少的特征、更高的类别熵(更多的信息)、更低的自相关和更低的不平衡。

结果显示在图 [14-1](#Fig1) 和图 [14-2](#Fig2) (另见 [`https://arxiv.org/abs/2107.02661`](https://arxiv.org/abs/2107.02661) )。

![../images/511613_1_En_14_Chapter/511613_1_En_14_Fig2_HTML.jpg](../images/511613_1_En_14_Chapter/511613_1_En_14_Fig2_HTML.jpg)

图 14-2

聚类 1 的箱线图

![../images/511613_1_En_14_Chapter/511613_1_En_14_Fig1_HTML.jpg](../images/511613_1_En_14_Chapter/511613_1_En_14_Fig1_HTML.jpg)

图 14-1

聚类 0 的箱线图

图 [14-1](#Fig1) 是一个箱线图，总结了所有等级对比较(x 轴)及其各自的 Spearman 相关性(y 轴),这些相关性是为聚类 0 的数据集计算的。左边是随机森林，右边是梯度提升。蓝色虚线显示了不同水平的相关性。这些点标识每次比较的相关值的位置。点的颜色指的是每个数据集的属性数量。请注意大多数箱线图的低方差，以及发现的疏忽或低相关性水平。

图 [14-2](#Fig2) 中的箱线图总结了所有等级对比较(x 轴)及其各自的 Spearman 相关性(y 轴),这些相关性是为聚类 1 数据集计算的。左边是随机森林，右边是梯度提升。蓝色虚线显示了不同水平的相关性。这些点标识每次比较的相关值的位置。点的颜色指的是每个数据集的属性数量。注意大多数箱线图的高方差，以及发现的高水平相关性。

图 [14-1](#Fig1) 和 [14-2](#Fig2) 显示，根据几次测试，属于第 0 类的数据集的执行具有低的或可忽略的相关性。这表明，确定比较的六种可解释性方法对组中的大多数数据集产生不同的可解释性等级，而不管使用随机森林还是梯度增强算法。结果表明，具有更大复杂性的数据集产生不同的解释。这证明了结果中发现的低相关性。

结果回答了第一个假设。考虑到目前旨在解释黑盒机器学习模型的工具，可以推断它们产生了相同、相似或不同可解释性的全球排名？

不同的相关性表明，数据集的属性直接影响模型的可解释性。因此，这些工具可以产生相关性更高或更低的可解释性。

尽管随机森林模型和梯度增强模型的结果相似，但相关性存在差异。梯度推进算法结果的一些比较中存在较大的差异；例如，在 SHAP 和洛佛之间，埃利 5 对 CIU，以及埃利 5 对溜冰者。这证明了模型中使用的算法的复杂性(在这种情况下，bagging 和 boosting)会影响可解释性的生成。

重要的是，箱线图中存在的异常值显示了在那些被分析的数据集中存在其他数据集簇的可能性。用于区分每个箱线图中不同数据集的属性数量的颜色表明，相关性中获得的结果不是数据集所具有的属性数量的函数。

结果的比较显示了第二个假设的答案。按照与上一个问题相同的思路，相等、相似或不同的可解释性的产生与数据集的特定属性有关吗？

是的，因为在基准输出中给出的两个数据集簇的等级相关性的结果是不同的，这表明诸如类熵、自相关、多数类百分比和属性数量等属性是干扰可解释性等级的属性。

*   如果一个模型(算法和数据集)为一个低复杂度的数据集解决了一个分类或回归问题，那么参考这个模型的可解释性的等级一定很少(或者甚至只有一个等级)，这允许你推断不同的可解释性度量彼此之间存在更高的相关性。

*   如果一个模型(算法和数据集)解决了一个具有高复杂性的数据集的分类或回归问题，那么这个模型必须有许多可解释性等级，导致不同可解释性度量的等级显示出彼此之间较低的相关性。

## 摘要

本章推导出数据集的复杂性对于生成分类模型的解释很重要，并且模型的选择也极大地影响了整体特征的重要性排序。在这一章中，我们想警告我们的读者不要把可解释性工具看作是魔杖，挥舞它就可以生成准确且易于理解的模型。可解释性技术的用户应该在他们的模型构建练习中采用可解释性实践作为一种仪式，然后遵循模型开发的最佳实践。与在模型函数上应用一个可解释的技巧相比，模型开发和使其为人类所理解需要付出更多的努力。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

数据集是开源的，主要在 OpenML 平台上使用。请在 OpenML 平台( [www)上按数据集名称搜索。openml。org](http://www.openml.org) )了解更多信息。

 </aside>