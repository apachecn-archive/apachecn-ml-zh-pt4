第一章

![image](../images/00007.jpeg)

数据科学导论

那么什么是数据科学，为什么它如此热门？这仅仅是另一种在炒作之后会逐渐消失的时尚吗？我们将从数据科学的简单介绍开始，定义它是什么，它为什么重要，以及为什么是现在。本章重点介绍了数据科学流程以及指南和最佳实践。它介绍了数据科学中一些最常用的技术和算法。它还探索了集合模型，这是数据科学前沿的一项关键技术。

什么是数据科学？

数据科学是从数据中获取有用见解的实践。虽然它也适用于小数据，但数据科学对大数据尤为重要，因为我们现在从组织内外的许多来源收集数 Pb 的结构化和非结构化数据。因此，我们现在数据丰富，但信息贫乏。数据科学为从海量数据中收集可操作信息提供了强大的流程和技术。数据科学来自多个学科，包括统计学、数学、运筹学、信号处理、语言学、数据库和存储、编程、机器学习和科学计算。[图 1-1](#Fig1) 展示了数据科学最常见的学科。虽然术语*数据科学*在商业上是个新名词，但自从 1960 年彼得·诺尔首次使用它来指代计算机科学中的数据处理方法以来，它就已经存在了。自 20 世纪 90 年代末以来，著名的统计学家如 C.F. Jeff Wu 和 William S. Cleveland 也使用了数据科学这一术语，他们认为这一学科与统计学相同，或者是统计学的延伸。

![9781484204467_Fig01-01.jpg](../images/00008.jpeg)

[图 1-1](#_Fig1) 。突出显示构成数据科学的主要学科

数据科学的从业者是数据科学家，他们的技能横跨统计学、数学、运筹学、信号处理、语言学、数据库和存储、编程、机器学习和科学计算。此外，为了提高效率，数据科学家需要良好的沟通和数据可视化技能。领域知识对于交付有意义的结果也很重要。在一个人身上很难找到如此广泛的技能，这就是为什么数据科学是一项团队运动，而不是个人努力。为了提高效率，需要雇佣一个具有互补数据科学技能的团队。

分析光谱

根据 Gartner 的说法，我们所做的所有分析可以分为四类:描述性分析、诊断性分析、预测性分析和规范性分析。描述性分析通常有助于描述情况，并有助于回答诸如*发生了什么？，谁是我的客户*？等。诊断分析帮助您了解事情发生的原因，并可以回答类似*为什么会发生这样的问题？*预测分析具有前瞻性，可以回答诸如*未来会发生什么？*顾名思义，规定性分析更具规定性，有助于回答像*我们应该做什么这样的问题。到我的目的地的最佳路线是什么？我应该如何分配我的投资？*

[图 1-2](#Fig2) 展示了完整的分析范围。它也显示了这个图表的复杂程度。

![9781484204467_Fig01-02.jpg](../images/00009.jpeg)

[图 1-2](#_Fig2) 。光谱所有数据分析

描述性分析

描述性分析用于解释给定情况下正在发生的事情。这类分析通常涉及人工干预，可用于回答诸如*发生了什么？，谁是我的客户？，我们有多少类型的用户？*等。常用的技术包括图表描述统计、直方图、盒须图或数据聚类。你将在本章的后面探索这些技术。

诊断分析

诊断分析有助于您了解某些事情发生的原因以及关键驱动因素。例如，无线提供商可以利用这一点来回答诸如*为什么掉线的电话越来越多？*或*为什么我们每个月都在流失更多的客户？*客户诊断分析可以使用聚类、分类、决策树或内容分析等技术来完成。这些技术可用于统计学、数据挖掘和机器学习。应该注意的是，商业智能也用于诊断分析。

预测分析

预测分析帮助你预测未来会发生什么。它用于预测不确定结果的概率。例如，它可以用来预测信用卡交易是否是欺诈性的，或者给定的客户是否可能升级到高级电话计划。统计学和机器学习为预测提供了很好的技术。这包括神经网络、决策树、蒙特卡罗模拟和回归等技术。

规定性分析

规范性分析将建议采取最佳行动方案来优化您的业务成果。通常，规范分析将预测模型与业务规则结合在一起(例如，如果欺诈概率高于给定阈值，则拒绝交易)。例如，它可以向给定的客户建议最佳的电话计划，或者基于优化，可以为您的送货卡车建议最佳路线。在通道优化、组合优化或交通优化等场景中，说明性分析非常有用，可用于在给定当前交通状况的情况下找到最佳路线。诸如决策树、线性和非线性规划、蒙特卡罗模拟或来自统计和数据挖掘的博弈论等技术可以用于进行规定的分析。参见[图 1-2](#Fig2) 。

分析的复杂性从描述性分析增加到规定性分析。在许多方面，规范分析是分析的天堂，通常被最复杂的分析组织所使用。想象一家智能电信公司，在其业务工作流系统中嵌入了分析模型。它在客户呼叫中心系统中嵌入了以下分析模型:

*   **客户流失模型**:这是一个预测客户流失概率的预测模型。换句话说，它预测了致电呼叫中心的客户最终背叛竞争对手的可能性。
*   **客户细分模型**:将客户细分为不同的细分市场，以达到营销目的。
*   **客户倾向模型**:该模型预测客户对每个营销提议的反应倾向，例如升级到高级计划。

当客户打电话时，呼叫中心系统会根据他们的手机号码实时识别他或她。然后呼叫中心系统使用这三个模型对客户进行评分。如果客户在客户流失模型中得分很高，这意味着他们很有可能会背叛竞争对手。在这种情况下，电信公司会立即将客户转给一组呼叫中心代理，他们有权提供有吸引力的报价以防止流失。否则，如果细分模型将客户评分为有利可图的客户，他/她将被安排到等待时间更短、客户服务最好的特殊礼宾服务。如果倾向模型在升级方面给客户打了高分，呼叫代理就会收到警报，并尝试向客户追加销售有吸引力的升级。该解决方案的美妙之处在于，所有模型都融入了电信公司的业务工作流程，促使他们的代理做出明智的决策，从而提高盈利能力和客户满意度。这在[图 1-3](#Fig3) 中进行了说明。

![9781484204467_Fig01-03.jpg](../images/00010.jpeg)

[图 1-3](#_Fig3) 。使用规范分析的智能电信公司

为什么重要，为什么是现在？

数据科学为客户提供了一个真正的机会，让他们根据收集的所有数据做出更明智、更及时的决策。借助合适的工具，数据科学不仅可以从客户自己的数据中，还可以从他们组织外部不断增长的数据源中为客户提供新的、可操作的见解，例如天气数据、客户人口统计数据、来自征信机构的消费者信用数据以及来自 Twitter、Instagram 等社交媒体网站的数据。以下是数据科学对商业成功至关重要的几个原因。

作为竞争资产的数据

数据现在是一项关键资产，它为明智的组织提供了竞争优势，这些组织可以正确地将数据用于决策。麦肯锡和高德纳同意这一点:在最近的一篇论文中，麦肯锡认为，使用数据和业务分析进行决策的公司比那些不使用数据和业务分析的公司更有生产力，并提供更高的股本回报率。同样，Gartner 认为，投资现代数据基础设施的组织将比同行高出 20%。大数据为组织提供了跨孤岛组合有价值数据的机会，以收集新的见解，推动更明智的决策。

*“与不使用数据和业务分析来指导决策的竞争对手相比，使用数据和业务分析来指导决策的公司效率更高，并在***上获得更高的回报”**

 *—布拉德·布朗等人，麦肯锡全球研究所，2011 年

*“到 2015 年，将高价值、多样化的新信息类型和来源集成到一致的信息管理基础架构中的组织将在财务上超过其行业同行 20%。”*

—regina casonato 等人，Gartner <sup class="calibre9">1</sup>

客户需求增加

在过去几十年中，商业智能一直是大多数组织使用的主要分析形式。然而，随着大数据的出现，更多的客户现在渴望使用预测分析来改善营销和业务规划。传统的 BI 对他们的业务进行了很好的事后分析，但对任何前瞻性问题(包括预测)没有帮助。

过去两年，客户对预测分析的需求激增，因为他们寻求更强大的分析技术，以从他们存储的业务数据中挖掘价值。在我们的综合经验中，我们没有看到像过去两年那样多的客户对数据科学的需求！

提高对数据挖掘技术的认识

今天，数据挖掘和机器学习算法的子集现在得到了更广泛的理解，因为它们已经被网飞和亚马逊等早期采用者尝试和测试，他们在推荐引擎中使用它们。虽然大多数客户并不完全理解所使用的机器学习算法的细节，但它们在网飞电影推荐或在线商店推荐引擎中的应用非常突出。类似地，许多客户现在意识到大多数成熟的在线供应商现在大量使用的定向广告。因此，尽管许多客户可能不知道所用算法的细节，但他们现在越来越了解它们的商业价值。

访问更多数据

数字数据在过去几年里一直呈爆炸式增长，而且没有减弱的迹象。大多数行业专家现在都认为，我们收集的数据比以往任何时候都多。根据 IDC 的预测，到 2020 年，全球数字世界将增长到 35 万亿兆兆字节。其他人认为，世界数据现在每 5 年增长 10 倍，这令人震惊。在最近的一项研究中，麦肯锡咨询公司还发现，在美国 17 个经济部门中的 15 个部门，拥有 1000 多名员工的公司平均存储超过 235 的数据，这比美国国会图书馆存储的数据还多！这种数据爆炸是由社交媒体、手机、智能传感器等新数据源的兴起以及计算机行业的巨大收益推动的。

收集的大量数据还使您能够构建更准确的预测模型。从统计学上我们知道，置信区间(也称为误差幅度)与样本量成反比。所以你的样本量越大，误差就越小。这反过来提高了模型预测的准确性。

更快更便宜的处理能力

我们现在拥有比以往任何时候都多的计算能力。摩尔定律提出，计算机芯片的性能将呈指数增长，每 18 个月翻一番。在现代计算的大部分历史中，这种趋势都是真实的。2010 年，国际半导体技术路线图更新了这一预测，预测 2013 年增长将放缓，届时计算机密度和数量将每 3 年而不是 18 个月翻一番。尽管如此，处理器性能的指数级增长已经带来了技术和经济生产力的巨大进步。今天，智能手机的处理器比 20 年前的台式电脑强大五倍。例如，诺基亚 Lumia 928 拥有双核 1.5 GHz 高通骁龙 S4，速度至少是 1993 年发布的英特尔奔腾 P5 CPU 的五倍，后者在个人电脑中非常受欢迎。在 90 年代，昂贵的工作站如 DEC VAX 大型机或 DEC Alpha 工作站需要运行先进的计算密集型算法。值得注意的是，今天的智能手机也比 1994 年的强大 DEC Alpha 处理器快 5 倍，其速度为 200-300 MHz！如今，您可以在配备多核处理器的经济型个人工作站上运行相同的算法。此外，我们可以利用 Hadoop 的 MapReduce 架构，以比以往更低的成本在商用服务器群上部署强大的数据挖掘算法。有了数据科学，我们现在有工具通过数据挖掘和机器学习算法的智能部署来发现数据中的隐藏模式。

我们也看到了容量的巨大增长，以及计算机内存价格的指数下降。图 1-4 和图 1-5 说明了这一点，它们显示了自 1960 年以来计算机内存容量的指数价格下降和增长。自 1990 年以来，每 MB 内存的平均价格已经从 59 美元下降到 0.49 美分，降价 99.2%。与此同时，内存模块的容量从 8MB 增加到了惊人的 8GB！因此，一台普通的笔记本电脑现在比 90 年代初的高端工作站更强大。

![9781484204467_Fig01-04.jpg](../images/00011.jpeg)

[图 1-4](#_Fig4) 。自 1960 年以来计算机内存的平均价格

![9781484204467_Fig01-05.jpg](../images/00012.jpeg)

[图 1-5](#_Fig5) 。自 1960 年以来的平均计算机内存大小

![Image](../images/00013.jpeg) **注**有关内存价格历史的更多信息，请访问约翰·麦卡勒姆:[http://www.jcmit.com/mem2012.htm](http://www.jcmit.com/mem2012.htm)。

数据科学过程

典型的数据科学项目遵循[图 1-6](#Fig6) 中概述的五步流程。让我们详细回顾一下这些步骤。

1.  **定义** **业务问题**:这很关键，因为它指导着项目的其余部分。在构建任何模型之前，与项目发起人一起确定他或她试图解决的具体业务问题是很重要的。如果没有这一点，人们可能会花费数周或数月时间构建复杂的模型来解决错误的问题，从而导致工作的浪费。一个好的数据科学项目可以收集好的见解，推动更明智的业务决策。因此，分析应该服务于业务目标。不应该是锤子找钉子！从业者使用正式的咨询技术和框架(如引导发现研讨会和六西格玛方法)来帮助业务利益相关者确定业务目标的优先级和范围。
2.  **Acquire and prepare** **data**: This step entails two activities. The first is the acquisition of raw data from several source systems including databases, CRM systems, web log files, etc. This may involve ETL (extract, transform, and load) processes, database administrators, and BI personnel. However, the data scientist is intimately involved to ensure the right data is extracted in the right format. Working with the raw data also provides vital context that is required downstream. Second, once the right data is pulled, it is analyzed and prepared for modelling. This involves addressing missing data, outliers in the data, and data transformations. Typically, if a variable has over 40% of missing values, it can be rejected, unless the fact that it is missing (or not) conveys critical information. For example, there might be a strong bias in the demographics of who fills in the optional field of “age” in a survey. For the rest, we need to decide how to deal with missing values; should we impute with the average value, median or something else? There are several statistical techniques for detecting outliers. With a box and whisker plot, an outlier is a sample (value) greater or smaller than 1.5 times the interquartile range (IQR). The interquartile range is the 75th percentile-25th percentile. We need to decide whether to drop an outlier or not. If it makes sense to keep it, we need to find a useful transformation for the variable. For instance, log transformation is generally useful for transforming incomes.

    相关分析、主成分分析或因子分析是显示变量之间关系的有用技术。最后，在这一阶段进行特征选择，以确定在下一步的模型中使用的正确变量。

    这个步骤既费力又费时。事实上，在一个典型的数据科学项目中，我们花费高达 75%到 80%的时间在数据获取和准备上。也就是说，这是将原始数据转化为用于建模的高质量宝石的关键步骤。古老的格言仍然是正确的:*垃圾进来，垃圾出去*。明智地投资于数据准备可以提高项目的成功率。

3.  **开发** **模型** :这是我们开发预测模型项目中最有趣的部分。在这一步中，我们根据给定的业务问题和数据，确定用于建模的正确算法。例如，如果这是一个二元分类问题，我们可以使用逻辑回归、决策树、增强决策树或神经网络。如果最终的模型必须是可解释的，这就排除了像增强决策树这样的算法。模型构建是一个迭代过程:我们用不同的模型进行实验，以找到最具预测性的模型。我们还会与客户一起验证几次，以确保在退出此阶段之前满足他们的需求。
4.  **部署模型**:一旦构建完成，最终模型必须部署到生产环境中，在那里它将被用来对交易评分，或者被客户用来推动真正的业务决策。根据客户的环境，模型的部署方式有很多种。在大多数情况下，部署模型需要重新实现数据科学家开发的数据转换和预测算法，以便与现有的决策管理平台集成。简单地说，这是一个繁琐的过程。Azure Machine Learning 使数据科学家能够将他们完成的模型部署为 web 服务，可以从任何平台上的任何应用程序调用，包括移动设备，从而大大简化了模型部署。
5.  **Monitor** **model’s performance**: Data science does not end with deployment. It is worth noting that every statistical or machine learning model is only an approximation of the real world, and hence is imperfect from the very beginning. When a validated model is tested and deployed in production, it has to be monitored to ensure it is performing as planned. This is critical because any data-driven model has a fixed shelf life. The accuracy of the model degrades with time because fundamentally the data in production will vary over time for a number of reasons, such as the business may launch new products to target a different demographic. For instance, the wireless carrier we discussed earlier may choose to launch a new phone plan for teenage kids. If they continue to use the same churn and propensity models, they may see a degradation in their models’ performance after the launch of this new product. This is because the original dataset used to build the churn and propensity models did not contain significant numbers of teenage customers. With close monitoring of the model in production we can detect when its performance starts to degrade. When its accuracy degrades significantly, it is time to rebuild the model by either re-training it with the latest dataset including production data, or completely rebuilding it with additional datasets. In that case, we return to Step 1 where we revisit the business goals and start all over.

    我们应该多久重建一次模型？频率因业务领域而异。在稳定的业务环境中，数据不会变化太快，模型可以每一两年重建一次。一个很好的例子是零售银行产品，如抵押贷款和汽车贷款。然而，在环境数据快速变化的动态环境中，模型可以每天或每周重建。一个很好的例子是竞争激烈的无线电话行业。客户流失模型需要每隔几天重新培训一次，因为客户被竞争对手越来越有吸引力的报价所吸引。

![9781484204467_Fig01-06.jpg](../images/00014.jpeg)

[图 1-6](#_Fig6) 。数据科学流程概述

常见的数据科学技术

数据科学提供了来自其组成学科的大量算法，即统计、数学、运筹学、信号处理、语言学、数据库和存储、编程、机器学习和科学计算。为简单起见，我们将这些算法分为以下几组:

*   分类
*   使聚集
*   回归
*   模拟
*   内容分析
*   推荐人

第 4 章提供了这些算法的更多细节。

分类算法

分类算法通常用于将人或事物分类为许多组中的一组。它们也被广泛用于预测。例如，为了防止欺诈，发卡方会将信用卡交易分为欺诈性或非欺诈性。发卡方通常具有大量的历史信用卡交易，并且知道这些交易的每一个的状态。许多这样的情况是由不想支付未授权费用的合法持卡人报告的。因此发行者知道每笔交易是否是欺诈性的。使用这些历史数据，发行者现在可以建立一个模型来预测新的信用卡交易是否可能是欺诈性的。这是一个二元分类问题，其中所有案例都属于两类中的一类。

另一个分类问题是客户升级到高级电话计划的倾向。在这种情况下，无线运营商需要知道客户是否会升级到高级计划。使用销售和使用数据，运营商可以确定哪些客户在过去升级。因此，他们可以将所有客户分为两类:升级与否。由于运营商也有关于新客户和现有客户的人口统计和行为数据的信息，他们可以建立模型来预测新客户升级的概率；换句话说，该模型会将每个客户分为两类。

统计学和数据挖掘为分类提供了许多伟大的工具:这包括逻辑回归，它被统计学家广泛用于构建信用卡、购买倾向模型或神经网络算法，如反向传播、径向基函数或岭多项式网络。其他包括决策树或集成模型，如增强决策树或随机森林。对于具有两个以上类别的更复杂的分类问题，您可以使用预测多个类别的多模态技术。分类问题一般使用使用标签数据进行训练的监督学习算法。Azure 机器学习提供了几种分类算法，包括逻辑回归、决策树、增强决策树、多模态神经网络等。更多详情见第 4 章。

聚类算法

聚类使用非直觉学习将数据分组到不同的类中。聚类和分类问题之间的一个主要区别是，聚类的结果事先是未知的。在聚类之前，我们不知道每个数据点属于哪个聚类。相反，对于分类问题，我们有历史数据显示每个数据点属于哪个类。例如，贷方从历史数据中知道客户是否拖欠汽车贷款。

聚类的一个很好的应用是客户细分，在这种情况下，我们出于营销目的将客户分成不同的部分。在一个好的分段模型中，每个分段中的数据都非常相似。但是，不同细分市场的数据差异很大。例如，游戏领域的营销人员需要更好地了解他或她的客户，以便为他们提供合适的产品。让我们假设他或她对顾客只有两个变量，即年龄和游戏强度。通过聚类，营销人员发现游戏客户有三个不同的细分市场，如图 1-7 所示。第一部分是狂热的游戏玩家，他们每天都充满激情地玩电脑游戏，通常都很年轻。第二部分是偶尔玩游戏的休闲玩家，他们通常在 30 多岁或 40 多岁。非游戏玩家很少玩电脑游戏，通常年龄较大；它们构成了片段 3。

![9781484204467_Fig01-07.jpg](../images/00015.jpeg)

[图 1-7](#_Fig7) 。来自聚类算法的简单假设客户群

统计提供了几种聚类工具，但使用最广泛的是 k-means 算法，它使用距离度量将相似的数据聚类在一起。使用这种算法，你可以先验地决定你想要多少个集群；这是常数 K。如果设置 K = 3，算法将产生三个聚类。关于 k-means 算法的更多细节，请参考 Haralambos Marmanis 和 Dmitry Babenko 的书。机器学习还提供更复杂的算法，如 Teuvo Kohonen 开发的自组织地图(也称为 Kohonen 网络)，或 Stephen Grossberg 和 Gail Carpenter 开发的自适应共振理论(ART)网络。聚类算法通常使用无监督学习，因为在训练期间不知道结果。

![Image](../images/00013.jpeg) **注**你可以在以下书籍和论文中阅读更多关于聚类算法的内容:

“智能网络的算法”，Haralambos Marmanis 和 Dmitry Babenko。康涅狄格州斯坦福德曼宁出版公司。2011 年 1 月。

“自组织地图。第三，加长版”。

斯普林格。t .科霍宁，2001 年。“Art2-A:用于快速类别学习和识别的自适应共振算法”，Carpenter，g .，Grossberg，s .，和 Rosen，d,《神经网络》, 4:493-504。1991 年 a。

回归算法

回归技术用于预测具有数字结果的响应变量。例如，无线运营商可以使用回归技术来预测其客户服务中心的呼叫量。有了这些信息，他们可以分配合适数量的呼叫中心员工来满足需求。回归模型的输入变量可以是数字或分类变量。然而，这些算法的共同点是输出(或响应变量)通常是数字。一些最常用的回归技术包括线性回归、决策树、神经网络和增强决策树回归。

线性回归是统计学中最古老的预测技术之一，其目标是从一组观察到的变量中预测给定的结果。简单的线性回归模型是线性函数。如果只有一个输入变量，则线性回归模型是拟合数据的最佳直线。对于两个或多个输入变量，回归模型是最适合基础数据的超平面。

人工神经网络是一套模拟大脑功能的算法。它们通过实例学习，并且可以被训练来从数据集做出预测，即使将响应映射到独立变量的函数是未知的。有许多不同的神经网络算法，包括反向传播网络和径向基函数(RBF)。然而，最常见的是反向传播，也称为多层感知器。神经网络用于回归或分类。

决策树算法是一种分层技术，它通过基于某些统计标准迭代地分割数据集来工作。决策树的目标是最大化树中不同节点的方差，最小化每个节点内的方差。一些最常用的决策树算法包括迭代二分法 3 (ID3)、C4.5 和 c 5.0(ID3 的后继者)、自动交互检测(AID)、卡方自动交互检测(CHAID)以及分类和回归树(CART)。虽然非常有用，但 ID3、C4.5、C5.0 和 CHAID 算法是分类算法，对回归没有用。另一方面，CART 算法可用于分类或回归。

模拟

模拟被广泛应用于许多行业，以模拟和优化现实世界中的流程。工程师们长期以来一直使用有限元或有限体积等数学技术来模拟飞机机翼或汽车的空气动力学。模拟为工程公司节省了数百万美元的研发成本，因为他们不再需要用真实的物理模型做所有的测试。此外，通过简单地调整计算机模型中的变量，模拟提供了测试更多场景的机会。

在商业中，模拟被用于建模过程，如优化呼叫中心的等待时间或优化卡车运输公司或航空公司的路线。通过模拟，业务分析师可以对大量假设进行建模，以优化利润或其他业务目标。

统计学为模拟和优化提供了许多强有力的技术:马尔可夫链分析可以用来模拟动态系统中的状态变化。例如，它可以用来模拟客户如何在呼叫中心流动:客户在离开之前要等多长时间，或者在使用交互式语音应答(IVR)系统后，他们留在呼叫中心的机会有多大？线性规划用于优化卡车运输或航空路线，而蒙特卡罗模拟用于寻找最佳条件，以优化给定的业务成果，如利润。

内容分析

内容分析用于挖掘文本文件、图像和视频等内容以获得洞察力。文本挖掘使用统计和语言分析来理解文本的含义。简单的关键字搜索对于大多数实际应用来说太原始了。例如，通过简单的关键字搜索来了解 Twitter feed 数据的情绪是一个手工和费力的过程，因为您必须存储积极、中立和消极情绪的关键字。然后，当您扫描 Twitter 数据时，您会根据检测到的特定关键字对每个 Twitter feed 进行评分。这种方法虽然在有限的情况下有用，但是很麻烦而且相当原始。该过程可以通过文本挖掘和自然语言处理(NLP)来自动化，NLP 挖掘文本并尝试基于上下文而不是简单的关键字搜索来推断单词的含义。

机器学习还提供了几种通过模式识别分析图像和视频的工具。通过模式识别，我们可以用人脸识别算法识别已知目标。多层感知器和 ART 网络等神经网络算法可用于检测和跟踪视频流中的已知目标，或帮助分析 x 射线图像。

推荐引擎

推荐引擎已经被亚马逊这样的在线零售商广泛使用，根据用户的喜好推荐产品。推荐引擎有三种主要方法。协同过滤(CF)基于用户或项目之间的相似性进行推荐。通过基于项目的协同过滤，我们分析项目数据以找出哪些项目是相似的。通过协同过滤，该数据具体是用户与电影的交互，例如评级或观看，而不是电影的特征，例如流派、导演、演员。因此，每当客户从这个场景中购买电影时，我们都会根据相似性推荐其他电影。

第二类推荐引擎通过分析每个用户选择的内容来进行推荐。在这种情况下，使用文本挖掘或自然语言处理技术来分析文档文件等内容。相似的内容类型被分组在一起，这形成了向新用户推荐的基础。关于协同过滤和基于内容的方法的更多信息可以在 Haralambos Marmanis 和 Dmitry Babenko 的书中找到。

推荐引擎的第三种方法使用复杂的机器学习算法来确定产品相似性。这种方法也被称为市场篮子分析。朴素贝叶斯或 Microsoft 关联规则等算法用于挖掘销售数据，以确定哪些产品一起销售。

数据科学的前沿

让我们以对处于数据科学前沿的集合模型的快速概述来结束本章。

集合模型的兴起

集成模型是来自机器学习的一组分类器，使用一组算法而不是单个算法来解决分类问题。它们模仿人类通过咨询有知识的朋友或专家来提高决策准确性的倾向。当面临重要的决定时，比如医学诊断，我们倾向于从其他医生那里寻求第二种意见来提高我们的信心。同样，集成模型使用一组算法作为专家小组，以提高准确性并减少分类问题的方差。

几十年来，机器学习社区一直致力于集成模型。事实上，早在 1979 年，达萨拉西和大春子就发表了开创性的论文。然而，自 20 世纪 90 年代中期以来，这一领域取得了快速发展，取得了几项重要贡献，导致了非常成功的实际应用。

集合模型的真实世界应用

在过去的几年中，集合模型已经在现实世界的应用中被发现，包括相机中的人脸识别、生物信息学、网飞电影推荐和微软的 Xbox Kinect。让我们来看看其中的两个应用。

首先，集合模型对 Netflix 奖竞赛的成功非常重要。2006 年，网飞举办了一场公开比赛，获得最佳协同过滤算法奖，奖金为 100 万美元，该算法将他们现有的解决方案提高了 10%。2009 年 9 月，100 万美元的奖金被授予了贝尔科尔的“务实的混沌”,这是一个来自美国电话电报公司实验室的科学家团队与两个不太知名的团队合作的结果。在比赛开始时，大多数团队使用单一分类器算法:尽管他们比网飞模型高出 6–8%，但性能很快就稳定下来，直到团队开始应用集成模型。领先的参赛者很快意识到，他们可以通过将自己的算法与明显较弱的团队的算法相结合来改进他们的模型。最终，大多数顶级团队，包括获胜者，都使用集合模型来显著超越网飞的推荐引擎。例如，第二名的团队在他们的服装中使用了 900 多个单独的模特。

微软的 Xbox Kinect 传感器也采用了系综建模。随机森林是一种集合模型，当用户使用 Xbox Kinect 传感器玩游戏时，它可以有效地跟踪骨骼运动。

尽管在现实世界的应用中取得了成功，集合模型的一个关键限制是它们是黑箱，因为它们的决定很难解释。因此，它们不适合必须解释决策的应用。信用评分卡是一个很好的例子，因为贷方需要解释他们分配给每个消费者的信用评分。在一些市场，这种解释是法律要求，因此集合模型不适合，尽管它们有预测能力。

构建集合模型

构建集成模型有三个关键步骤:a)选择数据，b)训练分类器，以及 c)组合分类器。

建立集成模型的第一步是分类器模型的数据选择。对数据进行采样时，一个关键目标是最大化模型的多样性，因为这可以提高解决方案的准确性。一般来说，模型越多样化，最终分类器的性能就越好，预测的方差就越小。

该过程的步骤 2 需要训练几个单独的分类器。但是如何分配分类器呢？在众多可用的策略中，最流行的两种是装袋和助推。bagging 算法使用不同的数据子集来训练每个模型。随机森林算法使用这种装袋方法。相比之下，boosting 算法通过使训练集中的错误分类的例子在训练期间变得更重要来提高性能。因此，在训练期间，每个额外的模型都专注于错误分类的数据。增强决策树算法使用增强策略。

最后，一旦你训练了所有的分类器，最后一步就是结合它们的结果来做出最终的预测。有几种方法可以合并投票结果，从简单多数到加权多数投票。

集成模型是机器学习中非常令人兴奋的一部分，有可能在分类问题上取得突破。

摘要

本章介绍了数据科学，定义了它是什么，它为什么重要，以及为什么是现在。我们概述了数据科学的主要学科，包括统计学、数学、运筹学、信号处理、语言学、数据库和存储、编程和机器学习。我们讨论了人们对数据科学兴趣高涨背后的主要原因:不断增长的数据量、作为竞争资产的数据、对数据挖掘日益增长的认识以及硬件经济。

介绍了一个简单的五步数据科学流程，以及如何正确应用该流程的指南。我们还介绍了数据科学中一些最常用的技术和算法。最后，我们介绍了集成模型，这是数据科学前沿的关键技术之一。

文献学

1.  亚历山大·林登，2014。高级分析的主要趋势和新兴技术。2014 年高德纳商业智能峰会，美国拉斯维加斯。
2.  “你准备好迎接大数据时代了吗？”麦肯锡全球研究所- Brad Brown、Michael Chui 和 James Manyika，2011 年 10 月。
3.  “21 世纪的信息管理”，Gartner - Regina Casonato，Anne Lapkin，Mark A. Beyer，Yvonne Genovese，Ted Friedman，2011 年 9 月。
4.  约翰·麦卡勒姆:http://www.jcmit.com/mem2012.htm。
5.  “智能网络的算法”，Haralambos Marmanis 和 Dmitry Babenko。康涅狄格州斯坦福德曼宁出版公司。2011 年 1 月。
6.  “自组织地图。第三，加长版”。斯普林格。t .科霍宁，2001 年。
7.  “Art2-A:用于快速类别学习和识别的自适应共振算法”，《神经网络》，4:493–504。1991 年 a。
8.  “使用微软 SQL Server 2008 进行数据挖掘”，杰米·麦克伦南、赵辉·唐和波格丹一世·克里瓦特。印第安纳州印第安纳波利斯威利出版公司，2009 年。*