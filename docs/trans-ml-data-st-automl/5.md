# 5.事务性机器学习解决方案的技术组件和架构

本章将把对话从理论转移到实践，向您展示如何将 TML 解决方案付诸实践，展示典型 TML 解决方案的架构，让您能够确定 TML 解决方案是否非常适合您试图解决的问题，并向您展示 TML 如何与其他技术集成，特别是如何将 TML 解决方案的输出用作其他下游系统的输入。我们将讨论 TML 组件之间的数据流，以及这些数据在每个组件中是如何处理的。下一节将概述 TML 解决方案。

## TML 解决方案概述

构建 TML 解决方案的第一步是确定 TML 是否是正确的解决方案。如前一章所述，在决定 TML 用例时，有四个方面需要考虑:

*   业务领域需要快速决策

*   快速做出决定

*   帮助您的业务所需的价值

*   实现决策价值的速度

确定 TML 是否是正确解决方案的快速经验法则是*如果你有快速数据，那么你将需要快速(事务性)机器学习。快速数据有三个组成部分:(1)数据积累的速度，(2)数据在源和接收器之间流动的速度，(3)数据种类(文本或数字)变化的速度*。然而，虽然这是一个经验法则，但应该进一步考虑是否可以将这些数据流连接起来，以创建用于机器学习的训练数据集。机器学习的应用将需要训练数据集来寻找用于进行预测、寻找最佳值和异常检测的最佳算法。 <sup>[1](#Fn1)</sup> 对具有快速数据或数据流的最优算法的搜索是使用自动机器学习来完成的。每个 TML 解决方案将包含以下组件:

*   数据流生产者

*   充当数据通道的云或字段网关

*   接收/发送数据以便在 DSSP 进一步处理的中间件软件

*   AutoML 对训练数据集执行机器学习

*   AutoML 为消费者生成预测、优化和异常

*   实时显示流光结果

*   算法和洞察力的管理

具体来说，数据生产者在不断地产生数据。数据生产者可以是人，也可以是机器。DSSP 中产生原始数据的中间件软件(MWS)接收原始数据。MWS 将数据格式化为 JSON 格式。MWS 还消耗来自 DSSP 的数据进行处理。该处理通过联接数据流将原始数据(在数据流中存储为 JSON)转换为训练数据集。AutoML 技术消耗训练数据集 <sup>[2](#Fn2)</sup> ，并应用机器学习来找到适合数据的最佳算法。最佳算法存储在 DSSP 中。AutoML 技术还使用最佳算法来生成预测、最佳值和异常，然后由消费者可视化和消费。数据存储在运行 Apache Kafka 的 AWS、Google 或微软服务器上的云中。

消费者可以实时看到流式结果。具体来说，通过 HTTPS 将结果通过安全的 WebSocket 推送到您的 web 浏览器，并通过可视化技术动态生成表格和图形。WebSockets 的优点是您不需要从 MWS 请求结果；当结果在 DSSP 可用时，MWS 会自动向您推送结果。TML 解决方案的管理员管理算法和见解。他们可以使用 aim 控制 TML 解决方案所有组件的运作。例如，如果您看到一个异常解决方案(主题)的大量数据读取，并且消费者对该主题的最后一次读取是在过去几天内，那么您可能希望调查消费者为什么没有使用最新的结果。如果消费者不再使用结果，或离开公司，这种解决方案应该是停用的候选。您也可以通过在 AiMS 中配置通知来自动处理这些情况，它会自动监控 TML 主题的最后使用情况，并通过电子邮件将结果发送给您。下一节将详细讨论这些步骤/组件。

## TML 解决方案的参考架构

TML 解决方案的典型参考架构如图 [5-1](#Fig1) 所示。关键组件是数据的生产者和消费者。这是阿帕奇·卡夫卡使用的发布订阅模式。流入 DSSP 和流出 DSSP 的数据由 MWS 管理，后者生成和使用来自 DSSP 的数据。

![../images/510404_1_En_5_Chapter/510404_1_En_5_Fig1_HTML.jpg](../images/510404_1_En_5_Chapter/510404_1_En_5_Fig1_HTML.jpg)

图 5-1

TML 参考建筑

表 [5-1](#Tab1) 描述了图 [5-1](#Fig1) 中的每个步骤。

表 5-1

TML 流程步骤

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

步骤

 | 

描述

 |
| --- | --- |
| one | 这些是产生数据的数据生成器。制片人可以是物联网传感器软件应用网络和社交媒体硬件设备:电话、手表、汽车、电视、冰箱等。 |
| Two | 数据通过云或现场网关传递。云网关是路由器、交换机等。现场网关可以是 MQTT、Modbus 和 REST。这些网关具有特定的通信协议，可以将电信号转换为处理所需的数字信号。通过 REST API 访问的 HTTP 等互联网协议可以处理云流量。 |
| three | 中间件软件(MWS)是一种专门设计的软件，它连接到 DSSP 来执行读、写、数据转换，调用 AutoML，所有这些都无需人工干预。它作为一个来源。 |
| four | DSSP 存储和管理所有流数据、算法、预测、最佳值、异常和训练数据集。它是所有信息的中央储存库。它还为故障切换提供冗余，并随着数据流的增长而扩展。 |
| five | 中间件软件(与 3 中相同)，它从 DSSP 中读取训练数据集，并调用 AutoML 来启动处理。它充当一个水槽。 |
| six | 一旦由 MWS 启动，AutoML 就连接到 DSSP 以读取训练数据集进行处理。MWS 将 DSSP 中的训练数据集的位置传递给 AutoML 技术；MWS 和 AutoML 之间没有训练数据集交换。一旦 AutoML 确定了最佳算法，它就会生成一个唯一的密钥来标识该算法，并将该密钥存储在 DSSP 的另一个主题中以备将来使用。 |
| seven | MWS 读取最优算法的唯一键，并使用它来提供存储在主题中的预测和最优值。消费者订阅该主题，并通过流可视化来消费这些见解。 |
| eight | 预测值、异常值和最佳值可被传送到调整传感器读数的设备和应用程序，或写入网络和社交媒体渠道，或被其他下游应用程序使用。 |

步骤 4、5 和 6 包括随着新数据流的进入，不断地向 DSSP 读写数据。具体来说，回想一下数据流是连续的数据流，因此任何机器学习过程也必须是连续的，原因如下:

*   较新的数据可能包含需要重新学习的较新的信息、趋势和模式。

*   通过重新学习，最佳算法将捕获不同的信息，并可能提供不同的预测、最佳值和异常值或对等组。

*   更新的预测和/或最佳值或异常将影响决策。

上述原因也是 TML 不同于 CML 的原因:从流数据中快速学习可以识别数据中新出现的模式，这在使用较慢的 CML 过程中是不可能的。从数据流中学习的速度是 TML 相对于 CML 的一个根本优势。虽然 CML 可以从新数据中重新训练或重新学习，但它需要首先提取历史数据，将其合并到训练数据集中，执行任何转换，将机器学习算法应用到训练数据集中，微调超参数，确定最佳算法，然后部署最佳算法，最后开始将其用于预测、优化或异常检测。所有这些都需要很多时间:几天或几周。在部署一个新的经过重新训练的模型的几天或几周内，数据中的底层结构可能已经改变，使得 CML 解决方案变得不那么有用和有效。但是，尽管 CML 是一个较长的过程，它可以用来优化 TML 模型。例如，在异常检测中，可以设置参数值来确定什么是异常，什么不是异常；您可以将这些参数调整为非常敏感或不太敏感。CML 模型可用于确定提供 TML 模型中所需灵敏度的参数值。

如表 [5-1](#Tab1) 所列，TML 流程还有其他好处。明确地

*   模型管理——随着 AutoML 对更新的数据进行重新训练，旧算法可能不再是“最佳”算法，不同的算法可能会更好。这个不同的算法与旧算法一起存储在 DSSP 中。这简化了模型管理，因为新模型的访问方式与旧模型完全相同。旧模型仍然可以被引用并用于与新模型比较和对比结果。

*   审计跟踪——当在新数据的再训练中发现新的算法或超参数时，它们被附加到同一主题或另一主题中；这确保了旧模型不会被覆盖或丢弃。这允许组织维护在源自相同数据流的训练数据集上发现的所有算法的审计跟踪。如果使用此算法的 TML 解决方案做出了错误的决策，导致了财务损失或其他事故，这一点可能很重要。能够追溯失败的根本原因将有助于修复、改进和重新校准 TML 解决方案，以获得更好的未来决策结果。

*   比较模型结果-在 DSSP 中存储算法的另一个好处是用于模型比较。算法的易用性使用户可以看到不同的模型如何处理相似的数据。这也可以用来测试其他人用 AutoML 技术构建的模型的输出。

*   组合模型输出——将不同模型的输出组合成一个统一的模型可以让用户看到整个系统的表现。具体来说，TML 解决方案可以用来解决较小的问题，当这些问题组合起来形成一个较大的系统。TML 的这种系统的系统方法可以非常有效地将非常大的机器学习问题分解成子组件，以便进行更有效的分析。例如，对于大型欺诈活动，多个 TML 解决方案可以分析每个管辖区(国家或城市)的分布式交易，以预测存储在各自数据流中的异常风险分值，这些数据流包括加拿大数据流、美国数据流、英国数据流、印度数据流等。然后，这些数据流可以通过另一个 TML 解决方案进行组合，以代表全球(整体)风险得分。

*   构建训练数据集——一个 TML 解决方案的输出可以作为另一个解决方案的输入。这样，通过将系统分解成子模型，可以将解决方案的结果组合起来，以构建特定的训练数据集。这些子模型的信息水平可以为整个模型或系统提供重要的信息。例如，如果我预测明天的电价，我可以构建 TML 解来预测天气温度和电力需求，将它们的输出作为输入到我的第三个 TML 解中来预测明天的电价。

下一部分将讨论 TML 解决方案的技术组件。

## 技术组件描述

构建 TML 解决方案需要几个组件。本节将详细描述每一项技术，并给出技术名称。每个 TML 解决方案的共同点是

*   用更多的数据流、算法和对等组来扩展和重复上述内容。

*   无监督学习
    1.  AutoML 技术应用机器学习来寻找用于异常检测的对等组。

    2.  AutoML 通过实时与对等组进行比较来确定新数据中出现异常的可能性。

*   连接数据流以构建训练数据集。

*   偏移量用于回滚数据流以获取历史数据。回想一下，偏移量只是表示数据流中数据(消费者)位置的数字，也就是说，数据点(消费者)的偏移量=0 表示它是数据流中的第一个数据点。在数据流的每个分区中，偏移量按顺序递增。

*   监督学习
    1.  AutoML 技术对训练数据集应用机器学习来产生最佳算法。

    2.  AutoML 使用最优算法进行预测或寻找最优值。

表 [5-2](#Tab2) 描述了每个技术组件、其先决条件和核心功能。

表 5-2

技术组件详情

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"></colgroup> 
| 

技术组件

 | 

描述

 | 

先决条件

 | 

功能

 | 

草案

 |
| --- | --- | --- | --- | --- |
| DSP | Apache Kafka(内部部署或云) | **内部部署:**装有 Windows 或 Linux 操作系统的计算机服务器不需要互联网**云:**运行 Apache Kafka 的融合云运行 Kafka 的亚马逊 AWS运行 Kafka 的微软 Azure运行 Kafka 的谷歌云云的互联网连接 | 管理偏移管理分区管理用于故障转移的数据复制存储所有数据流存储所有训练数据集存储所有算法存储所有预测存储所有最佳值 | TCP/IPSSL/TLS(可选) |
| 处女毒蛇 | Apache Kafka 连接器:源和汇 | **内部部署:**装有 Windows、MacOS 或 Linux 操作系统的计算机服务器**云:**运行 Windows、MacOS 或 Linux 操作系统的电脑阿帕奇卡夫卡 | 在 DSSP 创造话题DSSP 的作品给 DSSP 写信创建训练数据集为消费者订阅主题创造生产者创建消费群体启动 AutoML执行预测执行优化与 AiMS 整合执行 AiMS 功能:激活或停用主题警报和通知 | TCP/IPHTTPSSL/TLS(可选) |
| 处女怀孕了 | TML 的 AutoML，执行监督和非监督学习 | **内部部署:**装有 Windows、MacOS 或 Linux 操作系统的计算机服务器**云:**运行 Windows、MacOS 或 Linux 操作系统的电脑原始毒蛇 | 连接到 DSSP 以读取训练数据集对训练数据集执行 AutoML找到最适合数据的最佳算法将最佳算法写入 DSSP将最佳算法存储到磁盘从磁盘读取最佳算法执行预测执行优化执行异常检测 | TCP/IPHTTPSSL/TLS(可选) |
| 目的 | 存储在 dssp 中的管理器算法 | MAADS-VIPERvizWindows、MacOS 或 Linux OS | 管理 HPDE 生成的算法激活或停用算法执行警报和通知在服务管理平台中创建事件管理 Kafka 消费者、生产者和团体 | HTTPHTTPSTCP/IP |
| 马兹-维普维茨 | 提供监督和非监督 TML 解决方案的流可视化 | Windows、MacOS 或 Linux OS阿帕奇卡夫卡原始毒蛇 | 提供来自 HPDE 的所有可视化使用 WebSockets 将新结果推送到客户端 web 浏览器 | HTTPHTTPSTCP/IP |
| MAADS Python 库 | TML 解决方案的 API | 运行用于 Windows、MacOS 或 Linux 解释程序的 Python 编程语言的计算机• Jupyter Notebook（可选）原始毒蛇 | VIPER 的 TML 功能 | HTTPTCP/IP(可选) |
| 休息 | 应用程序接口 | 任何运行 Windows、MacOS 或 Linux 的电脑任何支持 REST(即 HTTP 请求)的编程语言原始毒蛇 | TML 函数REST 指向主机和端口上运行 VIPER 的服务器 | TCP/IPHTTP |

表 [5-2](#Tab2) 中讨论的组件可以根据规模进行实例化。具体来说，对于大型 TML 解决方案，可能需要通过拥有 DSSP、VIPER、VIPERviz 和 HPDE 的几个实例来进行负载削减。这些应用程序中的每一个都可以扩展到仅受硬件限制的任意数量的实例。下一节将展示这些组件如何在一个云实例中组合在一起。

## TML 解决方案的技术架构

上一节讨论了构成 TML 解决方案的技术组件。在本节中，我们将展示这些组件如何在图 [5-2](#Fig2) 所示的技术架构中相互配合。图 [5-2](#Fig2) 中首先要注意的是泳道。

![../images/510404_1_En_5_Chapter/510404_1_En_5_Fig2_HTML.jpg](../images/510404_1_En_5_Chapter/510404_1_En_5_Fig2_HTML.jpg)

图 5-2

TML 技术建筑

*   数据生成–这些都是应用程序、传统设备、移动设备、传感器以及网络和社交媒体。

*   网关——所有数据都流经云网关或一些现场网关。这些网关将核心网络连接到边缘网络，并提供允许数据通过网络传输到最终用户的访问控制。这些还连接不同位置的不同云/数据中心。或者，它们可以将数据存储在 TML 解决方案可以访问的数据库中。TML 将实时执行以下数据转换:(1)连接多个数据流，(2)将每个数据流修剪为相等的长度以形成训练数据集，(3)将数据流中的 JSON 对象转换为用于机器学习的数据阵列，(4)使用 Z 分数和对等组分析构建对等组以进行异常检测，(5)合并和格式化新数据流以进行预测、优化和异常检测。

*   防火墙–确保进出数据中心(或网络基础设施)的数据在适当授权下是安全的，由软件和硬件防火墙进行调节和控制。想要保护其环境的组织将建立一个控制数据进出的防火墙边界。

*   云中的 Kafka——云中的 Kafka 是我们的 DSSP，将存储我们所有的数据、见解和来自 TML 解决方案的算法，供最终用户使用。Kafka 云是安全的，访问它需要使用 SASL/普通认证的云用户名和密码。同样，TML 解决方案与 Kafka 之间的所有流量都将使用传输层安全 <sup>[3](#Fn3)</sup> (TLS)加密进行加密。

*   洞察力消费者——这些消费者使用 TML 解决方案的洞察力。这些人可能是应用程序、设备、网络或社交媒体用户。你可以是一个终端用户，也可以是一台获取信息用于决策的机器。

MAADS-VIPER 位于防火墙内部，接收来自数据生成器的数据。原始数据格式必须是文本格式。MAADS-VIPER 将会

1.  使用 MAADSTML Python 库函数 **vipercreatetopic** 来
    1.  使用云用户名/密码登录 Kafka 云

    2.  在卡夫卡中创造一个话题

2.  Use the MAADS Python library function **viperproducetotopic** to
    1.  使用云用户名/密码登录 Kafka 云

    2.  将数据转换成 JSON

    3.  使用 TLS 加密数据

    4.  将 JSON 数据写入创建的 Kafka 主题

    为了处理 Kafka 主题中的数据，对于监督式学习，MAADS-VIPER 将按照类似的登录过程读取 Kafka 中的主题

3.  使用 MAADS Python 库函数
    1.  **Vipercreatejointopicstreams**–连接多个数据流，并为连接的数据流创建主题

    2.  **蝰蛇生产流**
        *   合并流数据

        *   根据用户选择的偏移量回滚每个流，以形成历史数据

        *   将所有流中的数据生成到连接的主题流中

    3.  **Vipercreatetrainingdata**–创建训练数据集并将其生成到另一个主题

4.  一旦在另一个主题中构建并保存了训练数据集，就可以通过调用 HPDE 来处理它。具体来说，使用函数 **viperhpdetraining** :
    1.  登录 Kafka Cloud 以检索训练数据集(不存在从 VIPER 到 HPDE 的训练数据集移动)，并将机器学习算法应用于该数据集。

    2.  它将生成一个最优算法，并将其物理地写入磁盘，并将关于该算法的所有元数据存储在另一个 Kafka 主题中。

    3.  它将这个 Kafka 主题的名称传递回 VIPER，VIPER 可以使用这个名称进行预测和优化。

5.  使用**viperhpdepression**使用最佳算法进行预测:
    1.  该函数将接受输入数据，即独立变量的值或另一个数据流，将输入数据传递给最优算法，并返回一个预测。

    2.  可以将此函数放入循环中，将输入数据连续传递给最佳算法以生成预测。或者，用户可以将输入数据指向数据流，并在新数据进入输入数据流时生成连续预测。

6.  如果用户需要找到独立变量的最佳或最差值，他们使用 **viperhpdeoptimize** 来执行数学优化，以找到独立变量的最佳值。
    1.  最佳值存储在另一个 Kafka 主题中，并由应用程序检索使用；这些价值(和方法)将是构建闭环解决方案的理想选择，在闭环解决方案中，机器可以在没有人工干预的情况下做出所有决策。

7.  消费者通过 MAADS-VIPER 使用 **viperconsumefromtopic** 来消费预测和最优值。
    1.  该函数登录到 Kafka Cloud，并使用 OFFSET 参数从偏移量开始读取数据。用户可以从开头(偏移量= 0)或结尾(偏移量= -1)或两者之间的任何地方读取主题中的数据。

    2.  数据是 JSON 格式的，几乎任何编程语言或应用程序都可以读取。

    3.  预测值或最优值可以容易地从 JSON 数据中提取。

8.  如果有大量的消费者想要访问相同的主题，那么可以使用 T2 viperconsumergroupconsumoftopic。
    1.  此功能可用于并行处理主题中的数据。当数据被写入一个主题时，该函数将在同一时间将数据分发给每个消费者*。*

    2.  为了优化并行处理的主题，主题应该具有与消费者数量相同的分区数量。这允许 Kafka 将数据分发到主题中的每个分区，以便每个消费者可以同时访问数据进行消费。管理员可以创建一个具有初始分区数的主题，如果需要更多分区来容纳更多用户，可以使用 MAADSTML Python 库来增加分区数。

    3.  该函数对于提高大型分布式 TML 解决方案的性能非常有用。

## 无监督学习

为了使用无监督学习来处理数据以进行异常检测，您将使用两个函数: **viperanomalytrain** 和**viperanomalypict**。该过程类似于监督学习，但是这里我们不创建训练数据集。相反，我们使用 viperanomalytrain 从数据流中找到我们想要分析异常的对等组。具体来说，从数据流生成对等组的过程如下:

1.  **vipercreatejointopicstreams**–连接多个数据流，并为连接的数据流创建主题。

2.  **蝰蛇生产流**
    1.  合并流数据

    2.  根据用户选择的偏移量回滚每个流，以形成历史数据

    3.  将所有流中的数据生成到连接的主题流中

3.  **viperanomalytrain**–创建所有流的对等组。这个对等组是一组代表“正常”行为的事务。

4.  **viperanomalypdict**–实时生成每个新数据的概率得分，通过与对等组进行比较来测试其异常情况。

我们将在下一章展示前面的过程是如何发生的。在此之前，下一节将讨论 TML 组件之间的通信过程。

## 组件之间的通信过程

TML 组件之间的有效沟通对于成功的 TML 解决方案至关重要。确保有效沟通有三个重要因素:

*   安全性

*   并发

*   算法管理

卡夫卡、蝰蛇、VIPERviz 和 HPDE 之间的所有通信都是 SSL/TLS 加密的。对于通过分布式网络传输的敏感信息，这种安全性非常重要。并发性也是一个重要的方面，以确保 TML 解决方案可以处理多个生产者和消费者，他们希望同时从 Kafka 写入和读取信息。虽然可以支持 VIPER、HPDE 和 VIPERviz 的多个实例，但每个应用程序都内置了并发功能，可以同时处理多个请求。这不仅提高了性能，而且减少了每个应用程序的实例数量，从而降低了解决方案开销和成本。图 [5-3](#Fig3) 显示了 TML 解决方案的沟通周期。

![../images/510404_1_En_5_Chapter/510404_1_En_5_Fig3_HTML.jpg](../images/510404_1_En_5_Chapter/510404_1_En_5_Fig3_HTML.jpg)

图 5-3

TML 通信周期

图 [5-3](#Fig3) 显示了 TML 沟通周期中的 12 个步骤。这些描述如下:

*   **数据发生器**通过向 Kafka 产生数据开始通信周期。

*   **MWS 接收器**从数据发生器接收数据。

*   **编码** MWS 使用 SSL/TLS 加密对数据进行编码，并发送给一个 Kafka 主题。

*   **MWS 发送器**向一个卡夫卡主题发送数据。

*   **卡夫卡云**存储数据。

*   **解码** MWS 解码出训练数据集在卡夫卡中的位置，并发送给 HPDE。注意:MWS 不发送训练数据集到 HPDE，只是它在卡夫卡的位置。

*   **HPDE 消费者**消费 Kafka 中的数据，并对训练数据集执行机器学习。

*   **HPDE TML 算法生成器**生成最佳算法，微调超参数，并将其写入卡夫卡主题。

*   **MWS 洞察接收器**接收卡夫卡中的预言、优化和异常。

*   **MWS 洞察制作人**制作实时图表中的预测、优化和异常情况，并使用 WebSockets 推送到用户的浏览器。

*   **编码** MWS 使用 WebSockets 与客户的 web 浏览器通信，通过 HTTPS 推送见解，以便在客户的浏览器中可视化。

*   **网络浏览器**显示实时预测、优化、异常和目标。

*   **MWS 消费者**从他们的网络浏览器中消费关于预测、优化、异常和目标的可视化。

这个周期可以扩展到任意数量的数据流(数据生成器)、算法、生产者和洞察消费者。Kafka 云平台允许水平扩展，使 TML 在处理大量需要快速学习的快速数据时非常有效。

下一节将讨论 TML 解决方案组件之间的数据流。它将显示数据是如何产生和消费的，以及产生和消费的是什么类型的数据。它还将显示消费者需要生成和消费的数据类型，以用于可视化和决策制定。

## 数据流

TML 组件之间的数据流被标准化为 JSON 格式。JSON 格式是一种被广泛使用和接受的数据标准，用于存储、显示和分析信息。Kafka 也符合 JSON 标准。JSON 数据的另一个优势是跨平台和跨应用程序的兼容性，这意味着如果 TML 解决方案的结果需要被另一个系统使用，在许多情况下，这些系统应该能够读取 JSON 格式的数据。JSON 的另一个重要方面是性能。解析 JSON 格式的数据比非 JSON 格式的数据效率高得多。同样，HPDE 创建的每个算法的元数据信息存储在 JSON 中，存储在一个嵌入式数据库中，由 VIPER 读取。这使得 VIPER 和 HPDE 数据在不同操作系统之间的可移植性更加无缝和高效。

图 [5-4](#Fig4) 显示了核心 TML 组件之间的数据移动，具体如下:

![../images/510404_1_En_5_Chapter/510404_1_En_5_Fig4_HTML.jpg](../images/510404_1_En_5_Chapter/510404_1_En_5_Fig4_HTML.jpg)

图 5-4

数据如何在 TML 组件之间流动

1.  数据生成器发送由 MWS (MAADS-VIPER)接收的原始数据。

2.  MWS 在 JSON 中格式化数据，在键-值对中记录日期、时间、位置、值和其他信息，对数据进行编码，并将其生成 Kafka 主题。注意，可以有多个主题流(可能同时)被写到 Kafka。

3.  MWS 接收器使用前面描述的 MAADS 函数消费主题流并创建训练数据集。

4.  MWS 打电话给正在监听主机和端口连接的 HPDE。MWS 将卡夫卡中包含训练数据集的主题名称传递给 HPDE。

5.  HPDE 检索训练数据集并对数据执行机器学习，找到最佳算法，微调超参数，并将算法写入磁盘。然后，它将主题的名称和算法在磁盘上的物理位置返回给调用的 MWS 程序。

6.  MWS 将算法元信息写入 Kafka 主题，并返回主题的名称。

7.  其他 MWS 程序可以使用最佳算法主题名称来传递输入数据(来自数据生成器的原始数据)并生成预测、最佳值或异常。

8.  MWS 将预测、最优值或异常传递给 insight 消费者进行可视化。

前述过程可以重复任意次。该流程的核心要素是

*   确定要联接哪些数据流以创建定型数据集

*   记录每个训练数据集的最佳算法名称(即 Kafka 中的主题)

*   根据正确的主题制作和消费

*   使用新的原始数据和正确的最佳算法来产生预测和/或最佳值和异常

*   将正确的预测和/或最佳值或异常发送给正确的消费者应用程序、设备或网络/社交媒体进行消费

因此，对于上述流程，TML 解决方案将

1.  创建几个主题。

2.  生成几个最优算法写入磁盘。

3.  主题可能需要几个 Kafka 分区。

4.  使用 Kafka 存储和吞吐量。

5.  产生云成本。 <sup>[4](#Fn4)</sup>

因此，管理员、解决方案架构师和可视化设计人员应该密切关注整体解决方案成本，并尽量减少任何不必要的主题、分区和存储。下一节讨论并展示了一个示例 TML 解决方案架构。

## 示例架构

图 [5-5](#Fig5) 显示了使用融合云的示例架构。 <sup>[5](#Fn5)</sup> 融合云是一个在亚马逊 AWS、微软 Azure、谷歌云上提供 Kafka 作为托管服务的平台。

![../images/510404_1_En_5_Chapter/510404_1_En_5_Fig5_HTML.jpg](../images/510404_1_En_5_Chapter/510404_1_En_5_Fig5_HTML.jpg)

图 5-5

TML 范例建筑 <sup>[6](#Fn6)</sup>

上述架构的一些显著特征:

*   训练数据集存储在 Kafka 中，运行在使用 Amazon、Microsoft 或 Google 基础设施的融合云中。

*   MAADS-VIPER (MWS)、VIPERviz 或 HPDE 可以在 Windows、Linux 或 MacOS 环境中运行。

*   MAADS-VIPERviz 是一种可视化技术，用于可视化 Kafka 中的流结果。

*   所有的最优算法、预测、异常和最优值都存储在卡夫卡中。

*   SSL/TLS 加密用于保护进出融合云的数据。

*   VIPER、VIPERviz 和 HPDE 的多个实例可用于连接分布式网络中融合云的多个实例。

*   通过创建一个具有多个分区的主题，可以对访问同一主题的多个消费者进行并行处理。

这种架构的通用性跨越任何提供托管 Kafka 服务的云供应商，使 TML 解决方案不受云的限制，同时确保不同托管 Kafka 服务之间的标准通信和数据格式。这扩展了 TML 解决方案的可行性和可行性。它也使卡夫卡成为生产者、毒蛇、HPDE 和 VIPERviz 产生的所有信息的中心来源和汇集点。下一节将介绍 TML 成本构成。

## TML 成本管理

我们在上一章讨论了 TML 成本的构成；我们在这里详述这一点。对于基于云的解决方案，管理 TML 组件的成本将取决于下面讨论的几个组件:

*   人员–由于 TML 自动化了许多传统的数据科学家任务，您应该为设计、构建、测试、部署和维护 TML 解决方案规划以下资源。人数将取决于您计划开发的 TML 解决方案的规模和数量。这些角色如下:
    *   数据流工程师——为 TML 解决方案提供数据，并使用 MAADS-VIPER 和 MAADSTML Python 库将其提供给 Kafka 的人员。这个人应该有阿帕奇卡夫卡和 Python 的知识。

    *   TML 解决方案架构师——这是一个关键角色，因为此人将设计 TML 解决方案将如何使用数据流，特别是什么是源流和汇流，以及它们将如何结合以产生可视化、规模和决策的结果。

    *   数据流科学家——构建 TML 解决方案的方法、方法论和模型公式，并使用 MAADSTML Python 库进行开发以进行部署的人员。

    *   数据流可视化专家——维护或增强现成可视化的人。MAADS-VIPERviz 提供了四个预构建的可视化工具，分别用于预测、优化、异常和通用可视化，允许您可视化组合数据流。

    *   TML 管理员–使用 AiMS 仪表板管理 TML 解决方案的操作人员。

    *   云基础设施专家–为 TML 解决方案构建和管理云基础设施，并定义安全和访问控制列表的人员。

*   流程和变革管理
    *   变革管理专家——向(企业)用户传达 TML 解决方案的目的和价值，并定义 TML 解决方案所需的任何流程变革的人员。

*   技术
    *   Kafka 分区——最重要的成本构成是每个主题使用的分区数量。成本是以每个分区小时为基础计算的。例如，1000 个分区，1 个主题，1 个小时将花费你 4 美元。虽然这可能看起来很低，但如果您的 TML 解决方案连续运行 6 个月，有 1000 个分区，那么 6 个月内仅一个主题就要花费 17，280 美元。所以，小心使用分区。

    *   网络读写——这将取决于你想以多快的速度向 Kafka 读取数据和写入数据。速度越高，成本越多。

    *   存储—虽然存储是成本最低的组件，但也应该相应地进行管理。

上述组件是在组织中开发、部署和维护 TML 解决方案的核心组件。可能有更多的组件，但是前面的组件代表了成功的 TML 部署所需考虑的大部分因素。下一节将结束本章。

## 结束语

本章详细介绍了 TML 参考和技术架构，重点介绍了 TML 组件之间的通信和数据流。它还展示了一个 TML 建筑的例子。讨论的一些主要重点领域是

*   数据生成器、VIPER、VIPERviz、HPDE、Kafka 和 insight consumers 等 TML 组件之间的通信周期。这可能是一个连续的过程，取决于如何使用 MAADSTML Python 库函数(或 REST API)开发 TML 解决方案。这些函数为开发人员提供对 VIPER 的访问并控制它的功能:向 Kafka 生产、从 Kafka 消费以及调用 HPDE。使用这些库函数可以开发强大的 TML 解决方案。可以创建和合并多个 TML 解决方案。具体来说，使用 Kafka 中的主题，其他 TML 解决方案可以使用相同的优化算法和见解，并在不同的应用程序、设备、网络和社交媒体之间共享信息。

*   TML 组件之间的数据流是 JSON 格式的。JSON 格式使得跨不同应用程序共享见解变得容易，并且简化了从 JSON 对象中检索信息。数据的标准化也使得操作 JSON 对象变得容易，比如组合和分析不同的对象。它还消除了为 TML 解决方案维护物理数据库模式的需求，因为元数据信息存储在 VIPER 和 HPDE 的嵌入式数据库中，使 TML 解决方案在不同环境中具有高度的可移植性。

TML 解决方案可以构建为闭环或开环解决方案。对于闭环解决方案，这使得 TML 解决方案完全无摩擦、自动化，消除了任何人为干预。生成的见解可用于自动调整下游系统。开环解决方案在决策过程中需要一些人为干预，但与 CML 流程相比，这是最小的。

当架构师设计 TML 解决方案时，他们应该注意以下几点:

*   如果多个消费者访问同一个主题，应该考虑并行处理。这将要求每个主题有几个分区来匹配消费者的数量。然而，分区越高，TML 解决方案的成本就越高。

*   创建的算法数量可能会增加，使模型管理变得复杂，并且可能会产生安全问题。TML 管理员应使用 AiMS 来跟踪和管理算法，并在算法未被使用时将其停用。

*   TML 解决方案的成本主要取决于
    1.  人员——如数据流工程师、TML 解决方案架构师、数据流科学家、数据流可视化专家、TML 管理员、云基础设施专家以及流程和变更管理专家

    2.  卡夫卡隔断——隔断越高，成本越高

    3.  存储量

    4.  主题数量

    5.  网络上的数据吞吐量

TML 解决方案不受云、编程语言、数据库和操作系统的限制。它们与亚马逊 AWS、微软 Azure 和谷歌云上的任何托管 Kafka 服务兼容。使用 MAADSTML Python 库，开发人员可以用很少的代码创建功能强大的 TML 解决方案，这些解决方案可以用无限量的数据流、消费者和生产者快速扩展。JSON 数据格式的灵活性使得不同的应用程序和设备可以轻松地使用机器或人类决策和可视化的信息。通过组合不同的对象并分析这些对象以进一步提取信息，它还使得进一步操作 JSON 对象变得容易。

通过使用 Kafka、VIPER、VIPERviz 和 HPDE 的多个实例来扩展 TML 解决方案，使得构建大型 TML 解决方案成为可能。即使业务需求随着时间的推移而发展，TML 解决方案也可以增长(或收缩):这就是 TML 解决方案的弹性本质。可以添加更多的数据流，可以创建更多的训练数据集，可以生成更多的算法。虽然这种增长会增加组织内部的成本和复杂性，但是可以使用 AiMS 来控制、跟踪和管理复杂性和成本。TML 解决方案的可能性几乎是无限的，但与 AiMS 一起，它们可以经济有效且负责任地构建。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

异常检测由 HPDE 使用无监督学习来执行。

  [2](#Fn2_source)

MAADS-VIPER 将从源中提取数据，然后将 JSON 数据转换为数据数组以形成训练数据集，然后将转换后的数据加载到 TML 的 DSSP 中。因此，这将是一个提取-转换-加载的过程。

  [3](#Fn3_source)

[T2`www.rfc-editor.org/info/rfc8446`](http://www.rfc-editor.org/info/rfc8446)

  [4](#Fn4_source)

见表 [4-4](4.html#Tab4) TML 成本构成和表 [4-5](4.html#Tab5) TML 解决方案构成。

  [5](#Fn5_source)

[`www.confluent.io/confluent-cloud`见](http://www.confluent.io/confluent-cloud)。

  [6](#Fn6_source)

详见 [`www.confluent.io/blog/transactional-machine-learning-with-maads-viper-and-apache-kafka/?utm_source=linkedin&utm_medium=organicsocial&utm_campaign=tm.devx_ch.transactional-machine-learning-with-maads-viper-and-apache-kafka_content.analytics-`](https://www.confluent.io/blog/transactional-machine-learning-with-maads-viper-and-apache-kafka/%253Futm_source%253Dlinkedin%2526utm_medium%253Dorganicsocial%2526utm_campaign%253Dtm.devx_ch.transactional-machine-learning-with-maads-viper-and-apache-kafka_content.analytics-) 。

 </aside>