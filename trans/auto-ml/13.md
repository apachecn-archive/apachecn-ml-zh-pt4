

# *第十章*:企业中的 AutoML

“利用机器学习可以带来变革，但要取得成功，企业需要来自高层的领导。这意味着要理解，当机器学习改变了业务的一部分——例如产品组合——那么其他部分也必须改变。这可以包括从营销和生产到供应链的一切，甚至包括招聘和激励制度。”

–Erik Brynjolfsson，麻省理工学院数字经济项目主任

自动化**机器学习** ( **ML** )是一个使能器和加速器，为组织释放了加快分析生命周期的承诺，而没有数据科学家作为瓶颈。在前面的章节中，您学习了如何使用多种超大规模工具执行自动化 ML，包括开源工具、AWS、Azure 和 GCP。

然而，这一章是完全不同的，因为在这里我们将探索自动化 ML 在企业中的应用。我们将研究在现实世界的应用中应用自动化 ML，并讨论这种方法的优缺点。模型的可解释性和透明性是自动化 ML 中非常感兴趣的领域。我们将探索 ML 中的信任模型，为在企业中应用自动化 ML 提供剧本。

在本章中，我们将讨论以下主题:

*   我的组织需要自动化的 ML 吗？
*   自动化 ML–企业高级分析的加速器
*   自动化 ML 的挑战和机遇
*   建立信任——自动化 ML 中的模型可解释性和透明性
*   在组织中引入自动化 ML
*   行动号召–我下一步该去哪里？

# 我的组织需要自动化的 ML 吗？

技术决策者和利益相关者不喜欢时尚，你可能也不应该喜欢。在垂直企业中，为了技术而构建和使用技术的商业价值有限；该技术必须解决一个业务问题，或者提供一种创新的差异化，才是相关的。因此，这个问题变得非常重要:一个组织真的需要自动化的 ML 吗？或者它只是人工智能和 ML 成熟周期中我们可以不需要的一个步骤？这笔投资会带来**的投资回报** ( **的投资回报率**)，还是会成为那些在当时听起来是个好主意的未被使用的平台之一？

让我们通过观察自动化 ML 的价值主张来尝试回答这些问题，并看看它是否非常适合您的组织。作为一名技术利益相关者，设想自己是一个试图建立企业人工智能剧本的人，并决定是否投资和利用或忽视自动化 ML 的效用。

## 巨人的冲突——自动化人工智能对抗数据科学家

在一个组织中，无论规模大小，你首先需要将这个想法传达给你自己的数据科学团队。它可能是一大群人，包括博士、ML 工程师和数据科学家，也可能是一个紧密团结的创业团队，其首席数据科学专家是一名在机器上安装了 Jupyter 笔记本的工程师。无论是哪种情况，你都需要有令人信服的论据来为自动化的 ML 提供论据。

我们以前说过，但很乐意重复一遍:自动化 ML 不会很快扼杀数据科学家的工作。话虽如此，你很难找到一位数据科学家承认使用特征工程、超参数优化或使用自动化 ML 的神经架构搜索的效率。作为数据科学家，我们倾向于认为，数据科学是一种艺术形式，不能强行使用，有时这是正确的。模型调优需要大量的专业技术和知识，因此最好让知道自己在做什么的人来做。问题是这种模式无法扩展:

![Figure 10.1 – Life of a data scientist
](img/Figure_10.1_B16890.jpg)

图 10.1—数据科学家的生活

合格的数据科学家和其他能够大规模构建、调优、监控和部署模型的合格人员永远短缺。我们的组织拥有丰富的数据，但渴望洞察。我们已经看到了几个关键的商业智能、实验和洞察力项目被推到了以收入为中心的项目的优先位置。组织需要自动化的 ML 来让**主题专家** ( **中小企业**)和公民数据科学家建立数据实验并测试他们的假设，而不需要 ML 博士学位。他们会犯错吗？我确定。然而，自动化 ML 将使他们能够建立先进的 ML 模型并测试他们的假设。

所以，我们必须支持 AI 的这种民主化。这并不是说，由自动化 ML 训练的任务关键型信用风险模型应该在没有适当的尽职调查和测试的情况下投入生产——即使是手工制作的模型也不会出现这种情况。组织必须确保性能、健壮性、模型衰退、敌对攻击、离群参数以及准确性矩阵和 KPI 平等地应用于所有模型。

简而言之，企业的 ML 进程是缓慢的。它很难扩展，自动化程度也不高。业务团队和数据科学家之间的协作非常困难，交付业务价值的实际可操作模型也少之又少。自动化 ML 带来了解决这些问题的希望，并为数据科学家提供了额外的工具，以减轻特征工程、超参数优化和神经架构搜索的手动繁重工作。

# 自动化 ML——企业高级分析的加速器

在构建你的人工智能剧本并为你的组织重新设想人工智能人才战略时，你应该将自动化的人工智能视为一个加速器。以下是您希望考虑为您的组织使用自动化 ML 的一些原因。

## 具有人性化见解的 AI 民主化

自动化的人工智能正在迅速成为所有主要人工智能和深度学习平台的固有部分，并将在高级分析的民主化中发挥重要作用。所有主要平台都吹捧这些能力，但要让它成为企业的加速器，自动化的 ML 必须在 AI 的民主化中发挥重要作用。该工具集应该使公民数据科学家能够轻松地执行令人生畏的 ML 任务，并获得对人类友好的见解。任何缺乏可解释、透明和可重复的人工智能和自动化人工智能都不是你所希望的高级分析加速器。

## 增强智能

自动化 ML 在大多数现代数据科学平台中变得根深蒂固，因此将作为 MLOps 生命周期的一部分被商品化。对于数据科学家来说，最大的价值主张是简化特征工程、数据预处理、算法选择和超参数调整，也就是说，增强数据科学家的技能。内置自动 ML 的 MLOps 平台还提供培训和调整、模型监控和管理，以及针对 A/B 测试的直接模型比较功能。这套优秀的工具对加强数据科学家的技能非常有帮助，因此自动化 ML 被证明是数据科学家和领域 SME 的增强智能平台。

# 自动化 ML 的挑战和机遇

我们已经讨论了自动化 ML 的优势，但是所有这些优势都面临着挑战。自动化 ML 并不是灵丹妙药，在很多情况下它都不会起作用。以下是一些挑战和场景，其中自动化 ML 可能不是最适合的。

## 没有足够的数据

数据集的大小是自动化 ML 正常工作的关键因素。当在小数据集上使用特征工程、超参数优化和神经架构搜索时，它们不会产生好的结果。数据集必须非常大，自动化的 ML 工具才能有效地完成工作。如果数据集不是这种情况，您可能希望尝试手动构建模型的替代方法。

## 模型性能

在少数情况下，您从开箱即用模型中获得的性能可能不起作用，您可能需要手动调整模型以获得性能，或者应用自定义启发式方法进行改进。

## 领域专业知识和特殊用例

如果您的模型需要大量的主题专业知识和内置的规则，那么从自动化 ML 模型中获得的收益可能不会提供良好的回报。

## 计算成本

自动 ML 本质上是计算昂贵的。如果数据集非常大，您可以考虑使用本地计算资源(这可能更便宜)来避免与使用云机器相关的昂贵成本。在这些情况下，训练模型所产生的成本可能会超过优化带来的好处——概不负责。

## 拥抱学习曲线

任何值得做的事情从来都不容易，比如锻炼或者 ML。自动化 ML 从重复和乏味的任务中抽走了大部分工作，但是仍然有一个学习曲线。大多数平台将其自动化 ML 产品称为零代码、低代码或无代码方法；但是，您仍然需要熟悉这个工具。当你的结果与你的直觉或基于多年专业知识的假设不符时，会发生什么？如何根据已识别的重要特性来微调模型？哪些模型在训练数据上表现很好，但在生产数据集上表现很差，为什么？这些都是你的公民数据科学家和利益相关者在学习过程中需要考虑的实际问题。这种学习和适应很大程度上取决于您选择的工具以及它为您带来的便利程度。

## 利益相关者的适应

每一项新技术都面临着适应的挑战——由于其本质，自动化的 ML 在到达时就会死亡。你的企业人工智能战略应该包括培训，并纳入学习曲线和与引入新技术(如自动化 ML)相关的潜在中断。构建示例模板和初学者工具包将有助于利益相关者加快速度。我们在实践中看到，让初级数据科学家和开发人员参与进来有助于新技术的社会化。

让我们继续下一部分，在那里我们将讨论各种技术，这些技术可以帮助在由自动化 ML 训练的模型中建立信任。

# 建立信任——自动化 ML 中的模型可解释性和透明度

在由自动化 ML 训练的模型中建立信任似乎是一个具有挑战性的价值主张。向负责自动化决策管理的业务领导、审计人员和利益相关者解释他们可以信任一种算法来训练和构建一种将用于潜在任务关键型系统的模型，这要求您不要将其与“人造”ML 模型区别对待。模型监控和可观察性需求不会因用于构建模型的技术而改变。可重复的模型训练和质量测量，例如验证数据、组件集成、模型质量、偏差和公平性，也是任何 ML 开发生命周期的一部分。

让我们探索一些可以用来在自动化 ML 模型中建立信任并确保治理措施的方法和技术。

## 特征重要性

特征重要性，或者说一个特定的属性对预测结果的积极或消极的贡献程度，是一种由大多数自动化 ML 框架提供的模型检查技术。在前面的章节中，你已经看到了 AWS、GCP 和 Azure 是如何为他们的训练模型提供特性重要性分数的视图的。领域 SME 和公民数据科学家可以使用这些信息来确保模型的准确性。

特征重要性不仅有助于验证假设，还可以提供对以前未知数据的洞察。在领域 SME 的帮助下，数据科学家可以使用特征重要性来确保它不会对任何受保护的类别表现出偏见，并查看任何偏好是否违反法律。例如，如果贷款决策算法偏向于特定的性别、种族或人种，在大多数情况下，这将是非法和不道德的。相反，如果乳腺癌数据库显示出明显的性别偏见，这是由于生物构造，因此不是要减轻或解决的社会或隐含的偏见。测试一个自动化的 ML 模型，或者任何这方面的模型，用扰动测试特征的重要性，可以很好地检查正确性、健壮性和偏差。

## 反事实分析

在算法可解释性中，反事实分析属于基于实例的解释类别。简单地说，它使用因果分析来显示如果一个事件已经发生或没有发生会发生什么。例如，在有偏见的贷款模型中，反事实分析将揭示，在保持所有其他因素不变的情况下，修改贷款申请人的邮政编码会对结果产生影响。这表明模型中对特定地理区域的人存在偏见，这可能是潜在种族偏见的一个迹象，以邮政编码为代表。除了偏见，反事实分析还可以揭示模型假设中的错误，这可能非常有益。

## 数据科学衡量模型准确性

应该应用用于性能估计、模型选择和算法比较的标准 ML 方法，以确保训练模型的准确性和稳健性。下图显示了验证 ML 模型的一些标准方法:

![Figure 10.2 – Standard measures for data science 
](img/Figure_10.2_B16890.jpg)

图 10.2–数据科学的标准方法

对于大型数据集中的性能评估，推荐的方法包括通过正态近似检查置信区间，以及训练/测试分割。对于较小的数据集，重复 k 倍交叉验证、留一交叉验证和置信区间测试有助于确保对性能的良好估计。对于使用大型数据集的模型选择，训练验证、测试分割和使用独立测试集的重复 k-fold 交叉验证的三向保持方法效果很好。为了比较模型和算法，应用多个独立的训练和测试集进行算法比较，规定了 McNemar 测试和 Cochran 测试，而对于较小的数据集，嵌套交叉验证非常有效。

为了使自动化的基于 ML 的模型准确和健壮，我们需要确保我们在整个生命周期中执行可解释性度量。因此，需要在建模前(即描述输入数据的特征)、建模期间(即设计可解释的模型架构和算法)和建模后(即从输出中提取解释)进行检查。

## 预建模可解释性

预建模可解释性始于探索性数据分析和数据集统计描述和净化，即变量描述、元数据、出处、统计、变量间(配对图和热图)、基础事实相关性和生成合成数据的概率模型。这种可解释性扩展到可解释的特征工程，然后是可解释的原型选择和有意义的离群值的识别。

## 建模期间可解释性

当使用自动化的 ML 算法时，在给定选项的情况下，选择采用更易解释的模型族；线性模型、决策树、规则集、决策集、广义加法模型和基于案例的推理方法比复杂的黑盒模型更容易解释。

混合可解释模型也用于设计可解释模型架构和算法，例如**D****eep K-最近邻**(**DKNN**)**深度加权平均分类器**(**DWAC**)**自解释神经网络**(**SENN**)**上下文解释网络** ( **CENs** )和**特征包使用模型将预测和解释结合起来的方法，如**教导对决策的解释** ( **TED** )、多模态解释以及使神经预测合理化，极大地有助于解释模型。视觉解释当然非常有效，因为一幅画胜过千言万语，除非它在更高的维度上，因为那样会变得非常混乱，比如后现代艺术。**

使用架构调整和规则作为工件的可解释性使用可解释的**卷积神经网络**(**CNN**)、可解释的深度架构和基于注意力的模型，它们正被用于自然语言处理、时间序列分析和计算机视觉。

## 建模后的可解释性

有各种用于后建模可解释性的内置工具，它们是自动化 ML 工具包和超规模工具的一部分。这些工具包括宏观解释和基于输入的解释或扰动，以了解输入操作如何潜在地影响输出。基于宏观解释的方法，如重要性分数、决策规则、决策树、依赖图、口头解释和反事实解释，是领域 SME 了解训练模型结果的重要资源。

也有尝试探索众所周知的黑盒的解释估计方法，包括基于扰动的训练(LIME)、反向传播、代理模型、激活优化和 SHAP。

正如在前面的方法中所描述的，在 ML 模型中没有单一的建立信任的方法，无论它们是手工训练的还是通过自动化 ML 工具包建立的。实现这一点的唯一方法是遵循工程最佳实践；验证、可再现性、实验性审计追踪和可解释性是验证和确保其工作的最著名的方法。您可能不需要所有这些方法作为您的 ML 工作流程的一部分，但要知道，这些方法以及在整个生命周期中验证和监控您的模型的各种其他方法对于确保您的企业 ML 操作化的成功至关重要。

# 在组织中引入自动化的 ML

现在，您已经回顾了自动化 ML 平台和开源生态系统，并了解了它是如何在幕后工作的，难道您不想在您的组织中引入自动化 ML 吗？那么，你是怎么做的呢？这里有一些指导你完成这个过程的要点。

## 为撞击做好准备

吴恩达是 Landing AI 的创始人兼首席执行官，前百度副总裁兼首席科学家，Coursera 的联合主席和联合创始人，前谷歌大脑的创始人和领导者，斯坦福大学的兼职教授。他写了大量关于人工智能和人工智能的文章，他的课程对任何开始学习人工智能和深度学习的人来说都是开创性的。在 HBR 关于企业中的人工智能的文章中，他提出了五个关键问题来验证人工智能项目是否会成功。我们相信这同样适用于自动化的 ML 项目。你应该问的问题如下:

*   这个项目能给你带来快速的成功吗？
*   这个项目在规模上是不是过于琐碎或者过于笨拙？
*   你的项目针对你的行业吗？
*   您是否正在与可靠的合作伙伴一起加速您的试点项目？
*   你的项目创造价值了吗？

这些问题不仅有助于选择一个有意义的项目，也有助于寻求商业价值和技术勤奋。建立一个小团队，并任命一名领导者作为自动化 ML 冠军，将有助于推进这项事业。

## 选择正确的自动化 ML 平台

开源、AWS、GCP、Azure 或其他——你应该使用什么自动化的 ML 平台？

在选择自动化 ML 平台时，您需要牢记一些注意事项。首先，如果您是云原生的，也就是说，您的数据和计算驻留在云中，那么使用特定云提供商提供的自动化 ML 来实现所有实际目的会更有意义。如果您有一个混合模型，无论数据驻留在哪里，都要尽量让您的自动化 ML 计算靠近您计划使用的数据。特性奇偶校验可能不会产生如此显著的差异；然而，无法访问正确的数据肯定会。

一般来说，自动化 ML 的云计算和存储资源可能会很快变得昂贵，前提是您正在处理大型模型并同时进行多个实验。如果您在内部场景中有可用的计算资源和数据，那么这是一个理想的场所，不会增加您的超大规模服务器的费用。然而，这伴随着建立基础设施和为本地工具包进行设置的责任。因此，如果成本不是一个主要问题，并且您想快速探索自动化 ML 可以为您做什么，基于云的工具包将是一个理想的伴侣。根据您与云提供商的关系，您可能还能获得折扣。

## 数据的重要性

从前面几章的例子来看，数据，以及大量的数据，是一个成功的自动化 ML 项目所需要的最重要的东西，这一点已经变得非常明显。较小的数据集不能提供良好的准确性，也不能作为自动化 ML 的良好用例。如果您没有足够大的数据集来处理，或者您的用例不适合自动化 ML，那么它可能不适合这项工作。

## 针对受众的正确信息

自动化 ML 承诺为数据科学家和中小企业提供巨大的价值；因此，你应该仔细构思你的推销。

对于商业领袖和利益相关者来说，它是一个商业实现工具，将帮助公民数据科学家加快开发；业务用户可以测试他们的假设，并以更快的方式执行实验。

对于您的数据科学盟友，您应该引入自动化 ML 作为一种工具，通过从他们的日常工作中消除重复和平凡的任务来帮助增强他们的能力。在许多事情中，自动化 ML 可以帮助消除从数据集筛选重要特征的枯燥工作，并可以帮助在大搜索空间中识别正确的参数和模型。它将加快新数据科学家的培训，并将帮助其他喜欢涉足数据科学实验的工程师通过这样做获得对基础知识的牢固理解。如果你的同事数据科学家和 ML 工程师看到了这项技术的价值，并且没有感到威胁，他们会愿意适应。这可能不是他们第一次听说这种神奇的技术，他们会喜欢使用它，尽管会有一定程度的怀疑。

# 行动号召——我下一步该去哪里？

一切美好的事物都会结束，这本书也是如此。咻！我们在这里谈了很多。自动化 ML 是一个活跃的研究和开发领域，在本书中，我们试图给你一个广度优先的基础知识，主要优势和平台的概述。我们用开源工具包和云平台的例子解释了自动化特征工程、模型和超参数学习以及神经架构搜索的底层技术。我们详细介绍了三个主要的云平台，即微软 Azure、AWS 和 GCP。通过一步一步的演练，您看到了通过构建 ML 模型并对其进行测试而在每个平台中提供的自动化 ML 特性集。

学习之旅不会就此结束。书中提供了几个很好的参考资料，您可以进一步深入了解这个主题。自动化的 ML 平台，尤其是云平台，总是在不断变化，所以当你读到这篇文章的时候，一些屏幕和功能可能已经改变了。跟上这些超尺度的最好方法是跟上变化，这是唯一不变的。

作为临别赠言，我们坚信理查德·布兰森爵士所说的话，即“你不会通过遵守规则来学会走路。你在实践中学习，在跌倒中学习。”学习的最佳方式是实践——执行力胜过未被应用的知识。去尝试一下吧，你会很高兴有这个隐喻编码的战斗伤疤。

编码快乐！

# 参考资料和进一步阅读

有关本章主题的更多信息，您可以参考以下链接:

*   *如何选择自己的第一个 AI 项目*作者:https://hbr.org/2019/02/how-to-choose-your-first-ai-project[吴恩达](https://hbr.org/2019/02/how-to-choose-your-first-ai-project)
*   *可解释的神经科学人工智能:行为神经刺激*，2019 年 12 月，神经科学前沿，13:1346，DOI: 10.3389/fnins.2019.01346
*   *可解释的 ML——让黑盒模型变得可解释的指南*作者克里斯托夫·莫尔纳尔:【https://christophm.github.io/interpretable-ml-book/】T2