# 9.机器学习:实用人工神经网络演示

这是探索机器学习系列的最后一章。我展示了两个基于前几章讨论的概念和 Python 实现的人工神经元网络(ANN)的实例。你应该回顾至少前两章的内容，以便从阅读甚至复制本章的演示中获得最大的收益。

我非常感谢塔里克·拉希德，他的书《打造你自己的神经网络》(CreateSpace 独立出版平台，2016 年)是我准备本书这一章和其他章节的灵感和指导来源。我强烈推荐塔里克的书给那些希望更深入了解实用人工神经网络的读者。塔里克在 [`http://makeyourownneuralnetwork.blogspot.co.uk/`](http://makeyourownneuralnetwork.blogspot.co.uk/) 也有一个博客，我发现这是一个非常有用的信息来源和活跃的讨论。

本章的演示集中在识别手写数字上。它们是经典的人工神经网络项目，充分展示了人工神经网络的学习能力。

## 零件目录表

演示需要额外的零件，详见表 [9-1](#Tab1) 。

表 9-1。

Parts Lists

<colgroup><col> <col> <col></colgroup> 
| 描述 | 量 | 评论 |
| --- | --- | --- |
| 皮皮匠 | one | 40 引脚版本，可接受 T 型或 DIP 型 |
| 无焊试验板 | one | 700 个插入点，带 1 个电源板 |
| 跳线 | 1 包 |   |
| S7-1200 可编程控制器 | one | 1/4 瓦特 |
| 发光二极管 | one |   |
| ip 摄像机 | one | 版本 2 |
| 触觉按钮开关 | one | 使用无焊连接 |

## 演示 9-1: MNIST 数据集

我将向你展示人工神经网络如何识别手写数字。本项目中使用的训练和测试数据直接来自两个混合的国家标准和技术研究所(MNIST)数据库。多年来，这些数据库已被广泛用于训练和测试人工神经网络，并且是评定特定人工神经网络完成任务的准确度的公认标准。

MNIST 数据库的起源来自 500 人手写数字符号的输入图像，其中一半是美国人口普查局的雇员，另一半是高中生。原始黑白图像也被归一化以适应 20 × 20 像素的图像边界块，并进一步抗锯齿，从而为每个像素生成一个字节的灰度值。这意味着什么将很快向你解释清楚。

MNIST 数据集非常大，由 60，000 幅训练图像(104MB)和 10，000 幅测试图像(18MB)组成。这两个数据集都可以从以下网站以逗号分隔值(CSV)格式免费获得:

*   训练设置: [`http://www.pjreddie.com/media/files/mnist_train.csv`](http://www.pjreddie.com/media/files/mnist_train.csv)
*   测试设置: [`http://www.pjreddie.com/media/files/mnist_test.csv`](http://www.pjreddie.com/media/files/mnist_test.csv)

训练集应该用于训练 ANN。所有包含的记录都有标签，这意味着 CSV 数据用它所代表的相应图像来标识。测试集用于检查 ANN 在识别测试 CSV 数据方面的功能有多好。测试数据集还包含标签，以帮助验证人工神经网络是否成功识别了正确的数字。将训练数据与测试数据分开总是一个好主意，因为如果训练数据也是测试数据，人工神经网络可以返回存储的模式。这种情况不能很好地反映人工神经网络实际学习的情况。

图 [9-1](#Fig1) 仅显示了在我的 MacBook Pro 上运行的 hex editor 应用程序显示的训练数据集中包含的第一条记录的开头。

![A436848_1_En_9_Fig1_HTML.jpg](A436848_1_En_9_Fig1_HTML.jpg)

图 9-1。

A portion of the first record in the MNIST training data set

一幅图像由 784 个字节组成，因为数据库中的每幅图像都被调整为 28 × 28 像素或总共 784 个像素。每个像素值代表一个像素的等效灰度值。一个字节的数值范围为 0 到 255，其中 0 表示全白，255 表示全黑。因此，每个数据库图像由 784 个像素值、785 个逗号和 1 个标签字节组成，总计 1570 个字节。虽然这种大小的一条记录并不难处理，但是在一个文件中包含超过 60，000 条记录往往会使大多数程序超载，尤其是那些希望在 Raspberry Pi 上运行的程序。幸运的是，较大的 MNIST 训练和测试数据集有两个非常小的子集，可从以下网站获得:

*   测试数据集 [`https://raw.githubusercontent.com/makeyourownneuralnetwork/makeyourownneuralnetwork/master/mnist_dataset/mnist_test_10.csv`](https://raw.githubusercontent.com/makeyourownneuralnetwork/makeyourownneuralnetwork/master/mnist_dataset/mnist_test_10.csv)
*   列车数据集 [`https://raw.githubusercontent.com/makeyourownneuralnetwork/makeyourownneuralnetwork/master/mnist_dataset/mnist_train_100.csv`](https://raw.githubusercontent.com/makeyourownneuralnetwork/makeyourownneuralnetwork/master/mnist_dataset/mnist_train_100.csv)

我用十六进制编辑器打开了两个下载的数据集，它们看起来都很好。然而，要在 Python 脚本中使用数据，您需要使用一些语句来访问这些数据集。下面的 Python 语句实例化一个名为`dataFile`的 file 对象，将数据逐行读入一个名为`dataList`的 list 对象，最后关闭文件。这些语句类型是使用 Python 读取数据文件的一种非常常见的方式:

```py
dataFile = open("mnist_train_100.csv")
dataList = dataFile.readlines()
dataFile.close()

```

图 [9-2](#Fig2) 显示了一个树莓 Pi 上的交互会话，在这里我使用前面的语句创建了`dataList`对象。

![A436848_1_En_9_Fig2_HTML.jpg](A436848_1_En_9_Fig2_HTML.jpg)

图 9-2。

Interactive Python session creating a dataList object

我在 MNIST 数据集所在的同一个目录中运行了 Python 会话。如果在同一个目录中没有数据集，那么您必须在 MNIST 数据集名称前面加上适当的路径，以避免找不到文件的 Python 错误。

一旦数据被读取，你就可以开始检查它。我输入`len(dataList)`来找出放入`dataList`对象的记录数。正如所料，返回值是`100`。图 [9-3](#Fig3) 显示了这条语句以及第一条记录的显示，我通过输入`dataList[0]`来指示。

![A436848_1_En_9_Fig3_HTML.jpg](A436848_1_En_9_Fig3_HTML.jpg)

图 9-3。

dataList properties

如果您仔细检查图中的`datalist[0]`显示，您可能会看到数据以撇号开始和结束。这表明`dataList[0]`记录被 Python 解释器识别为一个字符串。它可能看起来像数字，但根据 Python，它被认为只是一串 ASCII 字符。结尾撇号前的字符是`\n`，是“转义”字母`n`。这向 Python 表明第一条记录结束了，它应该在该点放置一个新的行。新行字符是记录集的分隔符，告诉 Python 一个记录在哪里结束，下一个记录在哪里开始。所有 100 个记录都被索引，这意味着它们可以通过使用列表名称上适当的索引号被单独访问，就像我访问第一个记录一样(例如，`dataList[0]`)。在这种情况下，索引从 0 开始，范围从 0 到 99。

接下来，我将向您展示如何对记录进行成像，而不是简单地查看毫无意义的无菌数字。

### 想象一个 MNIST 记录

使用几个 Python 命令对数据记录进行成像实际上是相当容易的。我使用 Python GUI IDLE 2 来完成接下来的步骤。GUI 环境是显示结果图像所必需的。如果需要，可以使用 Python 3 GUI，但是需要修改 Python 3 的以下安装语句。创建和显示图像需要 matplotlib 库；更具体地说，pyplot 包中包含的`imshow`和`show`方法，它是整个 matplotlib 库的一部分。输入以下命令安装 matplotlib 库:

```py
sudo apt-get update
sudo apt-get install python-matplotlib

```

一旦安装完成，您就可以输入下一个命令，从 100 条记录的缩写数据集中读取数据。输入以下命令:

```py
import numpy as np
import matplotlib.pyplot as plt
dataFile = open('mnist_train_100.csv')
dataList = dataFile.readlines()
dataFile.close()

```

数据读取部分不需要前两个导入命令，但是我总是希望将任何导入语句放在代码块的开头。`dataFile`逻辑引用是用 open 语句创建的，它指向 100 条记录文件的开头。实际的读取发生在下一个语句中，该语句将 100 个单独的记录读入一个名为`dataList`的列表对象。`readlines`方法只是一个接一个地读取字符，直到遇到一个新行字符(`\n`)。此时，它为列表创建一个新记录，并继续逐字符读取，直到遇到文件尾(EOF)字符，这将停止读取过程。`close`方法只是“破坏”了`dataFile`逻辑引用，这样文件就不会被无意中修改。

一旦数据集在内存中，脚本就被设置为对选定的记录进行成像。以下代码实现了这一目标:

```py
record0 = dataList[0].split(',')
imageArray = np.asfarray(record0[1:]).reshape((28, 28))
plt.imshow(imageArray, cmap='Greys', interpolation='None')
plt.show()

```

第一个命令创建一个名为`record0`的小列表对象，它由读入大`dataList`对象的第一条记录中的所有 785 个元素组成。在`record0`对象中有 785 个单独的列表元素，因为`split`方法通过使用逗号分隔符作为分隔指示符来创建它们。第二个命令使用`imshow`方法创建要显示的图像。它从第二个列表元素开始，是一个 28 × 28 像素的灰度图像。注意`imshow`参数列表中`Greys`的拼写。最后，`show`方法实际上在 IDLE 2 GUI 中显示图像。

图 [9-4](#Fig4) 显示了在 IDLE 2 GUI 中运行的所有前述命令。

![A436848_1_En_9_Fig4_HTML.jpg](A436848_1_En_9_Fig4_HTML.jpg)

图 9-4。

IDLE 2 GUI interactive Python session

得到的数字图像如图 [9-5](#Fig5) 所示。

![A436848_1_En_9_Fig5_HTML.jpg](A436848_1_En_9_Fig5_HTML.jpg)

图 9-5。

The number figure

如您所见，图像显示了一个相当随意书写的数字 5，这是用于训练 ANN 的许多记录之一。顺便说一下，如果你回头看图 [9-1](#Fig1) ，你会看到数字 5 是第一条记录的标签，它确认了记录的身份。

在这一点上，我将讨论转向如何准备数据集，以便它们可以有效地用于人工神经网络。

### 调整输入和输出数据集

您肯定知道，所有 MNIST 数据集都包含从 0 到 255 的值，这远远超出了我迄今为止开发的任何人工神经网络所能接受的范围。输入值应在 0.01 至 1.0 的优选范围内，这非常符合 sigmoid 函数的输入要求。以下 Python 语句调整了 MNIST 数据集记录的值范围，以匹配人工神经网络输入数据集的首选范围:

```py
adjustedRecord0 = (np.asfarray(record0[1:]) / 255.0 * 0.99) + 0.01

```

图 [9-6](#Fig6) 显示了在交互式 Python 会话中创建的调整后的记录集。屏幕截图中还显示了记录集的一部分，确认新的 MNIST 值在所需的输入值范围内。

![A436848_1_En_9_Fig6_HTML.jpg](A436848_1_En_9_Fig6_HTML.jpg)

图 9-6。

Adjusted MNIST data set

前面的讨论关注的是输入，但是输出数据集应该是什么样的呢？答案在于考虑人工神经网络服务的目的。它的目的是识别一个手写数字，其值的范围从 0 到 9。让 ANN 只在与识别出的数字相关联的输出节点之一附近输出高值是有意义的。因此，如下所示的理想输出数组表明 ANN 检测到了手写数字 5。

![$$ \left\{\begin{array}{l}0\\ {}0\\ {}0\\ {}0\\ {}0\\ {}1\\ {}0\\ {}0\\ {}0\\ {}0\end{array}\right\} $$](A436848_1_En_9_Chapter_Equa.gif)T2】

这种数组中的实际值不是 0 或 1，而是接近 0 的低识别值和接近 1 的高识别值。也完全有可能让 ANN 在几个节点上输出中间值，例如 0.4 和 0.6，这表明 ANN 不能选择唯一的值，而是“认为”输入数可能是几个候选数之一。这非常类似于人类不能决定因果书写的数字是什么，例如混淆 4 和 9。

接下来的代码段创建了一个样本训练数组，需要它来更新 ANN 权重，以便它可以识别特定的数字。让我们使用前面讨论的实际输入值，为小型 MNIST 训练数据集中的第一条记录创建一个训练数组。Python 代码非常简单，如下所示:

```py
import numpy as np
dataFile = open('mnist_train_100.csv')
dataList = dataFile.readlines()
dataFile.close()
record0 = dataList[0].split(',')
onodes = 10
train = np.zeros(onodes) + 0.01
train[int[record0[0]] = 0.99
print train

```

除了最后几行之外，前面的程序段对您来说应该非常熟悉了。以下代码行创建一个 10 元素数组，所有值都等于 0.01:

```py
train = np.zeros(onodes) + 0.01

```

接下来，下面一行获取第一条记录中的第一个元素(标签)并将其转换为整数，然后将其设置为等于 0.99:

```py
train[int([record0[0])] = 0.99

```

图 [9-7](#Fig7) 显示了在交互式 Python 会话中运行的前面的代码段。

![A436848_1_En_9_Fig7_HTML.jpg](A436848_1_En_9_Fig7_HTML.jpg)

图 9-7。

Creating a training array interactive session

您可以清楚地看到创建的训练数组，其中第六个元素被设置为 0.99，因为标签等于 5。

既然已经开发了数据集输入和训练集，现在是时候关注如何配置这个人工神经网络了。

### 为手写数字检测配置人工神经网络

这个过程的第一步是决定基本的人工神经网络配置。到目前为止，我主要使用三层人工神经网络，我看不到改变这种方法的真正原因。基于前面的讨论，输出节点的数量被确定为 10。剩下的工作是计算要创建的输入和隐藏节点的数量。

计算输入节点的数量相对容易，因为必须检查 784 个独立的像素值。这意味着人工神经网络需要 784 个输入节点。这看起来很多，但是这个问题的本质决定了这是利用问题域中存在的所有数据所需的数量。

确定隐藏层中的节点数量是一个更难解决的问题。没有可用的分析方法来确定合适的数量。我在这个话题上做了相当多的研究，并确定大多数人工智能研究人员使用各种各样的“经验法则”来确定这个数字。以下是最常见的几种:

*   使用输入层节点(N <sub>i</sub> )和输出层节点(N <sub>o</sub> )的平均值。
*   取 N <sub>i</sub> 乘以 N <sub>o</sub> 的平方根。
*   隐含层节点数(N <sub>h</sub> )应该在 N <sub>i</sub> 和 N <sub>o</sub> 的大小之间。
*   Nh 应该是 N <sub>i</sub> 加上 N <sub>o</sub> 的 2/3 大小。
*   Nh 应该小于 N <sub>i</sub> 大小的两倍。

我非常清楚的一个事实是，人工神经网络配置通常会变成一种试错的情况。有两个相关的术语你应该熟悉，它们是欠拟合和过拟合。当神经网络中的节点太少，无法支持足够的训练时，就会出现欠拟合。拟合不足的症状是 ANN 不能被训练和/或误差高到足以使 ANN 不可用。过度拟合的情况正好相反，在过度拟合的情况下，节点过多，训练受到过多链接的阻碍，ANN 性能受到影响。当发生过拟合时，人工神经网络具有如此大的信息处理能力，以至于训练集中包含的有限数据量不足以训练隐藏层中的所有节点。此外，隐藏层中大量不需要的节点会增加训练网络所需的时间。这种增加的训练时间会使充分训练人工神经网络变得不可能。为了获得最佳性能，目标是既不使人工神经网络过拟合也不使其过拟合。

基于前面的讨论和我的研究，我得出了以下关于设置适当数量的隐藏层节点的结论:

三层人工神经网络中隐藏层节点的数量应设置为输出节点数量的平方，但不应超过输入和输出层节点的平均值。

这个结论可以被认为是前面提到的各种经验法则的“混搭”。我还有趣地注意到，在人工神经网络技术中似乎经常出现平方关系。当计算初始加权的平均值和计算误差函数斜率时，存在这种关系。10 个输出节点的平方意味着应该设置 100 个隐藏层节点。这个值似乎适合初次尝试。如果人工神经网络表现不佳，可以很容易地改变它。

此时，应该将前面的所有代码段合并到一个 Python 脚本中，该脚本还导入了上一章中开发的 ANN.py 脚本。以下列表名为 trainANN.py:

```py
# trainANN.py
import numpy as np
import matplotlib.pyplot as plt
from ANN import ANN

# setup the network configuration
inode = 784
hnode = 100
onode = 10

# set the learning rate
lr = 0.2

# instantiate an ANN object named ann
ann = ANN(inode, hnode, onode, lr)

# create the training list data
dataFile = open('mnist_train_100.csv')
dataList = dataFile.readlines()
dataFile.close()

# train the ANN using all the records in the list
for record in dataList:
    recordx = record.split(',')
    inputT = (np.asfarray(recordx[1:])/255.0 * 0.99) + 0.01
    train = np.zeros(onode) + 0.01
    train[int(recordx[0])] = 0.99
    # training begins here
    ann.trainNet(inputT, train)

```

对于正在执行的计算量来说，Python 代码非常简洁。将 ANN 类定义从测试代码中分离出来总是一个好主意，因为该类可以很容易地更新或扩展，而不需要修改测试代码。

我在一个交互式会话中执行了 trainANN 脚本，它运行时没有错误，但是当然，没有显示任何内容。它现在需要一些测试数据来看看它的功能有多好。

### 试运转

我下载的 MNIST 测试数据子集的设置方式与训练数据相同，因为它与训练数据的格式相同。以下熟悉的 Python 代码准备了测试数据:

```py
import numpy as np
testDataFile = open('mnist_test_10.csv')
testDataList = testDataFile.readlines()
testDataFile.close()

```

在用人工神经网络对第一个测试数据记录进行触觉测试之前，对其进行成像是明智的。图 [9-8](#Fig8) 显示了 IDLE 2 对记录进行成像的会话。

![A436848_1_En_9_Fig8_HTML.jpg](A436848_1_En_9_Fig8_HTML.jpg)

图 9-8。

IDLE 2 GUI interactive Python session

显示的数字如图 [9-9](#Fig9) 所示。

![A436848_1_En_9_Fig9_HTML.jpg](A436848_1_En_9_Fig9_HTML.jpg)

图 9-9。

The number figure

下一步是将以下代码添加到 trainANN.py 脚本中。从技术上讲，这个脚本既训练又测试 ANN。您可能希望给它一个新的名称来反映它的新功能。我只是保留了旧名称，并试图记住它现在测试的是 ANN。额外的 Python 代码如下:

```py
# create the test list data
testDataFile = open('mnist_test_10.csv')
testDataList = testDataFile.readlines()
testDataFile.close()

# iterate through all 10 test records and display output arrays
for record in testDataList:
    recordz = record.split(',')
    # determine record label
    labelz = int(recordz[0])
    # rescale and offset record values
    inputz = (np.asfarray(recordz[1:])/255.0 * 0.99) + 0.01
    outputz = ann.testNet(inputz)
    print 'output for label = ', labelz
    print outputz

```

图 [9-10](#Fig10) 显示了运行新修改的 trainANN 脚本的结果。输出了十个输出数组，但由于屏幕截图过程中的限制，屏幕截图中只显示了六个。

![A436848_1_En_9_Fig10_HTML.jpg](A436848_1_En_9_Fig10_HTML.jpg)

图 9-10。

trainANN output with test inputs

表 [9-2](#Tab2) 简洁地总结了标签值与输出数组中最高值索引的比较结果。

表 9-2。

Test Results

<colgroup><col> <col> <col> <col> <col> <col> <col> <col> <col> <col> <col></colgroup> 
| 标签 | seven | Two | one | Zero | four | one | four | nine | five | nine |
| 索引 | seven | three | one | Zero | four | one | seven | six | Zero | seven |
| 比赛 | x |   | x | x | x | x |   |   |   |   |

百分之五十是相当令人失望的，但也许这是意料之中的，因为人工神经网络只训练了 60，000 多条可用于训练的记录中的 100 条。我确实注意到匹配的记录的输出值相当高，而不匹配的记录具有均匀分布的随机值。

接下来，我稍微修改了代码以自动计算成功率，特别是考虑到我将运行 10，000 个测试记录，并且我不想手动计算那个测试运行。我还删除了输出数组的显示代码。以下代码实现了这些更改:

```py
match = 0
no_match = 0
# iterate through all test records and display output arrays
for record in testDataList:
    recordz = record.split(',')
    # determine record label
    labelz = int(recordz[0])
    # rescale and offset record values
    inputz = (np.asfarray(recordz[1:])/255.0 * 0.99) + 0.01
    outputz = ann.testNet(inputz)
    max_value = np.argmax(outputz)
    if max_ value == labelz:
        match = match + 1
    else:
        no_match = no_match + 1
print 'success match rate = ', float(match)/float(match + no_match)

```

我运行了六次 trainANN 脚本，看到了一些有趣的结果，如图 [9-11](#Fig11) 所示。

![A436848_1_En_9_Fig11_HTML.jpg](A436848_1_En_9_Fig11_HTML.jpg)

图 9-11。

trainANN script with success rate calculations

成功率从 0.4 到 0.6 不等；它使用相同的测试输入数据集。唯一合理的解释是，一些权重矩阵比其他矩阵拟合得更好。这些矩阵是使用随机正态分布生成的，正如我在第 8 章中讨论的，显然，有些比其他的更适合产生更精确的结果。让我们希望当使用完整的 60，000 个训练记录集训练 ANN 时，这些随机变化会消失。要使用 60，000 记录集，只需在 trainANN.py 脚本中对文件的`open`语句进行以下更改:

```py
dataFile = open('mnist_train.csv')

```

我做了这个更改，重新运行了 10 个测试数据记录。令我惊喜的是，成功率现在等于 0.90。顺便说一下，Raspberry Pi 花了大约 5 分钟来处理完整的训练集，我认为这对于一个四核 1.2GHz 处理器来说不是很长。

下一步是运行完整的 10，000 条记录的测试数据集。您可以通过再次只更改一条语句来实现:

```py
testDataFile = open('mnist_test.csv')

```

这一次，脚本花了大约 8 分钟完成，并显示了非常可观的 0.9381 成功匹配率。

接下来，我想看看不同的学习速度下，比赛的成功率是如何变化的。为此，我在 trainANN.py 脚本中添加了一个围绕训练和测试代码的新循环，其中学习速率以 0.1 的增量从 0.1 更改为 0.9。图 [9-12](#Fig12) 显示了该测试的结果。

![A436848_1_En_9_Fig12_HTML.jpg](A436848_1_En_9_Fig12_HTML.jpg)

图 9-12。

Match success rates with different learning rates

0.9442 的最大成功匹配率是针对等于 0.1 的学习率。这是一个非常好的识别率，可以与许多更大更复杂的研究级人工神经网络相媲美。我真的相信，如果你复制了我在这一点上所做的，你会很高兴创造了这样一个性能良好的人工神经网络。我可以从个人经验上说，大部分大学 AI 学生都没有完成你这一章所做的事情。你应该对你目前的背景和教育水平感到非常满意。

然而，不要害怕尝试一些额外的实验，看看人工神经网络在不同参数下的表现，包括改变隐藏节点的数量。Tariq 在他的书中提到的一个技术是 epochs 的概念，其中 ANN 使用相同的训练数据集进行多次训练。每个完整的训练周期被称为一个时期。塔里克和其他人工智能研究人员发现，通常有可能过度训练人工神经网络，导致整体性能比仅运行几个时期的预期更差。这种现象的确切原因尚不清楚，除了研究人员推测人工神经网络由于过多的数据输入而过度拟合。参见前面关于过度训练的讨论，它解释了这种训练出现的症状。

人工神经网络有趣的一面是，它有很多种，你可以用它来尝试调整额外的性能。虽然 94%到 95%的识别准确率没什么可羞愧的，但尝试进一步改进人工神经网络也是值得的。你也可以尝试建立一个卷积人工神经网络，据称它在 MNIST 测试数据集上有 98.5%的成功率。Adrian Rosebrock 博士在 [`www.pyimagesearch.com`](http://www.pyimagesearch.com) 的博客解释了这是如何做到的。这有点复杂，但是使用一个名为 Keras 的伟大 Python 库，以及 Adrian 的自定义库，可以快速、顺利地构建 ANN。这些是强烈推荐给那些想更进一步的人的。

在下一节中，我将向您展示一个使用 Pi 摄像头进行手写数字识别的补充项目。

## 演示 9-2:用 Pi 相机识别手写数字

您必须做的第一件事是确保 Pi 摄像机已在 Raspberry Pi 配置中启用。最简单的方法是通过在命令行输入以下命令来运行 raspi-config 实用程序:

```py
sudo raspi-config

```

然后你会看到显示的菜单，如图 [9-13](#Fig13) 所示。

![A436848_1_En_9_Fig13_HTML.jpg](A436848_1_En_9_Fig13_HTML.jpg)

图 9-13。

raspi-config menu

选择 6 启用摄像头。该选项安装 Pi 摄像机的驱动程序。驱动程序使相机设备和 Jessie 操作系统能够协同工作。

下一步是安装 Pi 摄像头。相机使用柔性带状电缆连接到 Raspberry Pi，该电缆在购买时应该已经连接到相机上。电缆的另一端插入相机串行接口(CSI)连接器，该连接器位于电路板上 RJ-45 连接器的正后方。要插入电缆，您必须首先小心地直接拉起细长塑料棒两侧的两个黑色塑料片。要非常小心，因为这是一个脆弱的塑料片，使用太多的力量很容易打破。塑料片将变松，但仍连接在连接器主体上。

接下来，小心地将柔性电缆插入插座，露出的银色触点背向 RJ-45 连接器。带状电缆上的蓝色背面应朝向 RJ-45 连接器。确保电缆牢固地固定在连接器的底部，并且电缆垂直于电路板，在连接器中没有任何倾斜。接下来，轻轻按下黑色塑料卡舌，将电缆锁定到位。请注意，没有咔嗒声或其他噪音表明塑料件完全就位。只是用坚定但温柔的压力把它锁定在适当的位置。作为一个警告，我注意到，如果移动相机，电缆可能会移位，导致带状电缆在连接器中轻微移位。如果发生这种情况，您通常会看到软件报告无法再与相机连接。如果您看到该错误，只需重新拔插连接器。图 [9-14](#Fig14) 是连接到 CSI 连接器的摄像机带状电缆的特写。

![A436848_1_En_9_Fig14_HTML.jpg](A436848_1_En_9_Fig14_HTML.jpg)

图 9-14。

Camera ribbon cable connected

接下来您需要安装一些 Python 库，这是用 Python 拍照所必需的。输入以下命令即可轻松完成该任务:

```py
sudo apt-get update
sudo apt-get install python-picamera

```

一旦前面的工作都完成了，你就可以拍照了。我将带您通过一步一步的 Python 交互式会话来演示如何对手写数字进行成像。

首先，你需要一个手写的数字作为主语。我建议用黑色细尖的记号笔在一张大约 4 × 4 英寸的白纸上画一个数字。我画了数字 9 作为我的主题。你可以画任何你想要的数字。图 [9-15](#Fig15) 显示的是我手写的数字。

![A436848_1_En_9_Fig15_HTML.jpg](A436848_1_En_9_Fig15_HTML.jpg)

图 9-15。

Subject handwritten number

这看起来可能有点奇怪，因为图像是使用 Pi 相机的单色效果捕捉的，我会简单解释一下。请相信我的话，那张纸是白色的，号码是黑色的。以下是 Python 交互式会话，每个命令后都有注释:

```py
>>> import picamera

```

picamera 包包含捕获、保存和读取图像所需的所有模块。

```py
>>> camera = picamera.PiCamera()

```

这将实例化一个名为`camera`的对象，在该对象上可以调用所需的操作。

```py
>>> camera.color_effects = (128, 128)

```

该命令设置 Pi 相机拍摄黑白图像，这在技术上更像是单色图像，甚至是“灰色阴影”

```py
>>> camera.capture('ninebw.jpg')

```

使用此命令拍摄或捕捉图像。在这种情况下，它以名称`ninebw.jpg`存储在当前目录中。它是默认的 1920 × 1080 像素的高分辨率格式。我建议把写有数字的那张纸放在相机前面大约 5 英寸的地方，支撑起来，使它垂直于相机。Pi 相机镜头的角度非常宽，所以在这么近的距离上，它会将传感器完全填满被摄体。生成的图像将在处理脚本中大幅缩小和调整大小。

图 [9-16](#Fig16) 显示 Pi 相机版本 2 在一个透明塑料支架中，面向写有数字的纸张。顺便说一句，廉价的持有人可在 Amazon.com。

![A436848_1_En_9_Fig16_HTML.jpg](A436848_1_En_9_Fig16_HTML.jpg)

图 9-16。

Pi Camera set up to capture image

捕获数字图像的完整交互式 Python 会话如图 [9-17](#Fig17) 所示。

![A436848_1_En_9_Fig17_HTML.jpg](A436848_1_En_9_Fig17_HTML.jpg)

图 9-17。

Interactive Python session

我修改了 trainANN.py 脚本，以便它使用图像图 [9-15](#Fig15) 作为测试数据输入。接下来显示了名为 trainANN_Image.py 的完整清单，并在清单后面给出了清晰的解释。

```py
import numpy as np
import matplotlib.pyplot as plt
from ANN import ANN
import PIL
from PIL import Image

# setup the network configuration
inode = 784
hnode = 100
onode = 10

# set the learning rate
lr = 0.1

# instantiate an ANN object named ann
ann = ANN(inode, hnode, onode, lr)

# create the training list data
dataFile = open('mnist_train.csv')
dataList = dataFile.readlines()
dataFile.close()

# train the ANN using all the records in the list
for record in dataList:
    recordx = record.split(',')
    inputT = (np.asfarray(recordx[1:])/255.0 * 0.99) + 0.01
    train = np.zeros(onode) + 0.01
    train[int(recordx[0])] = 0.99
    # training begins here
    ann.trainNet(inputT, train)

# create the test list data from an image
img = Image.open('ninebw.jpg')
img = img.resize((28, 28), PIL.Image.ANTIALIAS)

# read pixels into list
pixels = list(img.getdata())

# convert into single values from tuples
pixels = [i[0] for i in pixels]

# save to a temp file named test.csv with comma separators
a = np.array(pixels)
a.tofile('test.csv', sep=',')

# open the temp file and read into a list
testDataFile = open('test.csv')
testDataList =  testDataFile.readlines()
testDataFile.close()

# iterate through all the list elements and submit to the ANN
for record in testDataList:
    recordx = record.split(',')
    input = (np.asfarray(recordx[0:])/255.0 * 0.99) + 0.01
    output = ann.testNet(input)

# display output
print output

```

请注意，我不必更改基本的 ANN 类来将这些修改合并到 trainANN_Image 脚本中，这是将类定义与功能代码或应用程序代码分离的一个重要原因。

接下来的讨论只涉及对原始 trainAN.py 脚本所做的更改，以适应新的成像处理功能。

### 修改 trainAN.py 脚本

从以下命令开始:

```py
import PIL
from PIL import Image

```

使用 Python 处理图像需要 Python 图像库(PIL)和它的组件之一`Image`。

```py
img = Image.open('ninebw.jpg')
img = img.resize((28, 28), PIL.Image.ANTIALIAS)

```

这些命令加载在脚本中硬编码的文件，然后将其调整为 28 × 28 像素大小的图像。anti-alias 参数确保在缩小尺寸的操作过程中不会产生伪像。

```py
pixels = list(img.getdata())

```

该命令将 784 个像素值转换成一个名为`pixels`的列表。

```py
a = np.array(pixels)
a.tofile('test.csv', sep=',')

```

然后，像素列表被转换成一个数组，该数组适合作为逗号分隔的数组存储在名为`test.csv`的文件中。然后，这个新创建的文件以与未修改的 trainANN.py 脚本中所有其他测试文件完全相同的方式进行处理。

图 [9-18](#Fig18) 显示了输出数据数组，其中您可以清楚地看到，最后一个元素是整个数组中最高的元素，它对应于人工神经网络，人工神经网络认为它已经识别出数字 9，这是正确的答案。

![A436848_1_En_9_Fig18_HTML.jpg](A436848_1_En_9_Fig18_HTML.jpg)

图 9-18。

Output data array

这次演示花费了相当大的努力来准备和运行，以表明一个由 Raspberry Pi 控制的摄像头加上一个训练有素的人工神经网络可以真正识别一个以前所未有的方式书写的数字。

本演示的最后一部分描述了如何自动化图像识别过程。

### 基于人工神经网络的自动数字识别

用人工神经网络实现成像过程的自动化是一项相当简单的任务。我使用了中断驱动的结构，其中图像捕捉和处理通过按下连接到 Raspberry Pi GPIO 引脚之一的按钮来启动。

第一项是硬件设置，包括使用 Pi Cobbler I/O 适配器将 Pi 摄像机、按钮和 LED 连接到 Raspberry Pi。图 [9-19](#Fig19) 是显示 LED 和按钮到 Pi 补鞋匠的连接的烧结图。

![A436848_1_En_9_Fig19_HTML.jpg](A436848_1_En_9_Fig19_HTML.jpg)

图 9-19。

LED and push button connections

我认为不需要单独的原理图，因为图 [9-19](#Fig19) 中清楚地显示了连接。Pi 摄像机的连接如前所述。

在新的脚本中有一个“永远的循环”，我将其命名为 automatedImager.py，它只是在等待中断信号开始图像处理时闪烁一个 LED。接下来列出了完整的脚本，并指出对 trainANN_Image.py 脚本的新修改。

```py
import numpy as np
import matplotlib.pyplot as plt
from ANN import ANN
import PIL
from PIL import Image
import RPi.GPIO as GPIO
import time
import picamera

# instantiate and configure a Pi Camera object
camera = picamera.PiCamera()
camera.color_effects = (128, 128)

# setup the i/o pins 12 and 19
GPIO.setmode(GPIO.BCM)
GPIO.setup(12, GPIO.IN, pull_up_down=GPIO.PUD_DOWN)
GPIO.setup(19, GPIO.OUT)

# this is the callback function where all the processing is done
def processImage(self):
    # capture an image
    camera.capture('test.jpg')

    # create the test list data from an image
    img = Image.open('test.jpg')
    img = img.resize((28, 28), PIL.Image.ANTIALIAS)

    # read pixels into list
    pixels = list(img.getdata())

    # convert into single values from tuples
    pixels = [i[0] for i in pixels]

    # save to a temp file named test.csv with comma separators
    a = np.array(pixels)
    a.tofile('test.csv', sep=',')

    # open the temp file and read into a list
    testDataFile = open('test.csv')
    testDataList =  testDataFile.readlines()
    testDataFile.close()

    # iterate through all the list elements and submit to the ANN
    for record in testDataList:
        recordx = record.split(',')
        input = (np.asfarray(recordx[0:])/255.0 * 0.99) + 0.01
        output = ann.testNet(input)

    # display output
    print output

# event detection
GPIO.add_event_detect(12, GPIO.RISING, callback=processImage)

# setup the network configuration
inode = 784
hnode = 100
onode = 10

# set the learning rate
lr = 0.1 # optimal value

# instantiate an ANN object named ann
ann = ANN(inode, hnode, onode, lr)

# create the training list data
dataFile = open('mnist_train.csv')
dataList = dataFile.readlines()
dataFile.close()

# train the ANN using all the records in the list
for record in dataList:
    recordx = record.split(',')
    inputT = (np.asfarray(recordx[1:])/255.0 * 0.99) + 0.01
    train = np.zeros(onode) + 0.01
    train[int(recordx[0])] = 0.99
    # training begins here
    ann.trainNet(inputT, train)

while True:
    # blink an LED forever
    GPIO.output(19, GPIO.HIGH)
    time.sleep(1)
    GPIO.output(19, GPIO.LOW)
    time.sleep(1)

```

### 试运转

我以与手动测试运行完全相同的方式设置 Pi 相机。训练结束后，LED 开始闪烁，表明系统准备好按下按钮来激活图像捕捉和人工神经网络分析。人工神经网络测试运行的结果如图 [9-20](#Fig20) 所示。

![A436848_1_En_9_Fig20_HTML.jpg](A436848_1_En_9_Fig20_HTML.jpg)

图 9-20。

Automated test run output

最后一个数组元素是数组中的最高值，表明 ANN 将数字识别为 9，这是正确的数字。

这个项目总结了我想给你看的实践演示。你应该把它们作为进一步实验和练习人工神经网络的起点。

## 摘要

本章介绍了两个人工神经网络演示。这些演示展示了训练有素的人工神经网络如何识别手写数字。训练数据集包括来自 MNIST 数据库的 60，000 条记录。

第一次演示使用了 10，000 条测试数据记录，这些记录来自一个独立于 MNIST 培训数据库的数据库。结果表明，三层人工神经网络实现了 94.5%的成功识别率。

第二个演示使用 Pi 摄像头来识别手写数字。Python 脚本将捕获的图像转换为输入数据记录，成功识别了手写数字。

然后演示了一个稍加修改的 Python 脚本版本，它完全自动化了图像识别过程。