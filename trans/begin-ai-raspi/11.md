# 11.基于行为的机器人

基于行为的机器人技术(BBR)是一种控制机器人的方法。它起源于对动物和昆虫行为的研究。本章对这种方法进行了深入探讨。

## 零件目录表

对于第二次演示，您需要表 [11-1](#Tab1) 中列出的零件。

表 11-1。

Parts Lists

<colgroup><col> <col> <col></colgroup> 
| 描述 | 量 | 评论 |
| --- | --- | --- |
| 皮皮匠 | one | 40 引脚版本，可接受 T 型或 DIP 型 |
| 无焊试验板 | one | 300 个插入点，带电源条 |
| 无焊试验板 | one | 300 个插入点 |
| 跳线 | 1 包 |   |
| 超声波传感器 | Two | HC-SR04 标牌 |
| 4.9kω电阻 | Two | 1/4 瓦特 |
| 10kω电阻 | five | 1/4 瓦特 |
| MCP3008 | one | 8 通道 ADC 芯片 |

本章讨论的演示中使用了一个机器人，您可以按照附录中的说明进行制作。零件清单包括基本机器人所需项目之外的所需项目。

BBR 的底层形式结构被称为包容架构。1985 年，麻省理工学院教授罗德尼·布鲁克斯博士写了一份内部技术备忘录，题为“移动机器人的鲁棒分层控制机制”当时，布鲁克斯博士在麻省理工学院的人工智能实验室工作。他的备忘录随后在 1986 年作为论文发表在 IEEE 机器人和自动化杂志上。他的论文改变了多年来机器人研究的性质和方向。这篇论文的主旨描述了一个他称之为包容架构的机器人控制组织。这种架构背后的理论部分基于人类大脑的进化发展。

## 人脑结构

在一个非常广泛的范围内，人脑可以分为三个层次或部分。最低层是最原始的部分，负责基本的生命支持活动，如呼吸、血压、核心温度等。脑干是承载这些原始功能的有机脑部分。图 [11-1](#Fig1) 说明了脑干和边缘系统。

![A436848_1_En_11_Fig1_HTML.jpg](A436848_1_En_11_Fig1_HTML.jpg)

图 11-1。

Brain stem and limbic system

大脑功能的下一个最高水平被称为爬行动物大脑或边缘系统。它负责进食、睡眠、繁殖、逃跑或战斗，以及类似的行为。边缘系统由海马、杏仁核、下丘脑和脑垂体组成。最后，认知水平最高的是新皮层，它负责学习、思考和类似的高级复杂活动。构成新皮层或大脑皮层的大脑组件是额叶、颞叶、枕叶和顶叶。图 [11-2](#Fig2) 展示了组成大脑皮层的四个脑叶。

![A436848_1_En_11_Fig2_HTML.jpg](A436848_1_En_11_Fig2_HTML.jpg)

图 11-2。

Cerebral cortex

最常见的情况是，这些不同的大脑层次彼此独立运作，但它们可能而且经常发生冲突。也许你有“高度紧张”的个性，发现食物是缓解压力的一种受欢迎的消遣。高级功能知道吃太多错误类型的食物对你没有好处，但低级爬行动物大脑仍然渴望它。哪个大脑层面覆盖和改变你的行为是有问题的。有时较低的级别获胜，有时较高的级别获胜。然而，如果你有一种瘾，总是较低的层次获胜并改变你的行为，通常是最坏的情况。任何人都可以在给定时间准备激活许多不同的大脑级行为，但只有一个“胜出”并导致当前活动行为被显示。大脑行为之间的这种相互作用是布鲁克斯博士包容架构的一个来源。

## 包容架构

在讨论的这一点上，包容的定义会有所帮助。然而，真正需要定义的是包容这个词，因为包容被循环定义为包容的行为。包含:将某物纳入一个更广泛的范畴；将某物纳入更大的群体或更高位置的群体

这些定义意味着复杂的行为可以分解成多个更简单的行为。定义中还必须增加另一个视角。这个词是 reactive，因为在现实世界中，机器人依赖传感器根据感官输入做出反应或改变行为。这些输入不断对机器人环境的变化做出反应。反应行为也叫刺激/反应行为，适用于昆虫。与哺乳动物相比，昆虫是一种低级生物，它们没有高度发达的学习能力。它们所拥有的被称为适应，这使得昆虫能够适应某些类型的环境变化。通过对蟑螂吹气可以很容易地看出这一点。昆虫最初从吹来的空气中撤退。然而，反复向蟑螂吹气会导致它忽视空气，因为它被认为是无生命危险的。这种类型的低级学习对于机器人是有用的，尤其是自主机器人。

图 [11-3](#Fig3) 显示了反应式系统的传统方法。

![A436848_1_En_11_Fig3_HTML.jpg](A436848_1_En_11_Fig3_HTML.jpg)

图 11-3。

Flowchart for a sensor-based system

从传感器到行动的一系列过程的集合，可以被认为是一种行为。这种串行流程或任务的布局缓慢且相对不灵活。传感器获取数据，而不试图以任何方式处理它。这项工作留给了感知模块，感知模块必须在将所有相关的感官数据传递给模型模块之前对其进行分类。模型块将过滤后的数据转换成上下文意义或状态。计划块具有基于它从模型块接收的状态而遵循的规则。最后，动作块执行从计划块接收的适当规则，并向致动器发送所需的控制信号，如图中最后一个块所示。在串行架构中拥有所有这些模块会导致响应缓慢，这不是一个好的机器人属性。

图中所示的串行块代表了一个复杂的行为，可以用一个层来表示。行为意义上的层可以被认为是代理或机器人要实现的目标。

复杂的行为可以分解成更简单的行为。这是包容架构的关键。图 [11-4](#Fig4) 显示的是两层分解，而不是图 [11-3](#Fig3) 中显示的复杂的单层行为流。

![A436848_1_En_11_Fig4_HTML.jpg](A436848_1_En_11_Fig4_HTML.jpg)

图 11-4。

Two-layer behavior serial stream

每一层或每一条路径都被认为与特定的任务相关，例如沿着墙走或探测障碍物。这是布鲁克斯博士提出的包容架构。请注意，有一个额外的仲裁器模块，它在将选定的信号发送到执行器之前处理所有的动作模块信号。这个仲裁块是包容架构中的另一个重要元素。

通过将一个单一的、复杂的行为转换成多个并行的路径，系统可以变得更加灵敏。很容易想象，在不干扰任何现有层的情况下，可以添加更多的层。在不修改现有代码的情况下扩展代码的特性非常类似于前面章节中讨论的软件组合原则。能够扩展现有代码而不会对现有代码造成太多“干扰”总是一件好事。

包容架构没有提供任何关于如何将复杂行为分解成更简单的多任务的指导。此外，感知模块通常被认为是所有模块中最难定义和实现的。问题是从有限数量的环境传感器中创建一个有意义的数据集。然后，该数据集被馈送给模型块，该模型块有效地创建了机器人的世界或状态。在这一点上，BBR 与更传统的方法有很大的不同。我首先讨论传统方法，然后是 BBR 方法。

### 传统方法

在传统方法中，模型块存储机器人在其中操作的真实世界的完整和精确的模型。这可以通过多种方式实现，但通常需要某种类型的几何坐标系，以便移动机器人建立当前状态并预测未来状态。为了精确地确定状态，传感器数据必须是校准的和准确的。基于传感器数据集存储或计算理想状态信息。与理想状态的偏差是传递到计划块的误差，以便可以采取适当的控制措施来最小化这些误差。控制器或致动器也必须精确和准确，以确保正确的运动严格符合由计划和动作块产生的命令。

传统的方法通常需要大量的计算机内存来存储或计算必要的状态信息。它比 BBR 方法慢，这反过来又使机器人反应迟钝。

### 基于行为的机器人方法

在讨论 BBR 之前，有必要跑题一下。在动物行为的研究中，也被称为动物行为学，已经表明幼年海鸥对父母模型有反应。图 [11-5](#Fig5) 显示了这样一个亲本模型，图中圈出了一个特征，这个特征会触发幼鸥的本能摄食行为。

![A436848_1_En_11_Fig5_HTML.jpg](A436848_1_En_11_Fig5_HTML.jpg)

图 11-5。

Seagull ethology

对幼鸥来说，重要的是亲鸥模型有一个尖尖的喙，喙尖附近有一个彩色斑点。宝宝们张开嘴等待食物。这些幼年海鸥使用非常有限的真实世界表示法，但是已经证明这对于海鸥物种的生存是完全足够的。

类似地，真实世界的机器人可以使用有限的真实世界表示或模型，因此它应该足以执行期望的要求，而不依赖于过于详细的世界模型。

这些有限的表示通常被称为本地环境的“快照”。然后设计行为来对这些快照做出反应。其中两个要点是，移动机器人不需要维护几何坐标系，并且它不需要有一个充满内存的真实世界模型。通过利用类似反射的直接反应，移动机器人将模型、计划和动作块的复杂性降至最低。行为流几乎还原成一个简单的行为图，如图 [11-6](#Fig6) 所示。

![A436848_1_En_11_Fig6_HTML.jpg](A436848_1_En_11_Fig6_HTML.jpg)

图 11-6。

Simple behavioral stream

环境快照如何与机器人行为相关联？最初，必须创建一个数据集，该数据集由环境条件存在时生成的传感器数据组成，这将触发所需的机器人反射行为。这些被称为传感器信号。现在需要做的就是使用解释例程将签名与特定行为联系起来，这通常在预测块中完成。然而，可能会有一个问题，即给定相对粗粒度的传感器数据签名，可能会发生同时的刺激/响应配对。为简单行为分配优先级可以缓解这种情况。此外，默认或长期行为通常被赋予比紧急或“战术”行为更低的优先级。如果机器人遇到需要机器人控制系统立即关注的环境条件，就会出现战术信号。

制定一个行为优先计划会产生意想不到的积极结果。机器人通常以相同的行为操作，例如向前移动。所有按顺序行动的行为都应该努力保持这种常态。只有在环境条件允许的情况下，机器人的行为才应该偏离常规。当偏差发生时，更高优先级的行为会控制并试图恢复正常。

BBR 还结合了长期进展指标，以帮助避免“循环”情况，例如机器人在两个障碍之间不断跳跃或被锁在墙角的情况。这些长期进度指示器有效地生成了机器人在大致方向或路径上移动的战略轨迹。当进展受阻时，选择一组不同的行为来返回正常状态。

在分层包容模型中，低层次的目标可能是“避开障碍”这一层可能在更高层次的“漫游”之下据说较高层次的“四处漫游”包含了较低层次的“避开障碍物”行为所有层都可以使用传感器来检测环境变化，以及控制执行器的能力。一个总的限制是独立的任务具有抑制任何输入和禁止输出发送到致动器的能力。通过这种方式，最低水平可以对环境变化做出非常敏感的反应，就像生物体内的反射功能一样。更高的层次更抽象，致力于满足目标。

以下行为可以用各种图形或数学模型来表示:

*   函数记号
*   刺激/反应图
*   有限状态机
*   计划

我使用 FSM 模型，因为它提供了行为交互的良好表示，而没有太多的数学抽象。一个基本的有限状态机模型如图 [11-7](#Fig7) 所示。

![A436848_1_En_11_Fig7_HTML.jpg](A436848_1_En_11_Fig7_HTML.jpg)

图 11-7。

Basic FSM model

图 [11-8](#Fig8) 显示了具有相互关系的多种行为，包括感觉抑制和执行器抑制。请注意前面讨论的分层行为序列和行为优先级。

![A436848_1_En_11_Fig8_HTML.jpg](A436848_1_En_11_Fig8_HTML.jpg)

图 11-8。

Multilayered FSM model

在讨论的这一点上，我通常会继续向您展示运行在 Raspberry Pi 上的包容架构的 Python 实现。然而，接下来，我将偏离主题，讨论一个非常好的机器人模拟项目，它可以实现包容和更多功能。

## 演示 11-1:勇敢的项目

breve 项目是 Jon Klein 的工作，他将其作为本科和研究生论文工作的一部分。它可以从乔恩的网站 [`www.spiderland.org`](http://www.spiderland.org) 获得，适用于 Windows、Linux 和 Mac 平台。我在 MacBook Pro 上使用它，它似乎表现得非常完美。请注意，Jon 在他的网站上声明他不再主动更新应用程序，而是继续提供应用程序，至少以 Mac 格式提供。

以下是 Jon 自己的话来描述 breve:“breve 是一个免费的开源软件包，它可以轻松地构建多智能体系统和人工生命的 3D 模拟。使用 Python，或者使用一种叫做 steve 的简单脚本语言，你可以定义 3D 世界中代理的行为，并观察他们如何交互。breve 包括物理模拟和碰撞检测，因此您可以模拟现实的生物。它还有一个 OpenGL 显示引擎，所以你可以可视化你的模拟世界。”

网站上有大量 HTML 格式的文档，我强烈建议您查看；尤其是介绍如何运行众多可用演示脚本之一的介绍性页面。这些脚本都是“史蒂夫”前端语言以及 Python。对我来说，浏览许多文档页是不可能的，这些文档页本身就构成了一整本书。我确实在 breve 中运行了以下名为 RangerImage.py 的 Python 脚本。这里显示的清单提供了使用 breve 的强大功能和灵活性。

```
import breve

class AggressorController( breve.BraitenbergControl ):
    def __init__( self ):
        breve.BraitenbergControl.__init__( self )
        self.depth = None
        self.frameCount = 0
        self.leftSensor = None
        self.leftWheel = None
        self.n = 0
        self.rightSensor = None
        self.rightWheel = None
        self.simSpeed = 0
        self.startTime = 0
        self.vehicle = None
        self.video = None
        AggressorController.init( self )

    def init( self ):
        self.n = 0
        while ( self.n < 10 ):
            breve.createInstances( breve.BraitenbergLight, 1 ).move( breve.vector( ( 20 * breve.breveInternalFunctionFinder.sin( self, ( ( self.n * 6.280000 ) / 10 ) ) ), 1, ( 20 * breve.breveInternalFunctionFinder.cos( self, ( ( self.n * 6.280000 ) / 10 ) ) ) ) )
            self.n = ( self.n + 1 )

        self.vehicle = breve.createInstances( breve.BraitenbergVehicle, 1 )
        self.watch( self.vehicle )
        self.vehicle.move( breve.vector( 0, 2, 18 ) )
        self.leftWheel = self.vehicle.addWheel( breve.vector( -0.500000, 0, -1.500000 ) )
        self.rightWheel = self.vehicle.addWheel( breve.vector( -0.500000, 0, 1.500000 ) )
        self.leftWheel.setNaturalVelocity( 0.000000 )
        self.rightWheel.setNaturalVelocity( 0.000000 )
        self.rightSensor = self.vehicle.addSensor( breve.vector( 2.000000, 0.400000, 1.500000 ) )
        self.leftSensor = self.vehicle.addSensor( breve.vector( 2.000000, 0.400000, -1.500000 ) )
        self.leftSensor.link( self.rightWheel )
        self.rightSensor.link( self.leftWheel )
        self.leftSensor.setBias( 15.000000 )
        self.rightSensor.setBias( 15.000000 )
        self.video = breve.createInstances( breve.Image, 1 )
        self.video.setSize( 176, 144 )
        self.depth = breve.createInstances( breve.Image, 1 )
        self.depth.setSize( 176, 144 )
        self.startTime = self.getRealTime()

    def postIterate( self ):
        self.frameCount = ( self.frameCount + 1 )
        self.simSpeed = (self.getTime()/(self.getRealTime()- self.startTime))
        print '''Simulation speed = %s''' % (  self.simSpeed )
        self.video.readPixels( 0, 0 )
        self.depth.readDepth( 0, 0, 1, 50 )
        if ( self.frameCount < 10 ):
            self.video.write( '''imgs/video-%s.png''' % (self.frameCount))

        self.depth.write16BitGrayscale('''imgs/depth-%s.png''' % (self.frameCount))

breve.AggressorController = AggressorController

# Create an instance of our controller object to initialize the simulation
AggressorController()

```

图 [11-9](#Fig9) 显示了 breve 显示器中运行的实际机器人，它是由前面的脚本创建的。

![A436848_1_En_11_Fig9_HTML.jpg](A436848_1_En_11_Fig9_HTML.jpg)

图 11-9。

breve world

您可能已经注意到脚本中引用了 BraitenbergControl、BraitenbergLight 和 BraitenbergLight。这些是基于由[意大利](https://en.wikipedia.org/wiki/Italy#Italy) - [奥地利](https://en.wikipedia.org/wiki/Austria#Austria)控制论专家 [Valentino Braitenberg](https://en.wikipedia.org/wiki/Valentino_Braitenberg#Valentino%20Braitenberg) 进行的[思维实验](https://en.wikipedia.org/wiki/Thought_experiment#Thought%20experiment)，他写了《交通工具:合成心理学实验》(麻省理工学院出版社，1984 年)，我强烈推荐给渴望了解他的机器人创新方法的读者。在他的实验中，他设想了由传感器直接控制的车辆。由此产生的行为可能看起来很复杂，甚至是智能的，但实际上，它是基于简单行为的组合。这应该会提醒你工作中的包容。

Braitenberg 车辆可以被认为是一个基于自己的感官输入自主移动的智能体。在这些思想实验中，传感器是原始的，只是简单地测量一个刺激，它通常只是一个点光源。传感器还直接连接到马达致动器，使得传感器可以在受到刺激时立即启动马达。同样，这应该让你想起图 [11-4](#Fig4) 中所示的简单行为流。

最终的 Braitenberg 车辆行为取决于传感器和电机的连接方式。在图 [11-10](#Fig10) 中，传感器和电机之间有两种不同的配置。左边的车辆是有线的，因此它避开或远离光源。这与右边的车辆形成对比，右边的车辆朝着光源行驶。

![A436848_1_En_11_Fig10_HTML.jpg](A436848_1_En_11_Fig10_HTML.jpg)

图 11-10。

Braitenberg vehicles

说左边的车辆“怕”光，而右边的车辆“喜欢”光，并不过分。我给机器人分配了类似人类的行为，这正是布莱特伯格所寻求的结果。

另一辆 Braitenberg 车辆有一个光传感器，其行为如下:

*   更多的光产生更快的运动。
*   光线越弱，运动越慢。
*   黑暗产生停滞。

这种行为可以解释为机器人害怕光线，并快速移动以避开光线。它的目标是找到一个黑暗的地方藏身。

当然，补充的 Braitenberg 车辆具有这些特性:

*   越暗，移动越快。
*   越暗，移动越慢。
*   全光产生静止。

在这种情况下，该行为可以解释为机器人正在寻找光线并快速移动以到达光线。它的目标是找到最亮的地方停车。

Braitenberg 车辆在具有多个激励源的复杂环境中表现出复杂的动态行为。根据传感器和致动器之间的配置，Braitenberg 车辆可能会靠近声源，但不会接触到它，快速跑开，或绕着一个点转圈或 8 字形。图 [11-11](#Fig11) 展示了这些复杂的行为。

![A436848_1_En_11_Fig11_HTML.jpg](A436848_1_En_11_Fig11_HTML.jpg)

图 11-11。

Braitenberg vehicles with complex behaviors

这些行为似乎是目标导向的、适应性的，甚至是智能的，就像蟑螂的行为被认为是智力低下一样。但事实是，这个代理完全以机械的方式运作，没有任何认知或推理过程在起作用。

在 breve Python 示例中，我想进一步解释几个项目，为您创建自己的 Braitenberg 车辆的分步示例做准备。要注意的第一点是，所有 breve 模拟都需要一个控制器对象，它指定如何设置模拟。在这个模拟中，控制器的名称是 AggressorController。在控制器定义中，至少有一个名为`init`的初始化方法。在这个具体的例子中，因为这是一个 Python 脚本，所以有另一个名为`__init__`的初始化方法。实例化 breve 对象时调用第一个初始化方法。第二个初始化方法是在实例化 Python 对象时自动调用的。breve 使用称为桥的第三个对象来处理 breve 和 Python 对象之间的关系。您通常不必关心这些桥对象。事实上，如果你只使用 steve 脚本语言(而不是 Python)，你永远看不到桥对象。

方法`init`创建了 10 个 Braitenberg 灯光对象，其中一些你可以在图 [11-7](#Fig7) 中看到。它们是围绕布莱恩特伯格机器人的名为`'n'`的球体，它也是由`init`方法创建的，被称为`vehicle`。

`__init__`方法创建模拟所需的所有属性，然后它调用`init`方法，该方法实例化所有所需的模拟对象并为属性分配实值。完成后，只需单击“播放”按钮观看模拟。

逐步演示从这里开始。以下列表创建了一辆不起作用的 Braitenberg 车辆和一个光源:

```
import breve
class Controller(breve.BraitenbergControl):
    def __init__(self):
        breve.BraitenbergControl.__init__(self)
        self.vehicle = None
        self.leftSensor = None
        self.rightSensor = None
        self.leftWheel = None
        self.rightWheel = None
        self.simSpeed = 0
        self.light = None
        Controller.init(self)

    def init(self):
        self.light = breve.createInstances(breve.BraitenbergLight, 1)
        self.light.move(breve.vector(10, 1, 0))
        self.vehicle = breve.createInstances(breve.BraitenbergVehicle, 1)
        self.watch(self.vehicle)

    def iterate(self):
        breve.BraitenbergControl.iterate(self)

breve.Controller = Controller
Controller()

```

我将这个脚本命名为 firstVehicle.py，以表明它是开发工作模拟过程中生成的几个脚本中的第一个。图 [11-12](#Fig12) 显示了我在 breve 应用程序中加载并“播放”这个脚本后的结果。

![A436848_1_En_11_Fig12_HTML.jpg](A436848_1_En_11_Fig12_HTML.jpg)

图 11-12。

breve world for the firstVehicle script

这个脚本定义了一个`Controller`类，它有前面提到的两种初始化方法。`init`方法实例化一个 Braitenberg 灯光对象和一个 Braitenberg 车辆。`__init__`方法创建一个属性列表，由后续脚本填充。这个方法也调用了`init`方法。

还有一种叫做`iterate`的新方法，它只是让模拟连续运行。

开发脚本的下一步是给车辆添加传感器和车轮，使其能够穿越并探索布雷夫世界。以下语句添加车轮并设置初始速度，使车辆绕圈转弯。这些语句进入`init`方法。

```
self.vehicle.move(breve.vector(0, 2, 18))
self.leftWheel = self.vehicle.addWheel(breve.vector(-0.500000,0,-1.500000))
self.rightWheel = self.vehicle.addWheel( breve.vector(-0.500000,0,1.500000))
self.leftWheel.setNaturalVelocity(0.500000)
self.rightWheel.setNaturalVelocity(1.000000)

```

下一组语句添加了传感器。这些也被添加到`init`方法中。传感器也在车轮之间交叉连接(即右传感器控制左车轮，反之亦然)。`setBias`方法设置传感器对其链接车轮的影响量。默认值为 1，这意味着传感器对车轮有轻微的积极影响。值为 15 表示传感器对车轮有非常积极的影响。偏差也可以是负的，这意味着影响与车轮激活直接相反。

```
self.rightSensor = self.vehicle.addSensor(breve.vector(2.000000, 0.400000, 1.500000))
self.leftSensor = self.vehicle.addSensor( breve.vector(2.000000, 0.400000, -1.500000 ) )
self.leftSensor.link(self.rightWheel)
self.rightSensor.link(self.leftWheel)
self.leftSensor.setBias(15.000000)
self.rightSensor.setBias(15.000000)

```

前面几组语句被添加到了`init`方法中。整个脚本名称被更改为 secondVehicle.py。传感器被设计为对任何光源都有天然的亲和力。然而，如果传感器没有检测到任何光源，它们将不会激活它们各自链接的轮子。在这个脚本配置中，传感器不会立即检测到光源，车辆只是保持静止，这就是我为每个车轮设置初始自然速度的原因。这些设置保证机器人会移动。它可能不会朝着光源的方向移动，但它会移动。图 [11-13](#Fig13) 显示了升级版的 breve world 和升级版的车辆。

![A436848_1_En_11_Fig13_HTML.jpg](A436848_1_En_11_Fig13_HTML.jpg)

图 11-13。

Breve world for the secondVehicle script

在这个阶段，模拟正在工作，但它有点沉闷，因为车辆除了在 breve 世界中转圈之外没有任何目的，也许是为了瞥见孤独的光源。是时候给车辆一个更好的目标来实现模拟背后的基本原理了。我的目标非常简单，因为这是一个“hello world”类型的演示，其目的是阐明而不是模糊 breve 模拟的工作原理。目标是让车辆寻找一些光源，并简单地“穿过”它们。

这些额外的 Braitenberg 光源由添加到`init`方法中的以下循环生成。

```
self.n = 0
    while (self.n < 10):
        breve.createInstances( breve.BraitenbergLight, 1).move( breve.vector((20 * breve.breveInternalFunctionFinder.sin(self, ((self.n * 6.280000) / 10))), 1,(20 * breve.breveInternalFunctionFinder. cos(self, ((self.n * 6.280000 ) / 10)))))
        self.n = ( self.n + 1 )

```

我还注释掉了在初始脚本中创建的单个光源。此外，我将自然速度重置回 0.0，因为现在有足够数量的光源可供车辆传感器检测。图 [11-14](#Fig14) 显示了更新的 breve 世界，带有一些额外的光源和穿过它们的车辆。新脚本被重命名为 thirdVehicle.py。

![A436848_1_En_11_Fig14_HTML.jpg](A436848_1_En_11_Fig14_HTML.jpg)

图 11-14。

breve world for the thirdVehicle script

这最后一个脚本完成了我关于如何使用 Python 在 breve 环境中创建机器人模拟的介绍性课程。这一课只是触及了 breve 必须提供的东西的表面——不仅仅是在机器人模拟中，而是在其他一系列人工智能应用中。看图 [11-15](#Fig15) 看你认不认得。

![A436848_1_En_11_Fig15_HTML.jpg](A436848_1_En_11_Fig15_HTML.jpg)

图 11-15。

breve snapshot

这是康威在布雷夫运行的生命游戏的快照。这个脚本被命名为 PatchLife.py。它在演示菜单选项中有 Python 和 steve 两种格式。事实上，大多数演示都有两种格式。有许多演示可供您尝试，包括以下内容:

*   布莱特伯格:车辆，灯光
*   化学:格雷斯科特扩散，超循环
*   DLA:扩散限制侵略(分形增长)
*   遗传学:2D 和 3D 的生命游戏
*   音乐:播放 midi 和 wav 文件
*   神经网络:多层
*   物理:弹簧，关节，步行者
*   群集:群集的机器人和其他生命形式
*   地形:机器人，探索地形特征的生物

现在是时候结束简短的讨论，回归包容了。

## 演示 11-2:建造一辆包容控制的机器人汽车

本节的目的是描述如何编写一个树莓 Pi 来直接控制机器人汽车。机器人汽车与第 7 章中使用的平台相同，但现在使用包容架构来控制汽车的行为。Python 是包容类和脚本的实现语言。

在搜索了 GitHub 之后，我受到了 Alexander Svenden 的《EV3 邮报》的启发，他使用 Python 实现了一个通用的包容结构。我还依赖于我用 leJOS 开发包容 Java 类的经验。你可以在 [`www.lejos.org`](http://www.lejos.org) 阅读更多关于这些 Java 类的内容。需要两个主要的类:一个名为`Behavior`的抽象类，另一个名为`Controller`。`Behavior`类使用以下方法封装汽车的行为:

*   `takeControl()`:返回一个布尔值，表明行为是否应该控制。
*   `action()`:实现汽车所做的具体行为。
*   `suppress()`:使动作行为立即停止，然后将汽车状态返回到下一个行为可以控制的状态。

```
import RPi.GPIO as GPIO
import time
class Behavior(self):
    global pwmL, pwmR

    # use the BCM pin numbers
    GPIO.setmode(GPIO.BCM)

    # setup the motor control pins
    GPIO.setup(18, GPIO.OUT)
    GPIO.setup(19, GPIO.OUT)

    pwmL = GPIO.PWM(18,20) # pin 18 is left wheel pwm
    pwmR = GPIO.PWM(19,20) # pin 19 is right wheel pwm

    # must 'start' the motors with 0 rotation speeds
    pwmL.start(2.8)
    pwmR.start(2.8)

```

`Controller`类包含主要的包容逻辑，它根据优先级和激活需求来决定哪些行为是活动的。以下是该类中的一些方法:

*   `__init__()`:初始化`Controller`对象。
*   `add()`:将行为添加到可用行为列表中。它们的添加顺序决定了行为的优先级。
*   `remove()`:从可用行为列表中删除一个行为。如果下一个最高行为覆盖了任何正在运行的行为，则停止该行为。
*   `update()`:停止旧行为，运行新行为。
*   `step()`:找到下一个活动行为并运行它。
*   `find_next_active_behavior()`:寻找下一个想要激活的行为。
*   `find_and_set_new_active_behavior()`:找到下一个想要激活的行为并激活它。
*   `start()`:运行选择的动作方法。
*   `stop()`:停止当前动作。
*   `continously_find_new_active_behavior()`:实时监控想要活跃的新行为。
*   `__str__()`:返回当前行为的名称。

`Controller`对象也起调度程序的作用，一次一个行为是活动的。主动行为由传感器数据及其优先级决定。当具有更高优先级的行为发出它想要运行的信号时，任何旧的活动行为被抑制。

有两种方法可以使用`Controller`类。第一种方法是通过调用`start()`方法让类自己处理调度程序。另一种方法是通过调用`step()`方法来强制启动调度程序。

```
import threading
class Controller():

    def __init__(self):
        self.behaviors = []
        self.wait_object = threading.Event()
        self.active_behavior_index = None

        self.running = True
        #self.return_when_no_action = return_when_no_action

        #self.callback = lambda x: 0

    def add(self, behavior):
        self.behaviors.append(behavior)

    def remove(self, index):
        old_behavior = self.behaviors[index]
        del self.behaviors[index]
        if self.active_behavior_index == index:  # stop the old one if the new one overrides it
            old_behavior.suppress()
            self.active_behavior_index = None

    def update(self, behavior, index):
        old_behavior = self.behaviors[index]
        self.behaviors[index] = behavior
        if self.active_behavior_index == index:  # stop the old one if the new one overrides it
            old_behavior.suppress()

    def step(self):
        behavior = self.find_next_active_behavior()
        if behavior is not None:
            self.behaviors[behavior].action()
            return True
        return False

    def find_next_active_behavior(self):
        for priority, behavior in enumerate(self.behaviors):
            active = behavior.takeControl()
            if active == True:
                activeIndex = priority
        return activeIndex

    def find_and_set_new_active_behavior(self):
        new_behavior_priority = self.find_next_active_behavior()
        if self.active_behavior_index is None or self.active_behavior_index > new_behavior_priority:
            if self.active_behavior_index is not None:
                self.behaviors[self.active_behavior_index].suppress()
            self.active_behavior_index = new_behavior_priority

    def start(self):  # run the action methods
        self.running = True
        self.find_and_set_new_active_behavior()  # force it once
        thread = threading.Thread(name="Continuous behavior checker",
                                target=self.continuously_find_new_active_behavior, args=())
        thread.daemon = True
        thread.start()

        while self.running:
            if self.active_behavior_index is not None:
                running_behavior = self.active_behavior_index
                self.behaviors[running_behavior].action()

                if running_behavior == self.active_behavior_index:
                    self.active_behavior_index = None
                    self.find_and_set_new_active_behavior()
            self.running = False

    def stop(self):
        self._running = False
        self.behaviors[self.active_behavior_index].suppress()

    def continuously_find_new_active_behavior(self):
        while self.running:
            self.find_and_set_new_active_behavior()

    def __str__(self):
        return str(self.behaviors)

```

`Controller`类非常通用，允许使用通用方法实现各种各样的行为。`takeControl()`方法允许一个行为发出希望控制机器人的信号。它的工作方式将在后面讨论。`action()`方法是一种行为开始控制机器人的方式。如果传感器检测到阻碍机器人路径的障碍物，避障行为启动其`action()`方法。高优先级行为使用`suppress()`方法来停止或抑制低优先级行为的`action()`方法。当避障行为通过抑制向前行为的`action()`方法并激活其自身的`action()`方法来接管正常的向前运动行为时，就会发生这种情况。

`Controller`类需要一个包含机器人整体行为的`Behavior`对象的列表或数组。一个`Controller`实例从`Behavior`数组中最高的数组索引开始，并检查`takeControl()`方法的返回值。如果为真，它调用该行为的`action()`方法。如果为假，`Controller`检查下一个`Behavior`对象的`takeControl()`方法返回值。通过分配附加到每个`Behavior`对象的索引数组值来确定优先级。当较低优先级的`action()`方法被激活时，如果较高优先级的行为断言了`takeControl()`方法，则`Controller`类继续重新扫描所有的`Behavior`对象并抑制较低优先级的行为。图 [11-16](#Fig16) 显示了最终添加的所有行为的流程。

![A436848_1_En_11_Fig16_HTML.jpg](A436848_1_En_11_Fig16_HTML.jpg)

图 11-16。

Behavior state diagram

现在是时候创建一个相对简单的基于行为的机器人示例了。

## 演示 11-3: Alfie Robot Car

目标机器人是阿尔菲，这是前几章用过的。正常或低优先级行为是向前行驶。更高优先级的行为是避障，它使用超声波传感器来检测机器人直接路径中的障碍。避障行为是停车，倒车，向右转 90 度。

下面这个类命名为`NormalBehavior`。它强化了分层行为方法。这个类拥有所有必需的`Behavior`方法实现。

```
class NormalBehavior(Behavior):
    def takeControl():
        return true
    def action():
        # drive forward
        pwmL.ChangeDutyCycle(3.6)
        pwmR.ChangeDutyCycle(2.2)
    def suppress():
        # all stop
        pwmL.ChangeDutyCycle(2.6)
        pwmR.ChangeDutyCycle(2.6)

```

`takeControl()`方法应该总是返回逻辑值 true。更高优先级的行为总是被允许由`Controller`类控制；如果这个较低的优先级请求控制，这真的无关紧要。

`action()`方法非常简单:使用全功率设置正向驱动电机。

`suppress()`方法也很简单:停止两个电机。

然而，避障行为有点复杂。它仍然实现了在`Behavior`接口中指定的三个方法。我将这个类命名为`AvoidObstacle`来表示它的基本行为。

```
class AvoidObstacle(Behavior):
global distance1, distance2
    def takeControl():
        if distance1 <= 25.4 or distance2 <= 25.4:
            return True
        else:
            return False

    def action():
        # drive backward
        pwmL.ChangeDutyCycle(2.2)
        pwmR.ChangeDutyCycle(3.6)
        time.sleep(1.5)
        # turn right
        pwmL.ChangeDutyCycle(3.6)
        pwmR.ChangeDutyCycle(2.6)
        time.sleep(0.3)
        # stop
        pwmL.ChangeDutyCycle(2.6)
        pwmR.ChangeDutyCycle(2.6)

    def suppress():
        # all stop
        pwmL.ChangeDutyCycle(2.6)
        pwmR.ChangeDutyCycle(2.6)

```

关于这个类有几个项目需要指出。只有当超声波传感器和障碍物之间的距离小于或等于 10 英寸时,`takeControl()`方法才返回逻辑真。在没有断言真值的情况下，这种行为永远不会被激活。

`action()`方法使机器人后退 1.5 秒，如`time.sleep(1.5)`语句所示。机器人接下来在停止右电机并允许左电机继续运行的基础上旋转 0.3 秒。机器人然后停止等待下一个行为被激活。

`suspense()`方法简单地停止两个电机，因为没有其他关于暂停避障的明显行为意图。

下一步是创建一个名为`testBBR`的测试类，它实例化了前面定义的所有类，以及一个`Controller`对象。注意，我还在这个清单中添加了`StopRobot`类，这将在下面讨论。我这样做是为了避免又一个冗长的代码清单。下面的清单被命名为 homoption . py:

```
import RPi.GPIO as GPIO
import time
import threading
import numpy as np

# next two libraries must be installed IAW appendix instructions
import Adafruit_GPIO.SPI as SPI
import Adafruit_MCP3008

class Behavior():
    global pwmL, pwmR, distance1, distance2

    # use the BCM pin numbers
    GPIO.setmode(GPIO.BCM)

    # setup the motor control pins
    GPIO.setup(18, GPIO.OUT)
    GPIO.setup(19, GPIO.OUT)

    pwmL = GPIO.PWM(18,20) # pin 18 is left wheel pwm
    pwmR = GPIO.PWM(19,20) # pin 19 is right wheel pwm

    # must 'start' the motors with 0 rotation speeds
    pwmL.start(2.8)
    pwmR.start(2.8)

class Controller():

    def __init__(self):
        self.behaviors = []
        self.wait_object = threading.Event()
        self.active_behavior_index = None

        self.running = True
        #self.return_when_no_action = return_when_no_action

        #self.callback = lambda x: 0

    def add(self, behavior):
        self.behaviors.append(behavior)

    def remove(self, index):
        old_behavior = self.behaviors[index]
        del self.behaviors[index]
        if self.active_behavior_index == index:  # stop the old one if the new one overrides it
            old_behavior.suppress()
            self.active_behavior_index = None

    def update(self, behavior, index):
        old_behavior = self.behaviors[index]
        self.behaviors[index] = behavior
        if self.active_behavior_index == index:  # stop the old one if the new one overrides it
            old_behavior.suppress()

    def step(self):
        behavior = self.find_next_active_behavior()
        if behavior is not None:
            self.behaviors[behavior].action()
            return True
        return False

    def find_next_active_behavior(self):
        for priority, behavior in enumerate(self.behaviors):
            active = behavior.takeControl()
            if active == True:
                activeIndex = priority
        return activeIndex

    def find_and_set_new_active_behavior(self):
        new_behavior_priority = self.find_next_active_behavior()
        if self.active_behavior_index is None or self.active_behavior_index > new_behavior_priority:
            if self.active_behavior_index is not None:
                self.behaviors[self.active_behavior_index].suppress()
            self.active_behavior_index = new_behavior_priority

    def start(self):  # run the action methods
        self.running = True
        self.find_and_set_new_active_behavior()  # force it once
        thread = threading.Thread(name="Continuous behavior checker",
                                  target=self.continuously_find_new_active_behavior, args=())
        thread.daemon = True
        thread.start()

        while self.running:
            if self.active_behavior_index is not None:
                running_behavior = self.active_behavior_index
                self.behaviors[running_behavior].action()

                if running_behavior == self.active_behavior_index:
                    self.active_behavior_index = None
                    self.find_and_set_new_active_behavior()
            self.running = False

    def stop(self):
        self._running = False
        self.behaviors[self.active_behavior_index].suppress()

    def continuously_find_new_active_behavior(self):
        while self.running:
            self.find_and_set_new_active_behavior()

    def __str__(self):
        return str(self.behaviors)

class NormalBehavior(Behavior):

    def takeControl(self):
        return True

    def action(self):
        # drive forward
        pwmL.ChangeDutyCycle(3.6)
        pwmR.ChangeDutyCycle(2.2)

    def suppress(self):
        # all stop
        pwmL.ChangeDutyCycle(2.6)
        pwmR.ChangeDutyCycle(2.6)

class AvoidObstacle(Behavior):

    def takeControl(self):
        #self.distance1 = distance1
        #self.distance2 = distance2
        if self.distance1 <= 25.4 or self.distance2 <= 25.4:
            return True
        else:
            return False

    def action(self):
        # drive backward
        pwmL.ChangeDutyCycle(2.2)
        pwmR.ChangeDutyCycle(3.6)
        time.sleep(1.5)
        # turn right
        pwmL.ChangeDutyCycle(3.6)
        pwmR.ChangeDutyCycle(2.6)
        time.sleep(0.3)
        # stop
        pwmL.ChangeDutyCycle(2.6)
        pwmR.ChangeDutyCycle(2.6)

    def suppress(self):
        # all stop
        pwmL.ChangeDutyCycle(2.6)
        pwmR.ChangeDutyCycle(2.6)

    def setDistances(self, dest1, dest2):
        self.distance1 = dest1
        self.distance2 = dest2

class StopRobot(Behavior):

    critical_voltage = 6.0

    def takeControl(self):
        if self.voltage < critical_voltage:
            return True
        else:
            return False

    def action(self):
        # all stop
        pwmL.ChangeDutyCycle(2.6)
        pwmR.ChangeDutyCycle(2.6)

    def suppress(self):
        # all stop
        pwmL.ChangeDutyCycle(2.6)
        pwmR.ChangeDutyCycle(2.6)

    def setVoltage(self, volts):
        self.voltage = volts

# the test class
class testBBR():

    def __init__(self):

        # instantiate objects
        self.nb = NormalBehavior()
        self.oa = AvoidObstacle()
        self.control = Controller()

        # setup the behaviors array by priority; last-in = highest
        self.control.add(self.nb)
        self.control.add(self.oa)

        # initialize distances
        distance1 = 50
        distance2 = 50
        self.oa.setDistances(distance1, distance2)

        # activate the behaviors
        self.control.start()

        threshold = 25.4 #10 inches

        # use the BCM pin numbers
        GPIO.setmode(GPIO.BCM)

        # ultrasonic sensor pins
        self.TRIG1 = 23 # an output
        self.ECHO1 = 24 # an input
        self.TRIG2 = 25 # an output
        self.ECHO2 = 27 # an input

        # set the output pins
        GPIO.setup(self.TRIG1, GPIO.OUT)
        GPIO.setup(self.TRIG2, GPIO.OUT)

        # set the input pins
        GPIO.setup(self.ECHO1, GPIO.IN)
        GPIO.setup(self.ECHO2, GPIO.IN)

        # initialize sensors
        GPIO.output(self.TRIG1, GPIO.LOW)
        GPIO.output(self.TRIG2, GPIO.LOW)
        time.sleep(1)

        # Hardware SPI configuration:
        SPI_PORT   =  0
        SPI_DEVICE = 0
        self.mcp = Adafruit_MCP3008.MCP3008(spi=SPI.SpiDev(SPI_PORT, SPI_DEVICE))

    def run(self):
        # forever loop
        while True:
            # sensor 1 reading
            GPIO.output(self.TRIG1, GPIO.HIGH)
            time.sleep(0.000010)
            GPIO.output(self.TRIG1, GPIO.LOW)

            # detects the time duration for the echo pulse
            while GPIO.input(self.ECHO1) == 0:
                pulse_start = time.time()

            while GPIO.input(self.ECHO1) == 1:
                pulse_end = time.time()

            pulse_duration = pulse_end - pulse_start

            # distance calculation
            distance1 = pulse_duration * 17150

            # round distance to two decimal points
            distance1 = round(distance1, 2)

            time.sleep(0.1) # ensure that sensor 1 is quiet

            # sensor 2 reading
            GPIO.output(self.TRIG2, GPIO.HIGH)
            time.sleep(0.000010)
            GPIO.output(self.TRIG2, GPIO.LOW)

            # detects the time duration for the echo pulse
            while GPIO.input(self.ECHO2) == 0:
                pulse_start = time.time()

            while GPIO.input(self.ECHO2) == 1:
                pulse_end = time.time()

            pulse_duration = pulse_end - pulse_start

            # distance calculation
            distance2 = pulse_duration * 17150

            # round distance to two decimal points
            distance2 = round(distance2, 2)

            time.sleep(0.1) # ensure that sensor 2 is quiet

            self.oa.setDistances(distance1, distance2)

            count0 = self.mcp.read_adc(0)
            # approximation given 1023 = 7.5V
            voltage = count0 / 100

            self.control.find_and_set_new_active_behavior()

# instantiate an instance of testBBR
bbr = testBBR()

# run it
bbr.run()

```

此时，这是一个展示添加另一个行为是多么容易的好机会。

### 添加另一种行为

新类封装了基于电池电压水平的停止行为。如果电池电压下降到临界水平以下，你当然希望停止机器人。您还需要构建并连接一个电池监控电路，如图 [11-17](#Fig17) 示意图所示。

![A436848_1_En_11_Fig17_HTML.jpg](A436848_1_En_11_Fig17_HTML.jpg)

图 11-17。

Battery monitor schematic

本电路使用前面章节讨论过的 MCP3008 ADC 芯片。您应该检查这个芯片的安装和配置，因为它使用 SPI，这需要一个专门的 Python 接口库。

新的`Behavior`子类被命名为`StopRobot`。它实现了所有三种`Behavior`包容方法，以及一种设置实时电压水平的方法。以下是类代码:

```
class StopRobot(Behavior):

    critical_voltage = 6.0 # change to any value suitable for robot

    def takeControl(self):
        if self.voltage < critical_voltage:
            return True
        else:
            return False

    def action(self):
        # all stop
        pwmL.ChangeDutyCycle(2.6)
        pwmR.ChangeDutyCycle(2.6)

    def suppress(self):
        # all stop
        pwmL.ChangeDutyCycle(2.6)
        pwmR.ChangeDutyCycle(2.6)

    def setVoltage(self, volts):
        self.voltage = volts

```

为了接受额外的行为，还必须对`testBBR`类稍加修改。下面的代码显示了必须添加到`testBBR`类中的两条语句。注意，`StopRobot`行为是最后添加的，使它成为最高优先级——这是应该的。

`self.sr = StopRobot() (`将其添加到实例化的`Behavior`子类列表的底部。)

`self.sr.setVoltage(voltage) (`在电压测量后立即添加。)

### 试运转

机器人使用 SSH 会话运行，以使机器人汽车完全自主，没有任何妨碍的电线或电缆。该脚本从以下命令开始:

```
python subsumption.py

```

机器人立即沿直线向前行驶，直到遇到一个障碍物，那是一个纸箱。当机器人靠近盒子大约 10 英寸时，它迅速停下来，向右转，继续沿直线行驶。为了这个演示的目的，到此为止就足够了；尽管随着对机器人提出额外的要求，机器人的行为可以被不断地微调。

希望对 BBR 进行更深入研究的读者应该看看以下推荐的网站和在线文章:

*   [T2`https://sccn.ucsd.edu/wiki/MoBILAB`](https://sccn.ucsd.edu/wiki/MoBILAB)
*   [T2`http://www.sci.brooklyn.cuny.edu/~sklar/teaching/boston-college/s01/mc375/iecon98.pdf`](http://www.sci.brooklyn.cuny.edu/%7Esklar/teaching/boston-college/s01/mc375/iecon98.pdf)
*   [T2`http://robotics.usc.edu/publications/media/uploads/pubs/60.pdf`](http://robotics.usc.edu/publications/media/uploads/pubs/60.pdf)
*   `http://www.ohio.edu/people/starzykj/network/Class/ee690/EE690 Design of Embodied Intelligence/Reading Assignments/robot-emotion-Breazeal-Brooks-03.pdf`

## 摘要

基于行为的机器人(BBR)是这一章的主题。BBR 是基于动物和昆虫的行为模式，尤其是那些与有机体如何对其环境中的感官刺激做出反应有关的行为模式。

一个简短的部分讨论了人类大脑如何表现出多层次的行为功能，从基本的生存行为到复杂的推理行为。随后介绍了包容架构；它是紧密模仿人脑的多层行为模型。

进一步的深入讨论涉及简单和复杂的行为模型。对于本章的机器人汽车演示，我选择使用有限状态模型(FSM)。

接下来，我演示了一个名为 breve 的开源图形化机器人模拟系统。创建并运行了一个简单的 Braitenberg 车辆模拟，进一步证明了刺激/响应行为模式的功能。

最后的演示使用了 Alfie 机器人汽车，它由使用包容架构模型创建的 Python 脚本控制。该脚本包含三种行为，每种行为都有自己的优先级。我展示了基于包容的行为如何接管机器人，这取决于机器人遇到的环境条件。