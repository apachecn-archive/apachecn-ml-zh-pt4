# 6.行动中的 SAIF:案例研究

美国和欧洲的金融机构传统上被认为对少数群体有偏见。在一个组织选择向谁提供信贷/贷款或拒绝谁时，经常会观察到这种偏见。同样，这些少数民族往往比他们的同行收取更高的利息(Stefan 等人，2018 年；巴特利特等人 2019；奥尔登和哈马舍尔德 2016；劳埃德、博和约翰 2005；所罗门、阿尔珀和菲利普 2013；Patatouka 和 Fasianos 2015)。在撰写本报告时，大多数主要金融机构几乎没有采取任何措施来解决在银行业以及更普遍的融资渠道中观察到的系统性偏见问题。此外，金融机构越来越依赖人工智能通过自动化提高运营效率。对人工智能技术的这种依赖可能会放大对少数族裔的偏见。这是因为，截至目前，银行业创造的大多数(如果不是全部)人工智能系统必须依赖历史数据，这些数据不可避免地以某种方式反映或形成了行业的当前形势。换句话说，这些数据很可能包含人们试图克服的同样的缺陷。但更重要的是，正如在第五章[的“超越传统人工智能性能指标”一节中所讨论的，由算法行为产生的偏差在机构层面上起作用，并且比人类表现出的偏差具有更广泛的影响。](5.html)

考虑到前面的情况，必须确保贷款/信贷决策过程的自动化对申请人尽可能公平，同时最大化组织的利润。保持业务效率和公平性之间的平衡非常重要，因为错误的决定可能会对申请人产生负面影响，在某些情况下还会影响组织的声誉。具有讽刺意味的是，这是几乎不可能保证被拒绝贷款/信贷的申请人确实应该被拒绝的极少数情况之一。换句话说，那些被拒绝贷款的人永远没有机会证明他们是值得贷款的。这是不幸的，因为被拒绝贷款或信贷可能会对一个人的信誉和未来的借贷潜力产生不利影响。

本章介绍了 SAIF 框架的实际实施。这是通过一个信用评分系统的用例来实现的，该系统依赖于人工智能进行决策。通过这个案例研究，我们希望为读者提供一个如何在他们的组织中应用 SAIF 框架的例证；然而，必须指出的是，每个组织都需要使框架适应其环境。选择信用评分案例研究的动机是前面强调的原因。更重要的是，社区越来越需要金融机构的支持，由于错误的决策而得不到这种支持将是不幸的，并可能成为这些社区发展的障碍。

为了清楚起见，在本章的其余部分，我们假设人工智能系统是为一个称为金融公司的组织开发的。

本章的其余部分组织如下:

*   首先，我们提供一些关于信用评分用例的背景信息。

*   接下来，我们研究了金融公司背景下应用于信用评分系统的 SAIF 实践

*   最后，我们做一些总结。

## 背景

为了改善其在欧洲的运营并提高竞争力，Financials Corp .决定通过依赖人工智能来帮助决定谁获得贷款批准，从而简化其抵押贷款和个人贷款产品。做出这一决定后，该组织(Financials Corp .)任命了一名项目经理，并雇佣了一个数据专业人员团队来设计和构建急需的人工智能系统。虽然这种描述可能听起来过于简单，但事实上这是对大多数人工智能相关项目如何在许多组织中被引入或启动的准确描述。在某些情况下，更常见的是，招聘团队的组织不清楚团队要做什么。这意味着团队可能需要自己找出该做什么。

为了确保新系统的日常开发符合组织的业务目标，同时保持(如果不是提高)其声誉，Financials Corp .决定采用 SAIF 框架。

在一个组织中成功实施 SAIF 需要付出努力，并且需要整个组织的一致。人是成功的关键，参与必须从组织的高层开始，包括首席执行官(CEO)。在 Financials Corp .的情况下，关键角色或人员包括组织的首席执行官、人工智能负责人或首席数据官(CDO)、同时担任信用风险团队领域专家的项目经理，以及最后的开发团队，该团队由三名数据科学家/工程师和一名团队领导组成，该团队领导同时也是人工智能负责人。

在这种情况下，为了这个用例的简单性，我们假设组织的 CEO 已经定义了组织的价值和愿景，这可以通过下面的陈述来概括:

> *[……]金融公司不会因种族、肤色、年龄、残疾、性取向或身份而区别对待他人[……]。*

首席执行官授权人工智能负责人不仅要实现这一愿景，还要通过正在开发的系统来维护这一愿景。这意味着本组织致力于支持 SAIF 的实施，不仅提供必要的资源，而且致力于了解正在开发的系统的好处及其成功的必要条件。来自组织领导层的这种支持是极其重要的，因为它创造了一个环境，通过这个环境，技术团队可以教育领导层关于正在开发的系统的商业利益以及它对组织的意义。

通常，组织非常慢，尤其是大型组织，这意味着从开发团队到其他部门的请求可能需要几个月才能得到处理。更糟糕的是，有时这样的请求可能与团队完成工作所需的数据访问有关。拥有领导团队的支持通常是对项目的一个重要推动，因为其他部门经常发现更容易证明他们的资源分配是合理的，以解决开发团队每天可能面临的问题。

除了领导组织的人工智能战略，人工智能负责人还领导开发，并通过部署 SAIF 实践对项目的成功负责。实际上，这包括为 DS 流程的相关阶段定义适当的控制措施并监督其实施。人工智能负责人通过以下方式实现这一目标

*   与其他部门协作，如 IT 部门、法律部门和人力资源部门

*   在适当的时候委派职责

*   为开发团队提供足够的支持和培训

下一节讨论了适用于信用评分系统的设计和开发的一些控制措施，以及实施已确定的控制措施所需的政府安排。这些控制是在第 [4](4.html) 章的“数据科学开发流程”一节中开发的数据科学开发流程之上定义的。

## 信贷风险评估系统的流程-控制-治理

### 问题定式化

问题形成阶段旨在为开发团队提供一个简明清晰的问题陈述。对于信用风险评分，其公式如下:

> 使用申请人在申请过程中提交的信息(如性别、年龄等)创建一个评估其信用价值的系统。换句话说，开发一个信用评分系统，可以用来确定申请人是一个坏的信用风险还是一个好的信用风险。

用技术术语来说，这是一个分类问题，包括将申请人分为两个用户类别或类，即在给定其申请细节的情况下分为信用不良和信用良好的申请人。

DS 流程的问题形成阶段没有控制措施；然而，治理要求项目经理(他也充当领域专家)和开发团队的各种成员参与到导致这种表述的各种研讨会中。让开发团队的一些成员参与进来的基本原理是为了确保对要实现的目标有一个总体的理解，以及考虑到团队的技能和专业知识，这是否实际上可以实现。这项工作由项目经理和开发团队领导共同领导，在这种情况下，他也是 AI 的负责人。

### 表演

对构建的模型缺乏信心是大多数人工智能项目从未投入生产并因此被组织视为失败的一些关键原因。定义适当的性能指标对于一个成功的人工智能项目至关重要。正如前面在第 4 章[的“数据科学开发流程”一节中所讨论的，预先定义性能背后的基本原理是确保业务和开发团队之间有明确的一致性。](4.html)

项目经理和开发团队召开研讨会后，决定如下:

*   不正确地说申请是好的信用风险，形式上是假阳性(FP)， <sup>[2](#Fn2)</sup> 的成本超过了不正确地说申请是坏的信用风险，形式上是假阴性(FN)的成本。 <sup>[3](#Fn3)</sup> 换句话说，系统应该被设计成最小化误报。从商业角度来说，组织希望尽量减少申请人后来违约的比例。

*   根据组织的价值观和原则，公平/偏见和可解释性已被确定为正在开发的系统的软性能指标。

*   虽然预测申请人的信用风险是好还是坏很方便，但通常最好是估计预测类别的概率。这种概率提供了对模型置信度的进一步了解，同时允许对预测的解释具有更大的灵活性。

为正在开发的系统的行为提供一个全面的描述是很重要的，这样可以避免任何关于系统评估标准的模糊性。

#### 控制

为了简单起见，在性能阶段只确定了有限数量的控制。这些重点是定义和记录协议，以便根据确定的性能指标评估系统。这些包括但不限于

*   用于训练、评估和测试未来模型的数据分割策略和最小数据量。

*   用于计算最终性能指标的数据集的关键特征。例如，年龄和性别等敏感属性应该在最终的测试数据集中占相等(或几乎相等)的比例。

*   系统应该能够突出显示对模型预测影响最大的预测变量和值。

#### 管理

开发团队领导(DTL)与项目经理合作，确保在此阶段指定的控制和定义的性能是现实的和可实现的。没有为这个项目确定一个合理的目标是失败的原因。实际上，由于一些令人费解的原因，组织经常有一种不健康的倾向，将他们的大部分努力集中在过于复杂的目标或项目上，这在实践中增加了人工智能项目的失败率。

在定义人工智能项目的目标时，与人工智能项目失败相关的另一个方面常常被忽视，这就是开发团队的技能。现实的目标应该意味着项目开发团队的现实目标。DTL 有责任同意团队实际可实现的目标，因为不同意会增加项目的成本和交付时间。

作为治理安排的一部分，DTL 还确保开发团队能够访问适当的基础设施来开发、测试和部署模型。为了实现这一点，DTL 与组织的 IT 团队联系，以确保它能够提供工具和软件，在项目的整个生命周期中支持开发团队。确切地说，DTL 与 IT 部门合作，设计和部署符合组织标准的数据处理基础架构，以保证用户隐私，并严格控制组织内谁可以访问哪些信息以及信息的用途。

正如在第 [5](5.html) 章的“软性能指标”一节中提到的，FN 和 FP 等传统性能指标可能会与偏倚等软性能指标相冲突，这意味着调整算法以使其结果对所有组都公平有时会导致整体模型不太准确。可能需要在我们选择的绩效指标和偏差之间进行权衡，这需要与业务部门进行充分沟通。

### 数据收集和/或解释

#### 控制

使用正确的数据对于任何人工智能项目的成功都是至关重要的。此阶段的控制通常确保用于系统开发的数据符合性能阶段中设定的预期。

用于培训、评估和测试信用评分系统的数据由组织在过去五年中收集的历史信用/贷款数据组成。这些数据由信贷风险团队根据组织的数据管理政策提供。它包括各种信息，如债务人的人口统计信息和关于他们如何偿还贷款以及是否偿还贷款的信息。此阶段确定了以下非详尽的控制列表。人们可以把它们看作是数据收集和解释阶段必须满足的约束条件的清单。尽管这些控制是针对这个项目的，但它们适用于广泛的人工智能项目:

*   信用风险评估数据的充分性
    *   作为评估数据对信用评分的充分性的过程的一部分，数据的关键特征被相应地揭示和记录。这些信息有助于识别可能导致公平/偏见相关问题的因素。

*   充分检查数据集的偏差
    *   当组织提供了敏感属性的明确定义时，可以检查数据集中是否存在这种属性，并检查它们与结果变量的关系。然而，当这种定义不可用时，人口统计属性通常被认为是敏感的，可以构成一个良好的起点。

    *   一旦确定，需要测量或评估这些属性对结果的影响，并采取适当的行动或步骤来减轻这种影响。换句话说，需要记录减轻偏见的方法及其局限性(如果有)。

*   数据符合 GDPR 等法规
    *   用于信用评分的数据通常可能来自不同的来源。必须采取必要的措施，确保在适用法规的范围内收集和处理数据。

*   数据预处理和应用于数据的其他转换的文档记录的充分性，包括处理错误和缺失值的方法

*   数据标签方法的充分性
    *   在一个分类设置中，比如手边的这个，数据需要被标记。这种标记通常由非常了解数据和业务环境的领域专家来完成。然而，它有时可能依赖于复杂的规则。这些以及其他假设都被记录下来，并对其充分性进行评估。

*   数据记录的充分性和对原始数据的理解
    *   很少被理解的变量，尤其是被开发团队理解的变量，不应该包含在模型的设计中。当数据是从没有完全披露该数据是如何生成的数据代理或第三方获得时，可能会发生这种情况。另一个经常出现的问题是，组织没有正确地向数据代理传达数据的用途(例如，出于保密原因)，因此最终可能会得到一些与手头任务完全无关的数据点。

#### 管理

缺乏数据可以说是人工智能项目失败的最大挑战之一。作为数据收集和/或解释阶段治理安排的一部分，项目经理必须确保有一个清晰有效的策略来获取开发、测试和评估项目所需的数据。为此，项目经理与组织内外的 DTL 和相关数据源提供商合作。

围绕数据收集和理解的另一个治理安排涉及定义相关的控制，并确保它们在项目的整个生命周期中得到充分的实现和维护。相关的角色由 DTL 扮演，他相应地在开发团队中委派职责。作为该流程的一部分，开发团队与项目经理和信用风险团队联系，后者应提供足够的数据文档。

通常，组织对于什么构成敏感属性没有明确的定义。当没有这样的定义时，DTL 有责任与组织内的相关部门合作，为开发团队提供一个定义。

### 模型结构

#### 控制

与前面的阶段一样，模型构建阶段的控制旨在确保模型满足预期的性能和潜在的业务目标。如下图所示，它们可以用构建模型时需要回答的问题的形式来表达。

在信用评分系统的框架内，已经确定了以下非详尽的控制列表:

*   数据集的大小和它覆盖的时间对于正在开发的系统来说是否足够？
    *   这些信息在信贷风险评估项目的框架中是可取的，因为模型决策的可信度通常会随着训练数据的增加而增加。此外，它还告知模型的开发是否符合适用的法规。

    *   缺乏训练数据通常是 ML 模型表现不佳的关键因素。在某些情况下，可能没有足够的数据可用于所有客户群，在这种情况下，可能需要根据数据/功能的可用性为不同的用户群创建不同的模型。然而，由于数据可用性导致的性能不佳更有可能在模型的早期被观察到。

*   开发团队对模型的理解是否充分？
    *   不是开发团队的每个成员都需要理解模型的每个方面；但是，DTL 需要这种理解，并采取适当的措施使小组的其他成员了解最新情况。

*   模型是否经过适当校准？
    *   这是我们所希望的，因为我们希望估计的违约概率能够准确地代表模型的置信水平。换句话说，给定一个贷款样本，它们的预测违约概率应该尽可能接近样本中的违约百分比。请注意，对于一些模型，如逻辑回归，模型的估计类概率已经校准；然而，对于诸如随机森林的一些其他算法，这些并不反映算法在预测中的置信度，并且需要相应地校准。

*   模型需要可解释吗？
    *   理解哪里需要可解释性，什么需要可解释性是很重要的。

*   模型是否有充分的文档记录？
    *   建立一个人工智能模型包括几项任务，如分割数据，提取将作为模型输入的特征，训练和测试模型。这些任务需要与假设一起适当地记录下来。这样的文档应该确保模型可以从中重新创建。

    *   在此阶段可能会创建多个模型；然而，只有最好的模型或者要在生产中部署的模型才需要被记录。

*   采取了哪些措施来减轻偏见？
    *   偏差可能发生在开发过程的不同阶段，包括模型构建阶段。当对减轻偏差感兴趣时，如果需要，可以对数据应用额外的变换，或者依赖于结合了偏差减轻属性的算法或工具。这需要相应地记录下来。

*   用于培训的模型和数据是否版本化并得到充分维护？
    *   维护用于训练 ML 模型的数据以及训练代码的跟踪记录是非常重要的，因为它不仅允许在需要时在模型和/或数据的不同版本之间切换，而且更重要的是，保持跟踪已经应用于模型的变化。数据版本控制(DVC) <sup>[4](#Fn4)</sup> 等工具可以用于此目的。

#### 管理

模型构建阶段的治理安排由定义相关控制并监督其实施的 DTL 领导。DTL 通过与项目经理合作，充分理解现实部署场景中模型的预期行为来实现这一点。

组织通常不愿意为人工智能项目投资正确的资源。然而，如果得不到正确的支持，不仅会推迟交付，还会阻碍其成功。这是因为实施某些控制可能需要额外的时间、人力和培训资源。DTL 必须与组织内的相关部门联系，以提供开发团队所需的支持。考虑到这一点，在整个组织范围内采用 SAIF 框架非常重要，因为实施控制通常需要其他部门的参与，如 it、法律和人力资源部门。

### 评估/绩效衡量

#### 控制

DS 流程模型评估阶段的控制旨在验证模型是否经过充分测试。以下是此阶段已确定的控制措施的非详尽列表。它们以在模型评估期间必须回答的问题的形式表达:

*   模型的评估方法或方案是否记录在案，性能指标是否得到充分测量和报告？
    *   记录模型的评估策略可以帮助识别或排除最终人工智能系统设计中的缺陷。

    *   例如，用于评估模型的数据应该反映训练数据的分布。如前所述，一种称为 k-fold 交叉验证的技术通常用于模型验证。如果使用不当，可能会导致对模型性能的错误估计。

    *   值得注意的是，验证模型的理想方法是在模型构建阶段没有使用的足够大的测试数据集上检查其性能。需要检查和记录该数据集的充分性及其关键特征，以确保其代表培训数据。

*   模型中的重要特征是否被识别和记录？
    *   实现这一点的方法包括改变模型的输入数据并观察预测结果的相关变化。但是，某些算法可以自动计算要素的重要性，因此可以更好地了解每个要素或变量如何影响模型的结果。

    *   对于更复杂的模型，依赖关系图有助于说明功能对预测结果的影响。

*   领域专家对模型进行评估了吗？
    *   通常，领域专家或系统的未来用户会对如何测试模型有更好的理解。然而，由于领域专家不一定是人工智能专家，他们有效挑战模型的能力取决于模型的文档化程度。这指出了开发团队与业务沟通的重要性，以确保他们理解模型如何工作。到目前为止讨论的控件应该能够很好地理解模型是如何构建和工作的。

    *   让领域专家参与进来的另一个好处是，他们可以帮助设计有效的场景来测试模型。

*   性能是否被正确解读？
    *   虽然模型的性能经常使用在第 [5](5.html) 章的“人工智能性能指标概述”一节中讨论的指标来评估，但是这些通常需要在业务环境中进行解释。在信用评分系统的情况下，计算出的信用评分以及相关的假阴性和假阳性被传达给信用风险专家，然后信用风险专家帮助定义可接受的风险水平。

#### 管理

模型评估阶段的关键角色包括开发团队和领域专家，在这种情况下，他们由项目经理代表。项目经理在系统进入部署阶段之前签署系统。DTL 将适当的职责委派给开发团队的成员，并在需要时为他们提供必要的支持和培训。此外，DTL 与业务专家合作，以确保在业务环境中很好地理解和正确解释性能指标。

### 模型部署

#### 控制

DS 过程的模型部署阶段的控制确保为部署选择的模型符合组织的业务目标和价值。以下是以问题形式表示的控制措施的非详尽列表，在模型部署之前或期间必须回答这些问题:

*   模型是可解释的吗？
    *   值得注意的是，根据手头的应用，人们可以通过了解每个预测因素对反应的相对贡献来实现可解释性。信用风险评估模型传统上依赖于相对容易解释的逻辑回归。但是，其他算法(如随机森林和梯度推进树)可能会提供更好的性能，并且可以自动计算变量重要性，该变量重要性近似于变量在描述响应时的重要性。通常，对于更复杂的模型，可以采用基于结果的可解释性方法。

    *   通常将模型的可解释性与解释单一结果的能力联系起来。然而，ML 模型通常通过性能度量来判断，例如准确性，这反映了它们对相对大量的观察结果进行准确预测的能力。这表明，应该在手头的业务问题的背景下，致力于解释性能指标。

*   模型的结果是否被评估有偏差？
    *   在敏感属性的子组中检查模型的性能有助于识别模型结果中的偏差。

    *   必须与业务部门就适当的公平指标达成一致。这是因为一个模型在一个度量标准下可能是“公平的”,但在另一个度量标准下可能是不公平的。

*   是否已定义模型的管理和监控策略？
    *   在部署模型之前实施模型监控和管理策略可以确保错误被主动识别并得到相应的处理。作为其中的一部分，应该采取必要的预防措施来确保模型可以很容易地更新。由于多种原因，可能需要更新模型，例如业务条件的变化，或者模型不再准确地代表部署它的目标人群。

    *   这也保证了组织内的一个实体，例如数据科学团队，拥有该系统并负责其持续的维护和改进。

*   正在开发的 AI 系统是否可审计？
    *   了解哪个版本的代码、数据和模型被部署到产品中是非常重要的，尤其是当模型不能正常运行的时候。

*   模型的部署策略是否充分？
    *   通常，部署 ML 模型的方法可以分为动态和静态两种。当数据可能随时间变化时，动态模型通常是首选。对于信用风险的例子，系统需要不断调整以适应其目标人群，因此动态部署更合适。

*   部署的系统是否可扩展，是否通过适当的用户和权限管理得到保护？
    *   可伸缩性并不总是必需的，但是这样的决定通常取决于平台的用户数量。需要与业务部门协作来决定模型的可伸缩性。

#### 管理

模型部署阶段的治理安排确保在模型的整个生命周期中定义、实现和维护适当的控制。DTL 监督这个阶段，并与项目经理以及来自 IT 部门的技术专家一起工作，以确保开发团队对部署有适当的支持。

在某些情况下，开发团队创建的模型需要移交给软件开发团队，以与组织的软件开发堆栈兼容的编程语言重新实现。在这种情况下，DTL 必须密切监督新的实现，并与软件开发团队合作，以确保它得到充分的测试。

为这一阶段定义适当的控制主要由开发团队领导协调，他与 IT 部门和项目经理(在这种情况下也是领域专家)积极合作，以确定相关的控制。此外，DTL 必须确保项目经理在部署之前签署系统。

## 结论

在本章中，我们讨论了基于人工智能的信用评分系统的用例，以说明组织如何通过 SAIF 框架的流程-控制-治理模型有效地管理人工智能的风险。确切地说，我们已经确定了 DS 流程各个阶段的控制措施，并讨论了确定和实施这些措施所需的治理安排。尽管特别关注信用评分系统，但控制和治理安排的描述适用于大多数人工智能项目。

组织越来越依赖第三方来开发和部署他们的人工智能能力。在这种情况下，组织应该确保其人工智能系统在使用前有适当的控制措施。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

这可能也适用于世界其他地区；然而，已发表的关于少数民族经济歧视的研究大多集中在美国和欧洲。

  [2](#Fn2_source)

当申请人实际上是不良信用风险时，系统错误地指示申请人是良好信用风险。

  [3](#Fn3_source)

当申请人实际上具有良好的信用风险时，系统错误地指示该申请人具有不良的信用风险。

  [4](#Fn4_source)

[T2`https://dvc.org`](https://dvc.org)

 </aside>