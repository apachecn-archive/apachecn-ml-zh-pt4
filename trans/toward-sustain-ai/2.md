# 2.数据科学实践的伦理

Ethics in Data Science

> 混乱不是一个坑。混乱是一架梯子。许多试图攀登它的人失败了，再也没有机会尝试了。跌倒会让他们崩溃。有些人有机会攀登。他们拒绝，他们坚持王国或神或爱。幻觉。只有梯子是真的。只有攀登。
> 
> ——培提尔·贝里席，*王位游戏*

上面的引文把混沌描述为获取和维持权力的工具。在 HBO 的剧集《权力的游戏》中，各种主角为了自己的利益而采用的策略。*《权力的游戏》*展现了一个引人注目的人类文明世纪前的样子，那时还没有引入法律和规则来阻止人们以负面影响他人的方式行事。该剧强调了有权有势的人如何利用这一点。今天的社会和*《权力的游戏》*的社会已经大不相同了。重要的是，一个人不再能逃脱任何行为。相反，一个人的行动和行为是有规则可循的。

虽然*权力的游戏*是虚构的，但可以将它与人工智能的进化进行一些比较。更准确地说，随着社交媒体、物联网(IoT)设备和数字化的出现，获取数据变得前所未有的容易。人们可以获得关于人们睡眠模式的数据；他们早上做的第一件事是什么；他们开车、走路或在键盘上打字的速度；等等。此外，数据处理软件和硬件也有了显著改善。这使得分析和解释这些数据的可能性大大增加。这两个因素结合起来表明，除了一个人的想象力之外，一个人使用人工智能可以做的事情几乎没有限制。然而，这并不意味着所有这些利用数据的机会都符合一个社会的价值观。在没有法律法规来帮助驾驭各种可能性的情况下，人们如何决定做什么和不做什么？幸运的是，对伦理的研究可以为指导一个人的行动提供框架。

本章探讨人工智能的伦理，组织如下:

*   首先，我们检查人工智能中伦理的相关性。

*   然后，我们讨论人工智能的推理能力及其伦理含义。

*   接下来，我们将讨论作为业务资产的数据。

*   最后，我们做一些总结。

## 伦理学及其与人工智能的相关性

《牛津英语词典》将伦理定义为“定义一个人的行为或开展一项活动的道德原则”与此相一致，道德决策包括遵守指导个人活动的“行为准则”,该准则要求考虑他人的价值观、信仰和后果。

一方面，从社会的角度来看，无论个人特征如何，公民都应该尊重某些道德行为。这些特征可能包括宗教、地理位置和教育。社会中预期的道德行为通常被称为社会道德行为，包括基本的管理规则，如尊重他人的财产，避免对他人使用暴力，以及礼貌待人。 <sup>[2](#Fn2)</sup> 许多这样的规则被一个社会的法律框架所捕获。然而，法律规定的规则并不能告诉我们在面对每一个困境和做出每一个决定时应该做什么。因此，并非所有不道德的行为都是违法的。然而，正如 Whittingham (Whittingham 2008)所指出的那样，如果不加以制止，不道德行为很容易演变成非法行为。另一方面，从一个组织的角度来看，人们可以把道德看作是管理组织如何进行(商业)活动的一套规则和/或原则。

在专业背景下，社会可以预期的道德行为通常在与相关决策者的协议中进行描述和记录。此类规则由组织定义，但也会受到组织所处行业的影响，以及规定在与客户、同事和其他组织打交道时某些行为是否适当或可接受的法规。例子包括医疗实践道德、司法行为准则和公司员工手册。我们将组织和社会道德规范称为“一般行为准则”

《一般行为准则》通常已得到很好的确立和理解。然而，通过研究和开发进行的技术创新(R&D)，特别是当涉及探索尖端技术的潜力时，可能会考验其边界。这可以通过隐私的概念来说明，隐私的定义是

> 个人或团体封闭自己或关于自己的信息，从而有选择地表达自己的能力。 <sup>[3](#Fn3)</sup>

数据收集和处理机会的无处不在以及对个人进行在线查询的能力的急剧扩展不断挑战着隐私。隐私和尖端技术之间的复杂关系被英特尔公司的联合创始人和前首席执行官 Andrew Grove 总结为

> 这个新电子时代最大的问题之一。网络文化的核心是一种想要了解你一切的力量。一旦它发现了你和其他两亿人的一切，那就是一笔非常有价值的资产，人们会被诱惑用这笔资产进行交易。当人们称之为信息时代时，这并不是他们所想的信息。 <sup>[4](#Fn4)</sup>

因此，当我们继续理解和见证它们的结果时，人工智能系统成为道德批评的中心也就不足为奇了。为了更好地理解这种担忧的基础，有必要进一步探索人工智能系统的关键要素。

人工智能系统通常围绕两个基本要素构建:知识库和推理能力。通过推理，人工智能系统使用在其训练期间收集的知识来推断关于新数据的事情(通常是新知识)。通常，知识库由大量信息或数据(事实、关系、理论等)组成。)与世界的某些方面相关。编写计算机程序是为了向计算机提供操纵和导航知识库以识别或发现模式的能力。这些模式然后被用来建议一个行动过程来实现一个给定的目标。具体地说，这个过程产生一个经过训练的算法或模型，被称为“学习”或训练。因此，执行这些任务的计算机程序被称为“学习算法”，或者更正式的说法是“机器学习算法”。正如任何涉及学习的事情一样，增加人工智能系统的知识库通常会带来更好的结果。因此，现实生活中的人工智能系统往往需要大量数据来实现最佳功能。然而，这只有在数据质量“良好”的情况下才成立相反，低质量的数据最终会导致糟糕的人工智能系统。在人工智能社区中，这通常被称为“垃圾进垃圾出”。换句话说，人工智能系统的好坏取决于用来创建它的知识库。

综上所述，当构建一个人工智能系统时，依赖于尽可能准确地代表人工智能系统试图建模的现实世界问题的数据是至关重要的。要做到这一点，通常需要使用敏感信息，这反过来又会引发许多关于获取、处理和加工此类信息的隐私问题。这一点已通过《一般行为守则》得到各种机构的广泛认可，在一些国家, <sup>[6](#Fn6)</sup> 通过类似监管的措施，如《GDPR 》,对用户和各种组织或服务提供商之间的信息流动进行监管。

GDPR 规定的主要限制之一(从用户的角度来看，可以说是最重要的限制之一)是，与外科医生在实施手术时征得患者同意类似，GDPR 下的组织在收集和使用用户信息之前必须征得患者的明确同意。然而，外科医生和组织要求的同意之间的一个关键区别仍然是，当患者同意时，有责任非常明确地与患者接触，以理解这种同意意味着什么。换句话说，外科医生有义务以病人的最佳利益为重，而公司通常没有义务这样做。

根据 GDPR 的说法，用户可以通过选择同意或不同意来“控制”他们的数据。这种控制在实践中并不存在，因为用户通常不能使用服务，除非他们完全同意所有条款和条件。此外，一旦用户同意，他们很少或根本无法控制，更不用说真正了解数据的用途和使用方式。这可能是有问题的，因为组织通常不会在确保用户理解同意的含义上投入太多。当查看条款和条件时，这一点变得很明显，现在这些条款和条件包括“您的数据将只与可信的合作伙伴共享”这种形式的声明；这些合作伙伴是谁，他们做什么，以及他们与寻求同意的组织之间的协议的性质，对于给予同意的用户来说通常是一个谜。

例如，据报道，一些应用收集用户的个人数据，然后与脸书共享，用于广告定位。此外，通过脸书提供登录服务，剑桥分析公司——它处于脸书-剑桥分析公司数据丑闻的中心——能够收集数百万脸书用户和相关朋友的敏感信息，然后用于政治竞选活动。这种做法被认为是不道德的，不仅因为它可以被视为侵犯用户的隐私权，而且因为滥用用户的信任。信任和道德的概念是不可分割地联系在一起的，霍斯默对信任的定义特别提到了道德行为的重要性:

*   信任是一个人、一个团体或一家公司对道德上正当的行为的期望——也就是说，在共同努力或经济交换中，另一个人、团体或公司基于道德分析原则的道德上正确的决定和行为。(霍斯默 1995 年)

很明显，当用户认为道德标准很低时，组织的形象或业务可能会受到损害。在脸书-剑桥分析公司数据丑闻之后，脸书的市值下降了 1000 多亿美元，而剑桥分析公司停止了运营。然而，如果一家公司的真正道德标准仍然不透明，客户可能不会意识到他们的隐私处于危险之中。

上述讨论表明，理解在数据科学的背景下考虑道德规范意味着什么是至关重要的。以下部分讨论了数据科学实践的道德要求。

## 人工智能推理能力的伦理本质

使用人工智能的推理能力不一定会产生伦理后果，因为推理的信息可能在伦理上是中立的。换句话说，对信息的分析可能只会产生伦理上无关的影响。例如，一个利用过去的天气状况来推断未来天气状况的人工智能系统可能会这样做，而不会产生任何道德后果。相反，一个将深色皮肤的个体贴上“大猩猩”标签的 AI 系统确实会产生伦理后果，因为人与大猩猩之间存在偏见的同化。

围绕使用犯罪风险评估工具的争论提供了另一个具有伦理内涵的人工智能推理的例子。这些工具将个人的详细信息作为输入，并输出一个“累犯”分数，表明该个人再次犯罪的可能性。然后，法官根据分数和其他因素来决定受影响者的命运。高分意味着严厉的惩罚，低分意味着法官的宽大处理，最终意味着不那么严厉的惩罚。犯罪风险评估系统依靠历史犯罪数据来建立其推理能力。因此，历史上一直被执法机构作为目标的社区(尤其是少数民族)比其他社区更有可能在风险评估中获得高分。因此，风险评估系统很可能使已经存在的对这些少数民族的偏见持续下去。换句话说，风险评估系统建议人们受到更严厉的惩罚，因为他们可能会再犯。一个人可以争辩的推理在本质上是道德上有缺陷的，因为惩罚是针对过去的行为，而不是可能或可能永远不会实现的行为。

类似地，推断个人特征(如性取向、种族、宗教和政治偏好)的人工智能系统会产生伦理后果，因为所披露信息的隐私相关性质或其可能的使用方式。不管预测的准确性如何，在某些情况下，披露此类信息可能是歧视性的。

除了人工智能系统与隐私相关的伦理后果之外，我们可以将人工智能系统的伦理后果粗略地归因于以下因素:

*   影响推断信息的特征大部分来自有限数量的观察。这反映了一个被称为“大数定律”的问题，即小样本和从中抽取样本的更大人群之间的相似性经常被夸大(Rabin 2002)。例如，在一个公平的掷硬币实验中，一个人可能在掷硬币 100 次后观察到 70 个正面和 30 个反面，并得出结论说公平的掷硬币有 70%的正面和 30%的反面落地，这是不正确的。

*   知识库偏向于特定群体的优势。前面讨论的风险评估系统代表了一个很好的场景示例，其中知识库偏向于特定群体的优势。这很常见，因为知识库通常只是我们对世界的感知的数字表示。

*   知识库可能包含错误。公司通常依赖第三方数据来做出关键决策。例如，债权人、保险公司、雇主和其他企业依靠信用评分来评估信贷、保险、就业或租房申请。这是有问题的，因为信用数据是从多个来源收集的，并且经常包含错误。因此，受影响的个人可能看起来比实际风险更大，这反过来意味着他们将获得更高的利率。此外，由于受影响的个人通常不知道正在使用什么数据，因此改进的机会有限。

*   知识库主要由人际主观数据组成。这种类型的信息充其量只能提供一个“粗略”的方向，并且不能在个人之间进行比较。这种信息包括记录的感知。例如，当被要求从 1 到 10 (1 是最低程度的疼痛，10 是最高程度的疼痛)对疼痛进行评级时，患者可能会故意给出一个数字，以增加他们获得止痛药的机会。不管给出什么分数，它只对病人评定疼痛有意义。

*   推断信息的相关性缺乏透明度。很多学习算法是概率性的； <sup>[8](#Fn8) 这样的分数然后被用来影响如何向用户提供服务。例如，犯罪风险评估系统可以计算累犯分数，然后将其转化为与个人相关联的风险水平。不幸的是，由于大多数由学习算法驱动的系统的专有性质，不可能排除它们设计中的缺陷。</sup>

*   数据处理错误。数据处理中的错误可能由于从输入到数据操作错误的许多原因而发生。例如，一个组织希望通过分析社交媒体帖子(文本的短段落)来了解其客户对其的看法，其中一些帖子可能包含讽刺。然而，虽然已经取得了重大进展，但用于执行此类任务的技术并不完美，因此错误是意料之中的，人们应该意识到这一点。

*   人工智能产品的误导或虚假广告。例如(在写这本书的时候)，在医疗保健行业，目前有很多关于 AI 诊断工具的兴奋，所有这些工具充其量只能充当医生的助手。不幸的是，它们很少像这样被宣传，而是可能被用户理解为完全取代医疗专业人员的服务。这可能会造成严重的损害，特别是在发展中国家，那里的法规和控制宽松或不存在，由于普遍缺乏(获得)合格的医务人员，对这种服务的需求可能很高。

*   数据的变化。数据群体的变化使得知识库过时，这意味着它不能很好地代表新的目标群体。因此，组织必须对人员数据进行定期审计，以确保正确的代表性。

## 数据——业务资产

数字化转型——转变业务流程以整合云、移动、大数据和社交网络等新数字技术的使用——正稳步成为寻求优化现有运营同时抓住新机遇的组织事实上的运营战略。

因此，用户通过与数字服务或平台的交互产生的数据量(为简单起见，我们称之为用户生成的数据)在过去几年中激增。据市场情报公司 IDC 估计，2025 年将达到 175 兆字节。 <sup>[9](#Fn9)</sup> 与此同时，从 2014 年到 2019 年，全球互联网用户数量从 24 亿跃升至 44 亿， <sup>[10](#Fn10)</sup> 允许更多的个人访问基于互联网的服务。

尽管如此，大多数组织仍在试图找出如何从用户生成的数据中创造价值。技术先锋，尤其是谷歌、亚马逊和脸书，已经成为“大数据”可用性不断增加的主要受益者举例来说，亚马逊在 2019 年第三季度创下了 36 亿美元的历史最高广告收入。这家电商巨头之所以能取得这样的业绩，是因为它代表企业在其平台上投放的广告，与投放给它们的用户“相关”。然而，确定这种“相关性”的关键目标是实现利润最大化。这样做的先决条件是拥有足够多的有意义的信息，比如关于这些用户过去的搜索和购买记录。

其他例子涉及使用“免费增值”服务的公司，这种服务在使用时免费提供给客户，但向公司提供的数据以后可以货币化，例如通过向客户提供付费服务。以谷歌的免费搜索引擎为例，谷歌通过向其他公司出售广告空间来获取搜索信息。 <sup>[12](#Fn12)</sup> 因此，组织理所当然地将数据视为商业资产也就不足为奇了。这导致了一种趋势，其中个人(或至少他们产生的数据)可以被认为是商品的一部分。有人可能会说，组织积极地设计方案来收集和货币化用户生成的数据。这种方案通常是不透明的，因为提供给用户并为其所理解的服务通常并不完全公开其真正在做什么。

公司可能会辩称，用户从向公司提供对其数据的访问中受益，因为这允许公司提供更好或更有针对性的用户体验。然而，所获得的改进服务的价值是否与向公司提供的数据的价值成比例，这一点常常令人怀疑。一个极端的例子是要求用户注册/签约的服务，但是无论他们注册与否，他们接收的内容/服务实际上是相同的。该行业很清楚这种做法的误导性，一些公司开始响应加强保护的呼吁。举例来说，苹果公司积极监控并拒绝在其应用商店中显示此类行为的应用。截至 2020 年 10 月 26 日，其条款和条件规定

> *[…]如果你的应用不包含重要的基于帐户的功能，请让用户无需登录即可使用。应用可能不要求用户输入个人信息才能运行，除非与应用的核心功能直接相关或法律要求[……]。* <sup>[13](#Fn13)</sup>

将用户生成的数据货币化的组织通常只会向用户呈现扭曲的现实，这可以被视为缺乏透明度，因为通过将来自不同用户的数据结合在一起，他们会过滤向用户显示的内容，并最终塑造每个人的所见、所想和所为。例如，考虑搜索引擎的情况:人们在寻求与日常生活几乎所有方面相关的信息和建议时，越来越依赖搜索引擎(Carroll 2014)。搜索引擎的结果最终会改变我们对世界的看法和认知。给予用户的明显选择通常具有误导性，因为他们最终选择什么是由组织决定的(Goldman 2008 约旦 2017)。这代表了一种实践，如果给予透明性，大多数用户可能会不赞成。总之，有几个原因可以解释为什么企业利用数据这一商业资产的方式往往与数据主体(数据收集者)的价值观相冲突。

此外，将数据视为业务资产的能力阻碍了运营透明度，特别是数据处理和加工。如果数据主体意识到他们的数据的真正价值，他们可能会要求分享从他们的数据中产生的收入，从而威胁到企业的利润。有人可能会说，用户通过提供数据而获得的大多数服务都是免费的，可以被视为对其数据的补偿。然而，尽管一些组织努力对用户的数据进行补偿，但当前的收入分配似乎更倾向于数据处理者。

与任何业务资产一样，数据治理对于确保数据在整个组织中一致、可信，并且不会被滥用或操纵，从而损害处理数据的组织或数据主体至关重要。换句话说，数据治理鼓励良好的行为，并通过定期审计主动限制产生风险的行为。这些风险可能与监管罚款、数据安全、声誉受损等有关。例如，泄露的敏感信息可能会使受影响的个人处于巨大的压力之下，包括勒索的威胁，其可怕的后果就像阿什利·麦迪逊婚外情网站周围的数据泄露所暴露的那样，随后就有自杀的报道。 <sup>[14](#Fn14)</sup> 此外，实施适当的数据治理和审计策略有助于组织回答以下问题:数据发生了什么变化？谁访问了它？它是如何储存的？数据在组织中存在多长时间了？等等。回答其中一些问题可能有助于组织了解他们在多大程度上遵守了 GDPR 条款(5)“个人数据的保存时间不得超过处理这些数据的目的所必需的时间。”

这篇文章的一个关键限制是，它可能过于模糊，难以由当前的监管机构执行。因此，组织可能会倾向于不采用数据治理策略；然而，这样做只会加剧组织和客户之间的信任危机。根据 2018 年第二版 sales force State of the Connected Customer 报告，59%的客户和企业买家(接受调查的 6700 多人)认为他们的个人信息容易受到安全漏洞的影响，而 62%的人对公司如何使用他们的个人/企业信息感到不安。 <sup>[十五](#Fn15)</sup>

根据新法规，如果不符合数据治理的最新标准(包括作为不可或缺的一部分的安全性),数据很容易变成一种负担。涉及英国航空公司、 <sup>[16](#Fn16)</sup> Equifax、 <sup>[17](#Fn17)</sup> 和万豪酒店 <sup>[18](#Fn18)</sup> 等组织的事件是数据成为收集数据的组织的责任的说明性示例。

## 结论

过去几年见证了人工智能应用在社会几乎每个方面的不断发展和部署，从公共和私人机构到政府机构。这通常为解决复杂问题提供了有效的方法；不幸的是，技术开发和部署的方式可能会导致与隐私、公平、信任和透明度相关的不必要和不希望的后果。幸运的是，关于伦理的讨论提供了一个框架来帮助理解这些后果。更一般地说，伦理有助于揭示人工智能开发和部署过程中为不必要的行为提供机会的方面。揭示这些道德风险需要理解人工智能的基本要素及其含义。

接下来的章节介绍了将本章强调的人工智能的伦理后果最小化的方法。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

[T2`www.lexico.com/definition/ethics`](http://www.lexico.com/definition/ethics)

  [2](#Fn2_source)

[T2`https://examples.yourdictionary.com/code-of-ethics-examples.html`](https://examples.yourdictionary.com/code-of-ethics-examples.html)

  [3](#Fn3_source)

[T2`https://en.wikipedia.org/wiki/Privacy`](https://en.wikipedia.org/wiki/Privacy)

  [4](#Fn4_source)

[T2`www.esquire.com/entertainment/interviews/a1449/learned-andy-grove-0500/`](http://www.esquire.com/entertainment/interviews/a1449/learned-andy-grove-0500/)

  [5](#Fn5_source)

数据质量的评估是手边的应用领域所固有的。

  [6](#Fn6_source)

这在大多数发展中国家是个问题，这些国家尚未效仿。

  [7](#Fn7_source)

[T2`www.wsj.com/articles/you-give-apps-sensitive-personal-information-then-they-tell-facebook-11550851636`](http://www.wsj.com/articles/you-give-apps-sensitive-personal-information-then-they-tell-facebook-11550851636)

  [8](#Fn8_source)

简而言之，我们可以把概率算法看作是程序员没有明确定义操作标准的算法。

  [9](#Fn9_source)

IDC 白皮书–# us 44413318，2018 年 11 月

  [10](#Fn10_source)

[T2`www.internetworldstats.com/stats.htm`](http://www.internetworldstats.com/stats.htm)

  [11](#Fn11_source)

与苹果和微软一道，他们通常被称为 GAFAM

  [12](#Fn12_source)

[T2`https://marketingland.com/youtube-kicked-in-15-billion-as-google-ad-revenues-topped-134-billion-in-2019-275373`](https://marketingland.com/youtube-kicked-in-15-billion-as-google-ad-revenues-topped-134-billion-in-2019-275373)

  [13](#Fn13_source)

[T2`https://developer.apple.com/app-store/review/guidelines/legal`](https://developer.apple.com/app-store/review/guidelines/legal)

  [14](#Fn14_source)

[T2`www.theguardian.com/technology/2016/feb/28/what-happened-after-ashley-madison-was-hacked`](http://www.theguardian.com/technology/2016/feb/28/what-happened-after-ashley-madison-was-hacked)

  [15](#Fn15_source)

[T2`www.salesforce.com/content/dam/web/en_us/www/documents/e-books/state-of-the-connected-customer-report-second-edition2018.pdf`](http://www.salesforce.com/content/dam/web/en_us/www/documents/e-books/state-of-the-connected-customer-report-second-edition2018.pdf)

  [16](#Fn16_source)

[T2`https://ico.org.uk/about-the-ico/news-and-events/news-and-blogs/2019/07/ico-announces-intention-to-fine-british-airways/`](https://ico.org.uk/about-the-ico/news-and-events/news-and-blogs/2019/07/ico-announces-intention-to-fine-british-airways/)

  [17](#Fn17_source)

[T2`www.equifaxbreachsettlement.com`](http://www.equifaxbreachsettlement.com)

  [18](#Fn18_source)

[T2`https://ico.org.uk/about-the-ico/news-and-events/news-and-blogs/2019/07/statement-intention-to-fine-marriott-international-inc-more-than-99-million-under-gdpr-for-data-breach/`](https://ico.org.uk/about-the-ico/news-and-events/news-and-blogs/2019/07/statement-intention-to-fine-marriott-international-inc-more-than-99-million-under-gdpr-for-data-breach/)

 </aside>