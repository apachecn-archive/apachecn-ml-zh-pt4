# 10.伦理与人工智能

AI，尤其是 ANI(人工狭义智能)，开始在我们的生活中占据独特的位置。有虚拟个人助理，智能手机上的智能应用主机，自动驾驶汽车，智能家电，智能建筑，智能家居，等等。没有其他技术像人工智能一样，对如此多的行业和我们生活的所有领域产生如此深远的影响。这就是它如此迷人的原因；这真是不可思议，不亚于科幻小说的情节。

对于一种旨在模仿人类智能的技术来说，理解人工智能的黑暗面也同样重要，可能需要在政策层面上定义什么该做，什么不该做。如果我们想真正利用人工智能的变革力量，我们需要解决许多问题。

在接下来的 20 年里，专家预测人工智能将继续在转变和在许多情况下消除大量人类任务方面取得巨大进展。如果这种创新以道德的方式进行，并以人机合作为目标，我们就可以建立一个人类不再与机器竞争的未来。相反，我们将进入一个新的工作时代，不需要体力劳动，但需要更高的情商。

轻点智能手机屏幕就能叫到出租车，这或许已经成为一种生活方式。想象同样的事情，延伸到获得自动驾驶出租车！想象一下，为了适应下一波无人驾驶汽车，交通管理官员在管理交通和安全方面将不得不经历多大的困难。当然，交通部有他们的工作要做；他们也必须创新。

这只是一个例子，表明人工智能的影响是空前的。随着我们继续创新并利用人工智能解决新问题，我们必须同时关注道德使用和政策相关方面，因为这对整个社会都有影响，而不仅仅是少数行业或少数个人。我们必须采取一种民主的方式来应对技术导致的破坏的未来。

## 人工智能中的伦理问题

人工智能，在很多方面，是无孔不入的，同时也是挑衅性的。我们需要指导和框架来确保人工智能的道德使用，这是在人工智能进化阶段认真考虑与人工智能相关的道德的正确时间。

自省的能力造就了我们。但是，我们似乎急着把这个外包给算法。这种方法会带来严重的后果。我们很高兴看到自动化是如何提高我们的生活质量的，但我们并没有坐下来创建一个我们永远不会委托的活动列表。我们甚至还没有制定出明确划分人类和机器之间责任的指导原则。这些事情很重要。在缺乏基于价值观的标准和指导方针的情况下，人工智能制造商的偏见将接管并决定条款和条件。

道德不是说，不，你不能这样做。关键是要问你正在努力实现的目标是什么，你如何在不违背我们珍视的文化价值观的情况下实现这些目标。你可以做完全合法但非常不道德的事情。总是要求逆势观点的苏格拉底式过程并不总是有趣的，但沐浴在 AI 成就的荣耀中而不关注道德标准不再是一种可以接受的立场。

以下各节列出了在各种论坛上激烈辩论的主题。各阵营仍然存在分歧。

### 失业

当人工工作全部被 AI 辅助的机器取代，会发生什么？

文化方面，如社会地位以及随之而来的劳动分工，都受自动化程度的影响。在前工业时代，一个人从事体力劳动的能力决定了收入。渐渐地，我们进化并发明了自动化工作的方法，不是完全消除体力劳动，而是用机器增强人类的技能，这样我们就可以用更少的资源做更多的事情。结果呢？像机器操作员这样的新工作出现了，技能导向慢慢从体力劳动转向认知劳动，越来越强调与判断相关的技能。

例如，作为一个行业，卡车运输目前在全球雇用了数百万人。如果自动驾驶卡车在未来几年成为现实，卡车运输工作会发生什么变化？一方面，自动驾驶卡车可能会降低事故风险，不会显示出疲劳的迹象，会一直以可预测的方式行驶，降低运营成本，并大幅提高效率。因此，自动驾驶卡车似乎是一种道德选择。同样的情况可能会发生在其他行业和部门的大多数劳动力身上。

摆在我们面前的伦理问题是，当越来越多的工作自动化时，我们将如何处理手头的时间？我们目前的雇佣合同基于一个基本因素——我们出卖自己的时间来赚足够的钱来养活自己和家人。因此，如果基于时间的薪酬前景消失，我们需要找到新的赚钱方式。

### 不平等

我们如何奖励机器？

我们目前的大部分薪酬框架都是基于小时工资的。在风险和回报机制到位的情况下，很少有显著的变化，但总的来说，我们的服务始终等同于每小时的费率。如果人工智能将以很小的成本完成我们的大部分工作，公司将自然地转向更新的劳动力组合(人工智能代理的数量越来越多，人类劳动力越来越少)。这意味着更少的人会得到补偿。然而，公司所有者和其他投资于该公司的人将获得大部分收入。

如果你还没有注意到，这已经发生了，它正在创造一个不断扩大的贫富差距。商业模式围绕这种算法经济的公司雇佣更少的人，并在劳动力中分享他们创造的经济剩余的财富。

摆在我们面前的伦理问题是，如果我们真的走向一个没有体力工作的社会，我们如何为由更少的人和更多的机器组成的劳动力构建一个公平的补偿机制？

### 人类

机器将如何影响人类的行为？

一方面，我们正在享受让机器代表我们思考和行动的事实。另一方面，我们确实在改变人类的行为。这里有几个例子可以说明我们是如何被影响的:

*   网站的设计考虑到了迎合个人喜好的最细微的细节层次。

*   推荐引擎通过建议“像你一样的人已经购买了这些其他的东西”来向我们推送额外的产品。

*   当你开车经过一家超市时，你的手机震动了，只为你打折。

*   智能手机上的智能应用会建议走哪条路线才能更快到达目的地。

在正确的时间通过正确的渠道获得正确的信息是好事，但副作用是我们不再想任何事情。

摆在我们面前的伦理问题是这样的——首先，通过允许人工智能代理人代表我们思考和行动，我们是否正在走向一个我们对周围环境越来越无知的世界？第二，如果人工智能代理在模拟人类行为方面变得越来越好，那么同样的人工智能代理是否有可能被用来引导人类的注意力并触发某些对人类生存有害的行为？

### 人为的愚蠢

我们如何确保机器不会出现偏差？

人类通过从环境中学习来发展认知能力；机器也经历类似的学习阶段来获取智能。人类如果接触到不好的环境，就会学到不好的东西；如果数据不完整或被故意扭曲，机器学习也会面临类似的风险。

机器需要不断学习，需要接触各种各样的数据集，以便为处理现实世界中发生的事情做好准备。如果我们希望机器接受现实世界的挑战，仅仅依靠基于可用数据筛选的训练数据集是不够的。

人类并不总是公平中立的。机器也会表现出类似的不公平和不理性的行为。人工智能系统是由人类创造的，因此人类很有可能会在他们建造的机器中引入判断偏见。偏差也可以以许多不同的方式渗入机器行为——数据偏差和设计偏差是最突出的方式。

摆在我们面前的伦理挑战是，如果我们的未来将完全依赖于人工智能系统，我们需要确保机器按照预期运行，并且没有偏见。

### 安全性

我们如何让 AI 远离邪恶的意图？

技术变得越强大，恶意攻击的可能性就越大。自治系统需要更大的责任来保证它们的安全，我们需要担心的不仅仅是对手。如果人工智能代理变得如此专注于实现他们的目标，以至于他们推荐和实施可能给我们带来灾难性后果的事情，会怎么样？例如，如果一个人工智能系统的目标是找到癌症的解决方案，并且在仔细考虑了大量的诊断结果、根本原因、治疗计划和药物的有效性之后，它意识到解决癌症问题的最有效和最好的方法是杀死地球上的每个人，那会怎么样？从机器的角度来看，它已经找到了解决方案。从人类的角度来看，这是灾难性的。

摆在我们面前的伦理问题是，我们如何确保在我们开始在我们生活的所有领域使用人工智能系统之前，有足够的制衡机制，并像我们希望的那样无处不在？

### 奇异

我们如何管理人工超级智能系统？

人类的进化几乎完全是由于我们的智力和我们适应不断变化的环境的能力。然而，在我们发明越来越多的人工超级智能系统的热情中，我们可能会进入这样一个场景:机器是地球上最聪明的生物，远远超过人类！这种状态被称为“奇点”。

摆在我们面前的伦理问题是，即使它很遥远，有一天一个足够先进的机器可能会出现，并且这个机器将能够预测我们正在预测的事情，所以我们如何保持领先一步？

### 机器权利

我们如何定义人工智能的法律框架？

我们已经看到了奖励和厌恶机制是如何在人类生活中起决定性作用的。强化学习特别应用了一种虚拟的风险和回报机制，让人工智能主体学习并适应环境。

摆在我们面前的伦理问题是，一旦作为实体的机器达到足够的成熟水平，能够自主地观看、感知、思考和行动，它们就会要求一个法律框架来保护和管理它们的权利份额。应该像对待人类一样对待智能机器吗？他们应该有一个平行的法律和申诉系统吗？当一个人工智能代理因做错事而受到惩罚时，我们如何提供一个支持系统来让它理解自己的错误并保持动力在未来做得更好？当机器在做所有正确的事情，但人在回路中碍事时，我们如何解决这种情况？

## 董事会和首席执行官在道德人工智能中的角色

人工智能的预测措施旨在提供预期的结果。在现实世界中，这是唯一重要的一面。然而，正如人类是不完美的，主观的，容易腐败，机器也是如此。换句话说，尽管有既定的法律和协议，但我们社会中可疑的行为者找到了一种方法来玩弄这个系统。同样，AI 的有用性是公开的，人们可以出于恶意或自私的目的使用它。赌注越来越高。

因此，公司，特别是那些能够访问海量数据以及开发和部署人工智能产品和服务的公司，不仅应该要求工程师、企业家和高管具备更负责任的职业道德，还应该建立更自信的董事会和委员会，将道德人工智能作为他们的首要战略重点。

### 董事会的作用

传统行业的公司在定义企业道德时会求助于几十年的法律、法规和诉讼来寻求指导。然而，对于像人工智能这样具有变革性和颠覆性的东西，没有任何先验知识。规范和标准仍在出现；法律、法规和法律先例很少。这就是为什么董事会成为人工智能企业道德的积极支持者非常重要，使其与增长、盈利能力、M&A 目标和继任规划等其他问题一起成为重中之重。

董事会应该让首席执行官负责让人工智能伦理成为企业的优先事项。例如，董事们不应该表面上认为公司的人工智能产品和举措不会无意中助长偏见。相反，董事会成员应该规定，人工智能产品和计划应该不断接受压力测试，以发现人工智能偏见并采取补救措施。

### 首席执行官的角色:人工智能伦理的卓越治理

首席执行官可以通过三种方式建立他们的人工智能道德和治理审慎。

首先，首席执行官应该加强和扩大自己的知识，涵盖从人工智能偏见到透明度和问责制最佳实践的各种问题。他们还应该深刻意识到他们公司的人工智能产品和服务的含义，包括数据来源和算法的性质/类型。首席执行官们还应该建立一个专门的智库，收集全行业有关人工智能道德相关诉讼的信息，以及客户提出的担忧和政策制定者的观点。这将有助于首席执行官在整个企业范围内进行管理简报，并提高认识水平。

其次，首席执行官应该让高级顾问加入他们的智囊团，他们可以为董事会带来关于人工智能影响的更多观点。例如，如果你的公司正在提供与人力资源相关的人工智能产品和服务，那么引入一位高级顾问来批判性地审查与多样性、包容性、劳工和民权法规相关的偏见是否被充分边缘化是至关重要的。

第三，首席执行官们必须意识到，有道德的人工智能不能是事后的想法。应该在人工智能系统开发过程的核心建立足够的检查和平衡，以确保技术专家不会在开发人工智能系统时忘乎所以，而不注意使人工智能透明。我们不能忽视部署人工智能系统的风险，这些系统一方面工作得非常好，但另一方面却无法完全解释。因此，首席执行官必须确保企业配备了正确的工具、方法和审查机制。

### 技术专家的角色

技术专家和人工智能专家必须注意人工智能系统的目的和目标。更容易说的是算法高度精密但数据有偏差。真实世界的数据总是有偏差的，因为它是视情况而定的。人工智能专家的责任是充分理解数据背后的上下文，然后设计算法来支持人类的价值观。

## 结论

重要的是将人工智能中对公平的追求与商业利益脱钩，并为公平透明的人工智能解决方案创造空间。为此，让人工智能变得可解释至关重要。

基于人工智能的颠覆性力量建立商业战略的公司陷入了困境:让他们的人工智能透明的成本和收益是什么？他们如何保护自己的知识产权和竞争优势？

诚然，现在有一些经验法则或最佳实践。或许，对于每一个人工智能系统，如果我们能够详细说明所使用的数据类型、数据源的细节、预测模型开发中使用的参数、达到的准确度水平以及关于假阳性和假阴性的统计数据，我们可能会达到一个普遍认可的透明度水平，这可能会进一步导致建立一套普遍接受的道德人工智能标准。

在这一章中，我们讨论了人工智能后果的几个伦理相关的观点。在下一章中，我们将总结前几章的所有经验，并尝试建立一些方法来构建一个人机合作的生态系统。

## 参考

1.  [T2`https://80000hours.org/articles/ai-policy-guide/`](https://80000hours.org/articles/ai-policy-guide/)

2.  [T2`https://medium.com/artificial-intelligence-policy-laws-and-ethics/the-ai-landscape-ea8a8b3c3d5d`](https://medium.com/artificial-intelligence-policy-laws-and-ethics/the-ai-landscape-ea8a8b3c3d5d)

3.  [T2`https://www.cs.ox.ac.uk/efai/category/codes-of-ethics/`](https://www.cs.ox.ac.uk/efai/category/codes-of-ethics/)

4.  [T2`https://www.wired.com/story/ai-research-is-in-desperate-need-of-an-ethical-watchdog/`](https://www.wired.com/story/ai-research-is-in-desperate-need-of-an-ethical-watchdog/)

5.  [T2`https://mashable.com/2015/10/03/ethics-artificial-intelligence/#kyYeZZHNMsqD`](https://mashable.com/2015/10/03/ethics-artificial-intelligence/#kyYeZZHNMsqD)

6.  [T2`https://techcrunch.com/2017/01/22/ethics-the-next-frontier-for-artificial-intelligence/`](https://techcrunch.com/2017/01/22/ethics-the-next-frontier-for-artificial-intelligence/)

7.  [T2`http://www.zdnet.com/article/artificial-intelligence-legal-ethical-and-policy-issues/`](http://www.zdnet.com/article/artificial-intelligence-legal-ethical-and-policy-issues/)

8.  [T2`https://www.weforum.org/agenda/2016/10/top-10-ethical-issues-in-artificial-intelligence/`](https://www.weforum.org/agenda/2016/10/top-10-ethical-issues-in-artificial-intelligence/)

9.  [T2`https://www.weforum.org/agenda/2016/10/top-10-ethical-issues-in-artificial-intelligence/`](https://www.weforum.org/agenda/2016/10/top-10-ethical-issues-in-artificial-intelligence/)