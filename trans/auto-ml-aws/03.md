

# *第二章*:使用 SageMaker 自动驾驶器自动化机器学习模型开发

AWS 提供了许多自动化 ML 模型开发的方法。在这一章中，我将介绍这样一种方法， **SageMaker 自动驾驶器**。Autopilot 是一个自动执行典型 ML 流程关键步骤的框架。这允许新手以及有经验的 ML 从业者将数据探索、算法选择、模型训练和模型优化的手动任务委托给专门的 AWS 服务，基本上自动化了端到端的 ML 过程。

在我们开始深入了解 AWS 为 ML 过程自动化提供的本机功能之前，首先了解它们的适用范围、这些功能是什么以及我们将如何使用它们是很重要的。

在这一章中，我们将向您介绍一些专注于 ML 解决方案的 AWS 功能，以及 ML 自动化。在本章结束时，您将对如何使用 AWS 服务实现 AutoML 方法来自动化 *ACME Fishing Logistics* 用例有一个实际的概述。我们将讨论以下主题:

*   介绍 AWS AI 和 ML 前景
*   SageMaker 自动驾驶器概述
*   使用 pagemaker autopilot 克服自动化挑战
*   使用 pagemaker sdk 自动化 ml 实验

# 技术要求

在开始学习本章之前，您应该具备以下先决条件:

*   熟悉 AWS 及其基本用法。
*   web 浏览器(为了获得最佳体验，建议您使用 Chrome 或 Firefox 浏览器)。
*   一个 AWS 账户(如果你不熟悉如何开始使用 AWS 账户，你可以去这个链接:[https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/))。
*   熟悉 AWS 免费层(免费层将允许您免费访问一些 AWS 服务，具体取决于资源限制；你可以通过这个链接来熟悉这些限制:[https://aws.amazon.com/free/](https://aws.amazon.com/free/)。
*   本章的示例 Jupyter 笔记本在配套的 GitHub 资源库([https://GitHub . com/packt publishing/Automated-Machine-Learning-on-AWS/blob/main/chapter 02/auto pilot % 20 example . ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-on-AWS/blob/main/Chapter02/Autopilot%20Example.ipynb))中提供。

# 介绍 AWS AI 和 ML 前景

AWS 为其客户提供各种各样的**人工智能** ( **AI** )和 ML 功能。为了进一步帮助其客户更好地理解这些功能，AWS 已经将它们分组并组织到中，通常称为 **AI/ML 堆栈**。AI/ML 栈背后的主要目标是提供开发者或 ML 从业者可能使用的必要资源，这取决于他们的专业水平。基本上，它将 AI 和 ML 能力放在每个开发人员的手中，无论他们被认为是新手还是专家。*图 2.1* 显示了组成 AWS AI/ML 堆栈的层。

![Figure 2.1 – Layers of the AWS AI/ML stack
](img/B17649_02_01.jpg)

图 2.1–AWS AI/ML 堆栈的层

正如您从*图 2.1* 中看到的，AI/ML 堆栈通过将 AWS 功能分组为三个特定的层，实现了将 AI 和 ML 功能交到每个开发人员手中的目标，其中每一层都包含典型的 AWS AI/ML 资源，这些资源既满足用例需求，也满足实践者的舒适程度和专业知识。

例如，如果专业的 ML 从业者希望使用 Kubernetes 构建自己的模型培训和托管架构，那么 AI/ML 堆栈的底层将为他们提供构建该基础架构所需的所有 AWS 资源。专用的**弹性计算云** ( **EC2** )实例等资源，所有 ML 库都预打包为**亚马逊机器映像**(**ami**)，用于基于 CPU 和基于 GPU 的模型训练和托管。因此，AI/ML 堆栈的最底层需要高度的专业知识，因为 ML 从业者具有最大的灵活性，但也是最困难的任务，即创建他们自己的 ML 基础设施来解决 ML 用例。

或者，如果一个 ML 从业新手需要交付一个解决特定用例的 ML 模型，例如图像和视频中的**对象检测**，而他们没有必要的专业知识，那么 AI/ML 栈的顶层将为他们提供 AWS 资源来完成这一任务。例如，顶层的一个专用人工智能服务,**亚马逊识别**，提供了一个预先构建的识别图像和视频中物体的能力。这意味着 ML 从业者可以简单地将 Rekognition 服务集成到他们的生产应用程序中，而不必构建、训练、优化甚至托管他们自己的 ML 模型。因此，通过在栈的顶层使用这些应用的 AI 服务，关于模型的细节、所使用的训练数据或者哪些超参数被调优都从用户那里抽象出来。因此，这些应用的人工智能服务更容易使用，并为业务用例提供更快的平均交付时间。

沿着堆栈往下，我们看到 ML 从业者负责配置关于模型、调整的超参数和训练数据集的具体细节。因此，为了帮助他们的客户完成这些任务，AWS 在 AI/ML 堆栈的中间层提供了一个专门的服务，称为 Amazon SageMaker。SageMaker 很好地适应了这种情况，因为它为有经验的 ML 实践者提供了处理复杂 ML 用例的灵活性和功能性，而不必构建和维护任何基础设施。从 ML 从业新手的角度来看，SageMaker 允许他们使用其内置功能来轻松地构建、培训和部署简单和高级的 ML 用例。

尽管 SageMaker 是一个单独的 AWS 服务，但它有几个功能或模块来处理 ML 过程中每一步的所有繁重工作。新手和有经验的 ML 从业者都可以利用集成 ML 开发环境(SageMaker Studio)或 Python SDK (SageMaker SDK)来探索和争论大量数据，然后构建、训练、调整、部署和监控他们的 ML 模型。*图 2.2* 显示了这些 SageMaker 模块如何映射和缩放 ML 流程的每个步骤:

![Figure 2.2 – Overview of SageMaker's capabilities
](img/B17649_02_02.jpg)

图 2.2–sage maker 功能概述

我们不会深入探讨图 2.2 中突出显示的功能，因为我们将在后面的章节中利用一些功能，因此，我们将解释它们是如何工作的。现在，让我们更深入地研究负责自动化 ML 过程的本机 SageMaker 模块，称为 SageMaker Autopilot。

# SageMaker 自动驾驶器概述

SageMaker Autopilot 是 AWS 服务，为其客户提供 AutoML 功能。Autopilot 通过将以下 SageMaker 模块整合到一个自动化框架中，解决了 AutoML 的各种需求:

*   **SageMaker Processing** :处理作业处理组织、验证和特征工程数据的繁重提升和扩展需求，所有这些都使用一种简化和可管理的体验。
*   **SageMaker 内置算法** : SageMaker 通过提供几个迎合多种用例类型的预建算法，帮助 ML 从业者开始建模任务。
*   **SageMaker 培训**:培训任务负责与提供所需计算资源以培训模型相关的繁重的提升和扩展任务。
*   **自动模型调优**:模型调优或超参数调优通过允许 ML 从业者并行执行多个训练任务来扩展模型调优任务，每个训练任务具有所需参数的子集。这消除了必须依次调整、评估和重新训练模型的迭代任务。默认情况下，SageMaker 模型调整使用**贝叶斯搜索** ( **随机搜索**也可以配置)来创建先前使用的超参数的性能的概率模型，以选择更好地优化模型的未来超参数。
*   **SageMaker Managed Deployment**: Once an optimized model has been trained, SageMaker Hosting can be used to deploy either a single model or multiple models as a fully functioning API for production applications to consume in an elastic and scalable fashion.

    小费

    关于这些 SageMaker 模块的更多信息，你可以参考 AWS 文档([https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html))。

Autopilot 将这些功能联系在一起，创建一个自动化的工作流程。ML 从业者必须提供的唯一部分是原始数据。因此，Autopilot 使得即使是 ML 新手也能很容易地自动创建一个生产就绪的模型，只需简单地提供数据。

让我们从自动驾驶开始，这样你就可以看到这个过程是多么简单。

# 利用 SageMaker 自动驾驶器克服自动化挑战

在 [*第 1 章*](B17649_01_ePub.xhtml#_idTextAnchor015) 、*AWS 上的自动化机器学习入门*中，我们实际上强调了ML 从业者在创建生产就绪的 ML 模型时所面临的挑战。概括来说，这些挑战分为两大类:

*   构建最佳 ML 模型所带来的挑战，例如获取和理解数据，然后为用例构建最佳模型
*   ML 过程本身带来的挑战，事实上它是复杂的、手动的、迭代的和连续的

因此，为了更好地理解 Autopilot 是如何克服这些挑战的，我们必须了解 Autopilot 工作流的解剖，以及它与我们在第一章 、*AWS 自动机器学习入门*中讨论的示例 ML 过程的比较。

在我们开始使用 Autopilot 之前，我们需要明白有多种方式与服务交互。例如，我们可以使用 AWS **命令行接口** ( **CLI** )，使用**软件开发工具包**(**SDK**)以编程方式调用服务**应用程序编程接口** ( **API** )，或者简单地使用 **SageMaker Python SDK** 。然而，Autopilot 提供了一个额外的、易于使用的界面，它被集成到 SageMaker Studio 中。在这个例子中，我们将使用 **SageMaker Studio IDE** 。

下一节将带您通过 SageMaker 自动驾驶器将 AutoML 方法应用于*鲍鱼计算器*用例。

## 【SageMaker Studio 入门

根据您的个人或组织使用需求，SageMaker Studio 提供多种方式开始使用。例如，如果 ML 从业者是作为团队一部分工作的，那么可以为团队配置 **AWS 单点登录** ( **SSO** )或 **AWS 身份&访问**用户。但是，对于这个示例用例，我们将使用快速启动程序来启动 Studio，因为这对于个人用户访问来说是最方便的。以下步骤将指导您设置 Studio 界面:

1.  Log into your AWS account and select an AWS region where SageMaker is supported.

    注意

    如果你不确定哪些 AWS 地区支持 SageMaker，可以参考以下链接:SageMaker 支持的地区和配额([https://docs . AWS . Amazon . com/sage maker/latest/DG/Regions-Quotas . html](https://docs.aws.amazon.com/sagemaker/latest/dg/regions-quotas.html))。

2.  在搜索栏中输入`SageMaker`，或者从**服务**下拉菜单中点击**亚马逊 SageMaker** ，导航至 SageMaker 服务控制台。
3.  使用左侧导航面板，点击 **SageMaker 域**选项下的**工作室**。
4.  由于这是第一次配置 SageMaker Studio 域，**设置 SageMaker 域**控制台将提供两个设置选项，即**快速设置**和**标准设置**。*图 2.3* 显示了屏幕应该是什么样子:

![Figure 2.3 – Getting started with SageMaker Studio
](img/B17649_02_03.jpg)

图 2.3–sage maker Studio 入门

1.  选择**快速设置**选项，默认为**用户档案**下的**名称**。
2.  点击**默认执行角色**下拉菜单，选择**创建新角色**。
3.  一旦**创建 IAM 角色**对话框打开，选择**任意 S3 桶**选项，如图*图 2.4* 所示:

![Figure 2.4 – Create an IAM role dialog
](img/B17649_02_04.jpg)

图 2.4–创建 IAM 角色对话框

1.  点击**创建角色**按钮关闭对话框并返回**设置 SageMaker 域**屏幕。
2.  单击新创建的 IAM 角色，打开 IAM 控制台摘要页面仪表板。
3.  现在点击`Permissions policies`部分，打开**创建策略**屏幕。
4.  点击**创建策略**屏幕右上角的**导入托管策略**选项。
5.  一旦**导入托管策略**对话框打开，选中**管理员访问**旁边的单选按钮，然后点击**导入**按钮。
6.  在**创建策略**屏幕上，点击**审查策略**按钮。
7.  Once the `AdminAccess-InlinePolicy`, and then click the **Create policy** button.

    注意

    在生产场景中，不建议向管理员提供对 SageMaker 执行角色的访问权限。由于我们将在本书的实践示例中访问各种其他 AWS 服务，因此我们将使用管理员访问策略来简化服务权限。

8.  关闭 IAM 控制台选项卡，返回 SageMaker 控制台。
9.  将其余的**设置 SageMaker 域**选项保留为默认值，并点击**提交**按钮。
10.  If you are prompted to select a VPC and subnet, select any subnet in the default VPC and click the **Save and continue** button.

    注意

    如果你不熟悉什么是 VPC，可以参考下面的 AWS 文档([https://docs . AWS . Amazon . com/VPC/latest/user guide/what-is-Amazon-VPC . html](https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html))。

11.  几分钟后，SageMaker Studio 域和用户将被配置，如*图 2.5* 所示，您应该会看到 SageMaker 域:

![Figure 2.5 – Studio control panel
](img/B17649_02_05.jpg)

图 2.5–演播室控制面板

1.  点击您在*步骤 5* 中创建的默认名称旁边的**启动应用**下拉框，然后点击 **Studio** 启动 Studio IDE web 界面。
2.  Studio 将需要几分钟启动，因为这是 Jupyter 服务器第一次被初始化。

现在我们已经有了在线的 Studio UI，我们可以开始使用 Autopilot 了。但首先，我们需要原始数据。

## 准备实验数据

Autopilot 将 ML 过程的每一次调用都视为一次实验，正如您将看到的，使用 Studio 创建一个实验既简单又直接。然而，在实验开始之前，我们需要为实验提供原始数据。

回想一下从 [*第一章*](B17649_01_ePub.xhtml#_idTextAnchor015) ，*AWS 上的自动机器学习入门*，原始数据是从 UCI 仓库下载的。我们提供了该数据的副本，以及已经添加到附带的 GitHub 存储库中的列名([https://GitHub . com/packt publishing/Automated-Machine-Learning-on-AWS/blob/main/chapter 02/鲍鱼 _with_headers.csv](https://github.com/PacktPublishing/Automated-Machine-Learning-on-AWS/blob/main/Chapter02/abalone_with_headers.csv) )。为了让任何 SageMaker 模块与数据进行交互，需要使用亚马逊**简单存储服务** ( **S3** )将数据上传到 AWS 云并存储为一个对象。

注意

如果你不熟悉什么是 S3 以及它是如何工作的，你可以查看一下产品网站([https://aws.amazon.com/s3](https://aws.amazon.com/s3))。

使用下列程序将自动驾驶器实验的原始数据上传到 S3:

1.  将前面的文件从附带的存储库中下载到您的本地计算机上。
2.  要将文件上传到亚马逊 S3，请在新的 web 浏览器选项卡中打开 S3 控制台([https://s3.console.aws.amazon.com/s3](https://s3.console.aws.amazon.com/s3)),然后单击以 sagemaker-studio 开头的存储段名称。当您使用快速启动流程加入 Studio 时，系统会自动为您创建这个 S3 存储区。
3.  如图 2.6 所示，sagemaker-studio-…桶是空的。要将原始数据文件上传到桶中，点击**上传**按钮，打开如图*图 2.6* 所示的对话框:

![Figure 2.6 – SageMaker Studio bucket
](img/B17649_02_06.jpg)

图 2.6–sage maker 工作室桶

1.  将`abalone_with_headers.csv`文件从其下载位置上传到**对话框的**屏幕。然后点击**上传**按钮，如图*图 2.7* 所示:

![Figure 2.7 – File upload
](img/B17649_02_07.jpg)

图 2.7–文件上传

1.  一旦上传了文件，点击**关闭**按钮。

现在我们有了驻留在 AWS 中的数据，我们可以使用它来启动自动驾驶实验。

## 开始自动驾驶实验

现在数据已经上传完毕，我们可以用它来开始自动驾驶实验了:

1.  使用 Studio UI，单击左侧边栏上的 **SageMaker 组件和注册表**图标:

![Figure 2.8 – SageMaker Component and registries icon
](img/B17649_02_08.jpg)

图 2.8–SageMaker 组件和注册表图标

这将打开 **SageMaker 资源**导航窗格。

小费

如果你不熟悉导航 Studio UI，请参考 AWS 文档中的亚马逊 SageMaker Studio UI 概述([https://docs . AWS . Amazon . com/SageMaker/latest/DG/Studio-UI . html](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-ui.html))。

1.  在下拉菜单中选择**实验** **和试验**，然后点击**创建自动驾驶实验**按钮，如图*图 2.9* 所示，打开**创建实验**页签:

![Figure 2.9 – Create Autopilot Experiment
](img/B17649_02_09.jpg)

图 2.9–创建自动驾驶器实验

1.  通过**创建实验**选项卡，您可以设置自动驾驶器实验的关键配置参数。
2.  在`abalone-v0`中作为实验名称:

![Figure 2.10 – Experiment name
](img/B17649_02_10.jpg)

图 2.10-实验名称

小费

在实践中，将实验开始的日期和时间或者其他形式的版本信息作为实验名称的一部分是一个好主意。这样，ML 从业者可以很容易地跟踪实验谱系以及各种实验资产，并确保这些在多个实验之间是可区分的。例如，如果我们在 2021 年 7 月 1 日为鲍鱼数据集创建一个实验，我们可以将该实验命名为`abalone-712021-v0`。

*   `abalone_with_headers.csv`您之前上传的文件:

![Figure 2.11 – Input data location
](img/B17649_02_11.jpg)

图 2.11–输入数据位置

*   **目标属性名称**:这是原始数据集中特征列的名称，Autopilot 将根据它学习做出准确的预测。在**目标**下拉框中，选择**环**作为目标属性:

![Figure 2.12 – Target attribute name
](img/B17649_02_12.jpg)

图 2.12–目标属性名称

注意

ML 从业者必须提供目标标签的事实强调了在使用 Autopilot 时必须考虑的关键因素。自动驾驶只支持监督学习用例。基本上，自动驾驶器只会尝试拟合回归和分类(二元和多类)问题的支持模型。

*   `output`为**数据集目录名**用来存储实验输出数据:

![Figure 2.13 – Output data location
](img/B17649_02_13.jpg)

图 2.13–输出数据位置

*   **问题类型**:该字段指定要解决的 ML 问题的类型。如前所述，这可能是一个回归、二元分类或多类分类问题。在本例中，我们将通过从下拉框中选择 **Auto** ，让 Autopilot 决定我们要解决的问题:

![Figure 2.14 – Problem type
](img/B17649_02_14.jpg)

图 2.14-问题类型

小费

一些更有经验的 ML 实践者可能能够基于用例立即确定问题的类型，并且因此能够指定自动驾驶问题的类型。如果 ML 从业新手不能推断 ML 问题的类型，他们应该将该参数设置为 **Auto** ，因为 Autopilot 有能力确定 ML 问题的类型。

*   **自动部署**:该选项指定是否将最佳模型自动部署为生产就绪、SageMaker 托管的端点。在本例中，将**自动部署**选项设置为**关闭**，以免产生不必要的 AWS 成本:

![Figure 2.15 – Auto deploy
](img/B17649_02_15.jpg)

图 2.15–自动部署

1.  要开始自动化实验，点击**创建实验**按钮。

实验现在正在运行，正如您所见，使用 Autopilot 创建生产级模型的过程非常简单。然而，您可能想知道在后台实际发生了什么，以产生这种生产级模型。让我们来看看实验中实际发生的幕后情况。

## 运行自动驾驶器实验

一旦创建了实验，Autopilot 将为生产创建最佳候选。整个过程大约需要 2 个小时才能完成，并且可以在实验专用的 Studio UI 选项卡中跟踪进度。*图 2.16* 显示了一个示例实验选项卡:

![Figure 2.16 – Experiment tab
](img/B17649_02_16.jpg)

图 2.16–实验选项卡

随着实验的进行，组成实验的各种试验将显示在实验选项卡中，以及产生最佳模型的试验及其总体评估分数。*图 2.17* 显示了一个完整实验的例子:

![Figure 2.17 – Completed experiment
](img/B17649_02_17.jpg)

图 2.17-完成的实验

实验完成后，您可以右键单击最佳模型(或任何其他试验)并查看具体细节。提供了关于该模型的以下重要细节:

*   自动驾驶器根据原始数据评估的 ML 问题的类型
*   用于解决评估最大似然问题的算法
*   从训练模型中获得并用于评估其性能的指标
*   用于调整模型的优化参数
*   整个过程中产生的各种人工制品在 S3 的位置
*   可解释性报告，详细说明原始数据集中每个要素对预测的贡献
*   将模型部署为 pagemaker 托管端点的能力

因此，通过一个简单的过程，所有繁重的数据分析、模型构建、培训、评估和调整任务都已经自动化，并由 Autopilot 管理，使得新手 ML 从业者能够轻松克服 ML 过程带来的两个主要挑战。

虽然这对于没有经验的应用程序开发人员或 ML 新手来说可能足以简单地将模型投入生产，但是更有经验的 ML 从业者可能需要更多的证据来证明为什么特定的模型是最好的以及它是如何产生的。*图 2.18* 显示了自动驾驶器如何产生最佳模型的概述:

![Figure 2.18 – Overview of the AutoML process used by Autopilot
](img/B17649_02_18.jpg)

图 2.18-自动驾驶器使用的 AutoML 过程概述

从*图 2.18* 中可以看出，Autopilot 在后台自动执行六个关键任务:

1.  **数据分析**
2.  **候选生成**
3.  **特色工程**
4.  **候选调优**
5.  **最佳人选**
6.  **候选人部署**

让我们详细了解一下这个过程的每一步。

### 数据预处理

ML 过程的第一步是访问原始数据集并理解它，以便清理它并为模型训练做准备。Autopilot 会自动为我们执行数据分析和预处理步骤。在这里，Autopilot 利用 SageMaker 处理模块对原始数据集进行统计分析，并确定是否有任何缺失值。然后，Autopilot 会对数据进行重组和拆分，用于模型训练，并将输出数据存储在 S3。原始数据经过预处理后，就可以进入候选模型生成步骤了。

如果 Autopilot 在数据集中遇到任何缺失的值，它将尝试使用多种不同的技术来填充缺失的数据。例如，对于任何缺失的类别值，Autopilot 将创建一个独特的*未知*类别特征。或者，对于任何缺失的数值，Autopilot 将尝试使用特征列的*平均值*或*中值*来估算该值。

### 生成 AutoML 候选项

自动驾驶器执行的下一步是生成候选模型。本质上，每个候选模型都是一个 AutoML 管道定义，它详细描述了产生一个优化候选模型或最佳模型的工作流的各个部分。基于 Autopilot 对数据的统计理解，每个候选定义都详细说明了要训练的模型类型，然后基于该模型候选，设计最适合算法的功能所需的数据转换。

根据创建实验时指定的*问题类型*设置，Autopilot 将从 SageMaker 的内置估计器中选择合适的算法。在*鲍鱼计算器*的例子中，选择了 **Auto** ，因此，Autopilot 从分析数据集推断出这是一个回归问题，因此它创建了候选定义，每个候选定义实现了*线性学习算法*、 *XGBoost 算法*和*多层感知器*深度学习算法的变体。这些候选人中的每一个都有自己的一套训练和测试数据，以及要调整的特定超参数范围。Autopilot 创建多达 10 个候选定义。

小费

有关自动驾驶支持的算法的更多信息，可以查看 AWS 文档的模型支持和验证部分([https://docs . AWS . Amazon . com/sagemaker/latest/DG/auto pilot-Model-Support-Validation . html](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-model-support-validation.html))。

*图 2.18* 突出显示了来自**候选生成**步骤的输出，两个 Jupyter 笔记本:

*   *数据探索笔记本*:该笔记本概述了在**数据分析**步骤中分析的数据，并为 ML 从业者进一步调查提供指导。
*   *候选定义笔记本*:该笔记本提供了候选模型的详细概述、候选模型的推荐数据处理以及应该调整哪些超参数来优化候选模型。该笔记本甚至生成 Python 代码单元，通过适当的 SageMaker SDK 调用，来再现候选管道，从而为 ML 从业新手提供如何再现生产就绪模型的指导。

如果你还记得 [*第一章*](B17649_01_ePub.xhtml#_idTextAnchor015) ，*AWS 上的自动化机器学习入门*，一个高效的 AutoML 过程的特征之一是该过程必须是可重复的。通过提供候选人定义笔记本，Autopilot 不仅为 ML 从业者提供了操作指南，还允许他们构建流程并创建自己的候选人管道。

小费

由于 AutoML 在技术上只需执行一次，因此要获得生产部署的最佳候选，这些笔记本电脑可用作进一步定制和开发模型的基础。

在训练这些候选模型之前，必须对原始数据进行格式化，以适应候选管道将使用的特定算法。这个过程接下来发生。

### 自动化特征工程

AutoML 过程的下一步是特征工程阶段。在这里，Autopilot 再次利用 SageMaker 处理模块来设计这些新功能，具体到每个候选模型。然后，Autopilot 创建包含这些特征的训练和验证数据集变体，并将它们存储在 S3 上。每个候选人现在都有自己的格式化训练和测试数据集。现在训练过程可以开始了。

### 自动化模型调整

在过程的这个阶段，Autopilot 拥有必要的组件来训练每个候选模型。与典型的 ML 过程不同，其中每个候选人都被训练、调整和评估，Autopilot 利用 SageMaker 的自动模型调整模块来并行执行该过程。

正如本章开头所解释的，超参数优化模块使用*贝叶斯搜索*来寻找模型的最佳参数。然而，Autopilot 更进了一步，利用 SageMaker 的本机功能来扩展跨多种算法的调优能力。本质上，自动驾驶器不仅为单个候选模型找到最佳超参数，而且在与所有其他候选模型比较时找到最佳超参数。

正如已经提到的，自动驾驶器并行地执行这个过程，用超参数的子集训练、调整和评估每个候选模型，以便获得最佳候选模型和那个子集的相关超参数，作为试验。然后重复该过程，不断改进超参数，直到默认的 250 次试验。这种能力极大地减少了产生优化模型的总时间，与使用手动 ML 过程时的几天或几周相比，只需几个小时。

调整过程产生多达 250 个候选模型。接下来我们来回顾一下这些候选模型。

### 候选模型选择

如图 2.17 中的*所示，产生最佳评估指标结果的模型被标记为**最佳**。*

这个步骤的输出是每个试验的模型和相关的工件，以及一个可解释的报告。自动驾驶使用另一个 SageMaker 模块，称为 **SageMaker Clarify** ，来产生这个报告。

Clarify 通过量化数据集的每个特征对模型整体预测的贡献，帮助 ML 从业者理解训练模型如何以及为什么做出某些预测。这不仅有助于 ML 从业者，也有助于用例涉众理解模型如何决定其预测。理解为什么一个模型做出某些预测，促进了对模型处理业务用例的目标和需求的能力的进一步信任。

小费

有关 SageMaker Clarify 用来量化特征属性的过程的更多信息，你可以参考 SageMaker 文档中的模型可解释性页面([https://docs . AWS . Amazon . com/sage maker/latest/DG/Clarify-Model-explability . html](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-explainability.html))。

实验现在已经完成了，所以所有留给 ML 从业者去做的就是将*最佳*候选部署到生产中。

### 候选模型部署

现在最好的模型可以是自动或手动部署为 **SageMaker 托管端点**。这意味着现在最好的候选是一个 API，可以通过编程调用它来为生产应用程序提供预测。然而，简单地将模型部署到生产中并不能停止 ML 过程。这个过程是连续的，在实验之后还有许多任务要完成。

## 实验后任务

在前一章中，我们强调了 **CRISP-DM** 方法以模型被部署到生产中而结束，我们还强调了生产一个生产就绪的模型不一定是 ML 实践者的责任的结论。

同样的概念也适用于 AutoML 过程。虽然 Autopilot 负责生成生产就绪模型的各个步骤，但这通常是针对特定用例的一次性过程，Autopilot 会在模型部署后结束实验。另一方面，ML 从业者的义务是持续的，因为生产模型需要被持续监控以确保它不会偏离其预期目的。

然而，通过为每个候选模型以及候选笔记本提供所有的输出工件，Autopilot 为 ML 从业新手奠定了坚实的基础，以便在部署的模型偏离其预期目的时，闭合 ML 过程的循环并持续优化未来的生产模型。

此外，SageMaker 托管端点提供了额外的功能，有助于持续监控生产模型的概念漂移。例如，如果 ML 从业者决定在 Studio UI 中手动部署最佳候选模型，他们可以在选择最佳候选模型并点击**部署模型**按钮时启用数据捕获。*图 2.19* 显示了在使用 Studio UI 部署模型之前可用的选项:

![Figure 2.19 – Deployment options
](img/B17649_02_19.jpg)

图 2.19–部署选项

启用**数据捕获**设置将端点配置为捕获所有传入的预测请求作为，以及来自已部署模型的预测响应。SageMaker 的 Model Monitor 功能可以使用捕获的数据来实时监控生产模型，持续评估其对未知请求的性能，并寻找概念偏差。

小费

有关 SageMaker Model Monitor 执行的监控类型的更多信息，您可以参考 SageMaker 文档([https://docs . AWS . Amazon . com/sage maker/latest/DG/Model-Monitor . html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html))。

从这个例子中，您可以看到，通过利用 Studio UI 来创建和管理 AutoML 实验(使用 Autopilot ),软件开发人员或 ML 新手可以很容易地创建一个生产级 ML 模型，几乎没有经验，也不需要编写任何代码。

然而，一些有经验的 ML 实践者可能更喜欢文档，并使用 Jupyter 笔记本来整理实验，以便它是可重复的。在下一节中，我们将看看如何编写 AutoML 实验。

# 使用 SageMaker SDK 自动化 ML 实验

在 [*第 1 章*](B17649_01_ePub.xhtml#_idTextAnchor015) 、*AWS 上的自动化机器学习入门*中，为提供了样本代码，让通过手动和迭代的 ML 过程。由于 SageMaker 是一个 AWS web 服务，我们也可以使用代码通过使用用于 AWS 的**Python SDK**或 **boto3** 与它的各种模块进行交互。更重要的是，AWS 还为 SageMaker 提供了专用的 Python SDK，名为 SageMaker SDK。

本质上，SageMaker SDK 是一个更高级别的 SDK，它使用底层的 boto3 SDK，专注于 ML 实验。例如，要将模型部署为 SageMaker 托管的端点，ML 从业者必须使用三个不同的 boto3 调用:

1.  ML 从业者必须使用来自 SageMaker 培训作业的输出工件实例化一个经过培训的模型。这是使用 boto3 的底层 SageMaker 客户端`boto3.client("sagemaker")`的`create_model()`方法完成的。
2.  接下来，ML 从业者必须创建一个 SageMaker 托管端点配置，为端点指定底层计算机资源和附加配置设置。这是使用 SageMaker 客户端的`create_endpoint_config()`方法完成的。
3.  最后，使用`create_endpoint()`方法部署具有端点配置设置的已训练模型。

或者，ML 从业者可以通过简单地在已经训练好的模型上使用`deploy()`方法，使用 SageMaker SDK 来完成相同的目标。SageMaker SDK 创建底层模型、端点配置，并自动部署端点。

使用 SageMaker SDK 使得更有经验的 ML 从业者进行 ML 实验变得更加容易。在下一节中，您将通过一个例子来编写 AutoML 实验，从而开始熟悉 SageMaker SDK。

## 编纂自动驾驶器实验

就像 ML 从业者使用 Jupyter 笔记本来执行手动和交互式 ML 实验一样，Studio UI 也可以用来完成这些相同的任务。Studio IDE 提供了基本的 Jupyter 笔记本功能，并以 AWS 工程 Jupyter 内核的形式预装了 ML 从业者可能使用的所有 Python 库和深度学习框架。

小费

如果你不熟悉 Jupyter 内核的概念以及它们的使用方法，可以参考 Jupyter 文档网站([https://Jupyter-notebook-beginner-guide . readthedocs . io/en/latest/what _ is _ Jupyter . html # Kernel](https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html#kernel))。

让我们通过使用 Jupyter 笔记本执行下面的示例代码来看看这是如何工作的:

1.  使用 Studio UI 菜单栏，选择**文件** | **新建** | **笔记本**打开一个空白的 Jupyter 笔记本。
2.  如图*图 2.20* 所示，系统会提示您从预装的内核中选择一个合适的内核。从下拉列表中选择 **Python 3(数据科学)**:

![Figure 2.20 – Jupyter kernel selection
](img/B17649_02_20.jpg)

图 2.20–Jupyter 内核选择

1.  在后台，Studio 将初始化一个专用的计算环境，称为 **KernelGateway** 。这个计算环境，带有 *2 个 vcpu*和*4gb RAM，*实质上是执行 Jupyter 笔记本内各种代码单元的引擎。初始化此计算环境可能需要 2-3 分钟。
2.  Once the Kernel has started, we can create the first code cell, where we import the SageMaker SDK and configure the SageMaker session by initializing the `Session()` class. The `Session()` class is a wrapper for the underlying boto3 client, which governs all interactions with the SageMaker API, as well as other necessary AWS services:

    ```
    import sagemaker
    import pandas as pd
    role = sagemaker.get_execution_role()
    session = sagemaker.session.Session()
    ```

    小费

    如果你是 Jupyter 笔记本导航的新手，要执行一个代码单元格，你可以点击运行图标或者在高亮显示的单元格上按下 *Shift* + *Enter* 键。

3.  接下来，我们可以使用在 [*第 1 章*](B17649_01_ePub.xhtml#_idTextAnchor015) 、*AWS 自动机器学习入门*中使用的相同代码，从 UCI 存储库中下载原始鲍鱼数据集，添加必要的列标题，然后将文件保存为名为`abalone_with_headers.csv` :

    ```
    column_names = ["sex", "length", "diameter", "height", "whole_weight", "shucked_weight", "viscera_weight", "shell_weight", "rings"]
    abalone_data = pd.read_csv("http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data", names=column_names)
    abalone_data.to_csv("abalone_with_headers.csv", index=False)
    ```

    的 CSV 文件
4.  现在，我们可以配置自动驾驶实验，使用`AutoML()`类并使用下面的示例代码创建一个名为`automl_job` :

    ```
    from sagemaker.automl.automl import AutoML
    automl_job = AutoML(
        role=role,
        target_attribute_name="rings",
        output_path=f"s3://{session.default_bucket()}/abalone-v1/output",
        base_job_name="abalone",
        sagemaker_session=session,
        max_candidates=250
    )
    ```

    的变量

这个变量将与自动驾驶器实验相互作用。正如我们在上一节中所做的那样，我们还提供了实验的重要参数:

*   `target_attribute_name`:原始数据集中的特征列的名称，自动驾驶器将根据该特征列学习做出准确的预测。回想一下，这是`rings`属性。
*   实验产生的任何人工制品都存放在 S3。在前面的例子中，我们使用了在工作室入职过程中创建的默认 S3 存储桶。然而，在这个例子中，我们将使用 SageMaker `Session()`类提供的默认 bucket。
*   `base_job_name` or the name of the Autopilot experiment. Since we already have a version zero, we will name this experiment `abalone-v1`.

    注意

    没有向`base_job_name`参数提供版本信息。这是因为 SDK 会自动绑定当前日期和时间进行版本控制。

1.  为了启动自动驾驶实验，我们对`automl_job`变量调用`fit()`方法，为其提供原始训练数据的 S3 位置。我们也调用 SageMaker 会话`upload()`方法，作为`fit()`方法的参数，因为数据还没有上传到默认的 S3 存储桶。`upload()`方法将 bucket 名称(SageMaker 默认的 bucket)和前缀(文件夹结构)作为参数，自动将原始数据上传到 S3。下面的代码展示了一个如何正确调用`fit()`方法的例子:

    ```
    automl_job.fit(inputs=session.upload_data("abalone_with_headers.csv", bucket=session.default_bucket(), key_prefix="abalone-v1/input"), wait=False)
    ```

此时，自动驾驶实验已经开始，如前一节所示，可以使用 Studio UI 的 **SageMaker 组件和注册表**部分中的**实验和试验**下拉菜单来监控实验。右键点击当前自动驾驶实验，选择**描述自动驾驶作业**。

或者，我们可以对`automl_job`变量使用`describe_auto_ml_job()`方法，以编程方式获得自动驾驶作业的当前概览。

注意

记下 SDK 附加到作业名称的自动生成的版本信息。正如您将在后面看到的，这个作业名用于以编程方式探索实验以及清理实验。

为了使实验具有可重复性，一些 ML 从业者可能想要包括对结果模型的视觉比较。现在，AutoML 实验正在进行中，我们可以等待它完成，看看模型如何进行比较，并探索 SageMaker SDK 如何实现实验分析。

## 用代码分析自动驾驶器实验

一旦自动驾驶实验完成，我们可以使用 SageMaker SDK 中的`analytics()`类以编程方式探索各种候选模型(或试验)来比较候选评估结果，就像我们在上一节中使用 Studio UI 一样。

让我们通过使用同一个 Jupyter 笔记本执行以下示例代码来分析这个实验:

1.  我们需要做的第一件事是从 SageMaker SDK 加载`ExperimentAnalytics()`类，以获取试验组件数据，并使它们可用于分析。通过提供自动驾驶实验的名称，下面的示例代码实例化了`automl_experiment`变量，由此我们可以与实验结果进行交互。此外，由于 SageMaker SDK 自动为实验名称生成版本信息，我们可以再次使用`describe_auto_ml_job()`方法来查找 **AutoMLJobName** :

    ```
    from sagemaker.analytics import ExperimentAnalytics
    automl_experiment = ExperimentAnalytics(
        sagemaker_session=session,
        experiment_name="{}-aws-auto-ml-job".format(automl_job.describe_auto_ml_job()["AutoMLJobName"])
    )
    ```

2.  接下来，下面的示例代码将返回的`experiment` analytics 对象转换成 pandas DataFrame，以便于分析:

    ```
    df = automl_experiment.dataframe()
    ```

3.  这种分析的一个例子可能是直观地比较前五个试验的评估结果。以下示例代码分别在训练数据集和验证数据集上按最新的评估准确性指标`validation:accuracy – Last`和`train:accuracy - Last`筛选数据帧，然后按升序对这些值进行排序:

    ```
    df = df.filter(["TrialComponentName","validation:accuracy - Last", "train:accuracy - Last"])
    df = df.sort_values(by="validation:accuracy - Last", ascending=False)[:5]
    df
    ```

*图 2.21* 显示了该数据帧的示例:

![Figure 2.21 – Sample top 5 trials
](img/B17649_02_21.jpg)

图 2.21–前 5 名试验样本

1.  我们可以通过`matplotlib`库:

    ```
    import matplotlib.pyplot as plt
    %matplotlib inline
    legend_colors = ["r", "b", "g", "c", "m"]
    ig, ax = plt.subplots(figsize=(15, 10))
    legend = []
    i = 0
    for column, value in df.iterrows():
        ax.plot(value["train:accuracy - Last"], value["validation:accuracy - Last"], "o", c=legend_colors[i], label=value.TrialComponentName)
        i +=1
    plt.title("Training vs.Testing Accuracy", fontweight="bold", fontsize=14)
    plt.ylabel("validation:accuracy - Last", fontweight="bold", fontsize=14)
    plt.xlabel("train:accuracy - Last", fontweight="bold", fontsize=14)
    plt.grid()
    plt.legend()
    plt.show()
    ```

    使用一个图来进一步可视化比较

*图 2.22* 显示了合成图的示例:

![Figure 2.22 – Plot of the top 5 trials
](img/B17649_02_22.jpg)

图 2.22–前 5 项试验的曲线图

使用`ExperimentAnalytics()`类是与实验的各种试验进行交互的一种很好的方式，但是，您想简单地看看哪个试验产生了最佳候选。通过在自动驾驶作业上调用`best_candidate()`方法，我们不仅可以看到哪个试验产生了最佳候选人，还可以看到候选人最终评估指标的值。例如，以下示例代码生成最佳候选人的姓名:

```
automl_job.best_candidate()["CandidateName"]
```

当在 Jupyter 笔记本中执行上述代码时，您将看到类似如下的输出:

```
'abalone-2021-07-05-17-07-15-99Qg-240-9bfa065e'
```

同样，可以在另一个笔记本单元格中执行以下示例代码，以查看最佳候选人的评估指标:

```
automl_job.best_candidate()["FinalAutoMLJobObjectiveMetric"]
```

此代码的结果将类似于以下内容:

```
{'MetricName': 'validation:accuracy', 'Value': 0.292638897895813}
```

此外，正如上一节中的例子一样，您还可以通过编程查看**数据探索笔记本**、**候选人定义笔记本**和**可解释性报告**的 S3 位置。

以下代码示例可用于获取此信息:

*   **数据探索笔记本** :

    ```
    automl_job.describe_auto_ml_job()["AutoMLJobArtifacts"]["DataExplorationNotebookLocation"]
    ```

*   **候选人定义笔记本** :

    ```
    automl_job.describe_auto_ml_job()["AutoMLJobArtifacts"]["CandidateDefinitionNotebookLocation"]
    ```

*   **可说明性报告** :

    ```
    automl_job.describe_auto_ml_job()["BestCandidate"]["CandidateProperties"]["CandidateArtifactLocations"]["Explainability"]
    ```

使用 SageMaker SDK 的`analytics()`类和各种自动驾驶输出工件让我们能够进一步深入了解实验。剩下的就是部署生产模型了。

## 部署最佳候选人

AutoML 过程的最后一部分是将最佳模型部署为生产 API，作为 SageMaker 托管的端点。为了提供这一功能，SageMaker SDK 再次提供了一个简单的方法，称为`deploy()`。

注意

在 SageMaker 上托管最好的模型会产生 AWS 使用成本，超过免费层提供的成本。

让我们运行以下代码来部署最佳模型:

```
automl_job.deploy(
    initial_instance_count=1,
    instance_type="ml.m5.xlarge",
    candidate=automl_job.best_candidate(),
    sagemaker_session=session,
    endpoint_name="-".join(automl_job.best_candidate()["CandidateName"].split("-")[0:7])
)
```

与`fit()`方法一样，简单地调用`deploy()`方法并提供一些重要的参数将创建一个托管端点:

*   我们需要通过提供参数`instance_type`来提供处理推理请求的计算机资源的类型。在本例中，我们选择了`ml.m5.xlarge`实例。
*   然后我们需要指定实例的数量。在这种情况下，我们指定一个实例。
*   我们可以通过为特定的候选对象提供 Python 字典来部署特定的候选对象，或者，如果没有提供候选对象，`deploy()`方法将自动使用最佳候选对象。
*   Lastly, we need to provide the unique name for the endpoint. This name will be used to provide model predictions to the business application.

    小费

    在命名端点时，为了将特定的端点与产生它们的实验联系起来，使用提供给实验的版本信息是一个很好的实践。从前面的示例 Python 代码中，您可以看到我们通过使用`best_candidate()`方法并通过`"CandidateName"`过滤响应来派生`endpoint_name`。

一旦代码单元被执行，SageMaker 将自动在特定的计算资源上部署最佳模型，并使端点 API 可用于推理请求，从而完成实验。

注意

与前面的例子不同，在前面的例子中，使用 Studio UI 来部署模型，使用 SageMaker SDK 中的`AutoML()`类不包括在部署模型时启用数据捕获的能力。回想一下，捕获推理请求和推理响应的能力使 ML 从业者能够使用这些数据来连续地监控生产模型。建议您使用 SageMaker SDK 的`Model()`类来部署模型。该类允许您指定`data_capture_config`参数，如果您希望关闭连续模型监控的循环。你可以在 SageMaker SDK 文档(https://SageMaker . readthe docs . io/en/stable/API/inference/model . html # SageMaker . model . model . deploy)中了解更多关于`Model()`类的信息。

正如在 [*第 1 章*](B17649_01_ePub.xhtml#_idTextAnchor015) 、*AWS 上的自动化机器学习入门*中强调的*典型* ML 流程的情况一样，现在可以将部署的模型移交给应用程序开发负责人，让他们测试并将模型集成到生产应用程序中。然而，由于这个例子的预期目的是简单地演示如何进行所需的 SageMaker SDK 调用来执行 AutoML 实验，所以我们不打算使用这个模型来测试推论。相反，下一节将演示如何删除端点。

## 打扫卫生

为了避免不必要的 AWS 使用成本，您应该删除 SageMaker 托管端点。这可以通过使用 AWS SageMaker 控制台([https://console.aws.amazon.com/sagemaker](https://console.aws.amazon.com/sagemaker))或使用 AWS CLI 来完成。在 Jupyter 笔记本中运行以下命令来清理部署:

1.  使用 AWS CLI 删除 SageMaker 托管的端点:

    ```
    !aws sagemaker delete-endpoint --endpoint-name {"-".join(automl_job.best_candidate()["CandidateName"].split("-")[0:7])}
    ```

2.  Then use the AWS CLI to also delete the endpoint configuration:

    ```
    !aws sagemaker delete-endpoint-config --endpoint-config-name {"-".join(automl_job.best_candidate()["CandidateName"].split("-")[0:7])}
    ```

    小费

    如果您希望进一步清理实验中的各种试验，可以参考 SageMaker 文档的清理部分([https://docs . AWS . Amazon . com/sage maker/latest/DG/experiments-Clean Up . html](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-cleanup.html))。

从自动化 ML 过程的角度来看，您现在应该熟悉如何使用 Autopilot 模块来实现 AutoML 方法，以及如何使用 SageMaker SDK 来创建一个已编纂和记录的 AutoML 实验。

# 总结

本章向您介绍了 AWS 的一些 AI 和 ML 功能，特别是 Amazon SageMaker 的功能。您看到了如何通过 SageMaker Studio UI 和 SageMaker SDK 与服务进行交互。通过实际操作的例子，您了解了 Autopilot 对 AutoML 方法的实施不仅解决了典型的*ML 流程带来的两个挑战，还解决了自动化的总体标准。特别是，如何使用自动驾驶器来确保 ML 过程是*可靠的*和*流线型的*。ML 从业者需要完成的唯一任务是将原始数据上传到亚马逊 S3。*

本章还强调了 AutoML 方法的一个重要方面。虽然 AutoML 过程是*可重复的*,因为它总是会产生一个优化的模型，但是一旦您将模型投入生产，就没有必要重新创建它，当然，除非业务用例发生变化。然而，Autopilot 通过提供**候选笔记本**、模型**可解释性报告**，以及启用**数据捕获**来监控模型的概念漂移，为帮助 ML 从业者持续优化生产模型创造了坚实的基础。因此，对于 ML 从业者来说，使用 AutoML 方法是自动化他们的初始 ML 实验的一个很好的方式。

值得注意的是 Autopilot 实现 AutoML 方法的一个缺点。自动驾驶只支持**监督学习**用例——使用**回归**或**分类**模型的用例。

在下一章中，您将学习如何使用 AutoGluon 包将 AutoML 方法应用于需要高级深度学习模型的更复杂的 ML 用例。