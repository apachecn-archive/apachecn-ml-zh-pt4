<title>B17649_11_ePub</title>

# 第 11 章:mls DLC 的持续集成、部署和培训

如果你回顾一些关于机器学习的*架构最佳实践*内容，即*在 AWS* 上构建一个安全的企业机器学习平台白皮书，甚至是关于 MLOps 的 SageMaker 文档，你会注意到在自动化应用的各种挑战中，它们都需要有一个**跨职能团队**。

那么，为什么跨职能的敏捷团队对 AWS 上的自动化 ML 如此重要？

AWS 提供了许多与 ML 相关的*技术*，这些技术在功能上经常重叠，为他们的客户提供了选择和灵活性。此外，业界提供了许多经过试验和测试的*流程*指南，如 CI/CD，来自动化这一流程。然而，无论是 AWS 还是行业都无法影响一个公司的组织结构或应用程序开发文化。任何变化都需要在组织内部发生，并由组织来完成。

在 [*第 10 章*](B17649_10_ePub.xhtml#_idTextAnchor133) 、*机器学习软件开发生命周期(MLSDLC)简介*中，我们重点介绍了由数据科学家、ML 工程师以及平台、应用、数据和安全专家组成的跨职能团队如何为成功实施自动化 MLSDLC 流程做出贡献。通过使用 *ACME web 应用程序*的实际例子，您了解了这些不同的角色是如何相互作用的，以及为什么他们的领域专业知识和工件贡献对于项目的成功如此重要。

在本章中，我们将重点关注 MLSDLC 流程的自动化，以了解我们在第 10 章*【机器学习软件开发生命周期(MLSDLC)简介】*中创建的各种工件如何映射到流程的每个阶段。

为此，我们将讨论以下主题:

*   编纂持续集成阶段
*   管理持续部署阶段
*   管理持续培训

在本章结束时，您将完成一个自动化的端到端 MLSDLC 流程，该流程将 *ACME 网站*以及年龄计算器模型部署到生产环境中。这将为您提供必要的框架，以便在进行任何代码更改或添加任何新数据时，继续自动化该过程。

# 技术要求

对于本章，您将需要以下内容:

*   网络浏览器。(为了获得最佳体验，建议您使用 Chrome 或 Firefox。)
*   访问您在本书中一直使用的 AWS 帐户。
*   访问您在本书中一直使用的 Cloud9 开发环境。
*   参考 AWS 免费层的使用限制，以避免不必要的成本。
*   本章的源代码示例在本书的 GitHub 资源库(https://GitHub . com/packt publishing/Automated-Machine-Learning-on-AWS/tree/main/chapter 11)中提供。

# 编纂持续集成阶段

在这一节，我们将从 [*第 10 章*](B17649_10_ePub.xhtml#_idTextAnchor133) ，*机器学习软件开发生命周期介绍(MLSDLC)* 中的停顿处继续。我们总结了上一章，不同的团队将他们的工件提交到源代码仓库。因此，在进行安全审查之前，扮演着将这些工件集成到整体解决方案中的核心角色的团队，即平台团队，掌握了控制权。从高层次来看，下图显示了**平台团队**在我们的场景中扮演的核心角色:

![Figure 11.1 – The Platform Team's role within the MLSDLC process
](img/Figure_11.1_B17649.jpg)

图 11.1-平台团队在 MLSDLC 流程中的角色

正如您所见，由于平台团队位于跨职能团队的*中间*，他们负责*将所有解决方案组件*粘合在一起。一旦所有的部分都被*粘合*在一起，平台团队就负责根据业务用例验证这些组件是否能很好地协同工作。例如，平台团队将验证 web 应用程序用户可以将鲍鱼属性数据输入到 web UI 中，并将该数据作为推理请求数据发送到 ML 模型，其中 ML 模型向用户返回有效响应。

那么，*平台团队如何将各个部分整合在一起呢？*更重要的是，*平台团队如何以连续和自动化的方式做到这一点？*

回答这些问题的最佳方式是实际展示平台团队在构建他们的集成工件时所执行的典型任务。

## 构建集成工件

为了测试是否所有的部分都匹配在一起，平台团队在**测试**或**质量保证** ( **QA** )环境中创建了一个生产解决方案的实体模型。然后对解决方案执行**功能测试**，也称为**系统测试**，以确保整个系统按照预期方式工作。此外，为了自动化这个过程，平台团队将解决方案编码为 **CDK 构造**。

为了作为平台团队来构建这个结构，我们将继续使用我们在 [*第 10 章*](B17649_10_ePub.xhtml#_idTextAnchor133) 、*机器学习软件开发生命周期介绍(MLSDLC)* 中使用的 AWS Cloud9 IDE。请遵循以下步骤:

1.  登录您在本书中一直使用的同一个 AWS 帐户，打开 AWS Cloud9 控制台(https://console . AWS . Amazon . com/cloud 9)。
2.  在 **Your environments** 部分，点击 **MLOps-IDE** 开发环境的 **Open IDE** 按钮。
3.  使用 Cloud9 工作区内的终端窗口，运行以下命令，将本书的 GitHub 存储库中预构建的堆栈结构复制到`stack.py`文件夹:

    ```
    $ cd ~/environment/acme-web-application
    $ cp ~/environment/src/Chapter11/Files/cdk/test_application_stack.py acme_web_application/stacks/
    ```

4.  使用左侧导航面板，双击`test_application_stack.py`文件开始查看。
5.  现在,`test_applciation_stack.py`文件已经打开，我们可以查看由 stack 构造创建的最重要的 AWS 资源。除了加载必要的 CDK Python 库和实例化`TestApplicationStack()`类，我们必须声明的第一个变量是`endpoint_name`。这是我们将给予 SageMaker 托管端点的名称，它正在托管我们训练好的模型。
6.  接下来，我们必须定义一个名为`sagemaker_test_role`的 IAM 角色。SageMaker 将使用这个角色来访问存储生产级模型的模型注册中心。
7.  我们必须定义的下一个变量是模型本身。这里，我们必须使用 SageMaker CDK 模块的`CfnModel()`类实例化 SageMaker 模型。我们还必须定义一个`AwsCustomResource()`来对 SSM 服务进行 API 调用，并检索指向模型注册中心内已训练模型位置的参数。
8.  既然我们已经定义了模型，我们需要分配托管模型所需的计算资源。这是通过使用`CfnEndpointConfig()`类实例化`endpoint_config`变量来完成的。由于这是为了测试环境，我们不需要提供可扩展的计算资源，我们只需要提供测试模型所需的最少的计算实例。这就是为什么我们为测试环境指定了一个`ml.t2.large`实例类型。
9.  有了`model`和`endpoint_config`之后，我们可以使用`CfnEndpoint()`类实例化`endpoint`，从而完成测试环境的模型部署部分。
10.  The next component of the test environment is to create the back-service for the website's *Contact form* and the *Age Calculator form*. The Platform Team provides this backend functionality as a `api` variable as an `HttpApi()` gateway class. The team also distributes the static HTML components as part of a `CloudFrontWebDistribution()` class.

    注意

    由于 CloudFront 发行版仅用于测试各种工件集成，我们将发行版价格类别指定为`PRICE_CLASS_100`。这意味着静态网站内容将只分发到北美、南非和中东的 edges。通过不使用 CloudFront 的完整全球分发功能，我们可以将测试成本降至最低。要了解更多关于 CloudFront 分布类和边缘位置的信息，可以查看定价文档(【https://aws.amazon.com/cloudfront/pricing/】T2)。

11.  一旦网站的内容被上传到 S3 并通过 CloudFront 分发，我们就可以为*联系人表单*和*年龄计算器表单*创建路径，它们将指向一个`formHandler` Lambda 获取网站 API 请求并基于`requests`路径处理它们。例如，如果`formHandler` Lambda 从`/api/predict`路径接收到一个 API `POST`请求，它会将请求有效负载发送到 SageMaker 托管的模型进行推断。然后，它将从托管模型中获取推理响应，并将其发送回网站。
12.  最后，我们必须使用 CDK 的`CfnOutput()`模块创建两个输出。第一个输出称为`self.cdn_output`，包含`cdn.domain_name`作为它的值。这将允许我们捕获网站的网址。
13.  第二个输出称为`self.api_output`，并提供`api.url`作为一个值，本质上是提供表单 API 的 URL。

我们将在下一节中使用这些输出来构建测试工件。

## 构建测试工件

为了测试应用程序，我们需要设身处地为应用程序用户着想，了解他们如何与 web 应用程序中提供的功能进行交互。由于我们的示例网站仅由一个 *HTML 页面*、一个*联系表单*和*年龄计算器预测表单*组成，为了测试系统的整体功能，我们必须确认这些组件做了它们应该做的事情。

按照以下步骤创建必要的测试:

1.  使用 Cloud9 workspace 的终端窗口，运行以下命令，将预先构建的测试脚本复制到`acme-web-application`文件夹:

    ```
    $ cd ~/environment/acme-web-application
    $ rm –rf tests
    $ cp -R ~/environment/src/Chapter11/Files/tests .
    ```

2.  使用 Cloud9 环境的左侧导航面板，展开`tests`文件夹，然后双击`system_test.py`文件来查看测试代码。

如果你看一下测试代码，你会发现我们使用 Python `requests`库来模拟用户发出网站请求。*第一个测试*通过验证我们从 web 服务器获得了适当的状态代码，以及交付的内容是 HTML 代码，来关注网站本身。本质上，该测试模拟网站正在运行并且可以访问。

第二个测试关注后端 RESTful API。在这个测试中，我们将样本鲍鱼属性数据发送到后端 API，后者又将数据发送到托管生产模型进行推断。然后，我们验证是否收到了相应的状态代码，以及预测鲍鱼年龄的 HTML 响应。本质上，这个测试模拟了年龄计算器的用户体验。

*最后一个测试*模拟对后端 API 的错误调用，以确保 API 以正确的错误消息做出响应。这种测试并不总是必要的，但是测试应用程序是否以正确的错误作出响应可以确保当错误发生时，它们可以被正确地调试，因为我们知道应用程序正在正确地报告任何错误。

既然我们已经为系统编写了一些基本的功能测试，我们就可以构建生产环境了。

## 构建生产工件

现在我们已经完成了必要的工作，我们有了一个公平的想法，即被测试的系统工件将在生产中工作。因此，要创建生产环境，我们必须复制我们在测试或 QA 环境中使用的应用程序结构。请遵循以下步骤:

1.  使用 Cloud9 workspace 的终端窗口，运行以下命令从本书的 GitHub 存储库中复制预构建的生产工件:

    ```
    $ cd ~/environment/acme-web-application
    $ cp ~/environment/src/Chapter11/Files/cdk/production_application_stack.py acme_web_application/stacks/
    ```

2.  使用左侧导航面板，双击`production_application_stack.py`文件进行查看。

如果您比较生产应用程序结构和测试应用程序结构，您会注意到有一些额外的组件。首先，我们创建了一个新的 *S3 存储桶*来存储所有的生产应用程序日志。这个存储桶将存储网站访问的所有日志，以及记录来自生产模型的推理日志。您可能还记得 [*第 10 章*](B17649_10_ePub.xhtml#_idTextAnchor133)*【机器学习软件开发生命周期(MLSDLC)介绍】*中，我们讨论安全性时，提到记录所有系统活动是一个很好的做法。从生产 ML 模型的角度来看，我们记录推理请求，以及推理响应数据，以衡量模型的执行情况。

在定义`endpoint_config`时，您会看到，对于生产环境，我们通过使用`ml.c5.large`实例，使用大小合适的生产计算资源来托管模型。我们还指定了最少的`2`实例，这样我们就可以利用 SageMaker 托管模型的高可用性(多个 AWS 可用性区域)特性。此外，我们通过`data_capture_config`打开推理，将所有推理请求数据和所有响应推理响应记录到日志桶中。

我们添加到产品构造中的另一个新组件是`createBaseline` Lambda 函数。因为生产构造正在部署生产级 ML 模型，所以我们想要捕获其预期性能的统计分析。这样，通过引用捕获的推理响应，我们可以监控模型的质量漂移。为此，我们为 Lambda 函数定义了`baseline_creator`变量，然后作为`CustomResource()`触发 Lambda 执行。

最后，我们添加了`scaling_target`变量并提供了策略，该策略指定了端点如何扩展。对于我们的生产环境，当每个`ml.c5.large`实例在 15 分钟内每秒钟收到超过`750`个请求时，我们将开始伸缩。

在测试和生产构造中，我们已经用实例化了`formHandler`和`createBaseline` Lambda 函数。这两个变量都是指组成这些功能的代码工件。因此，在我们关闭测试和生产 CDK 构件之前，我们需要用预构建的 Lambda 构件更新源代码 respiratory，以确保在我们部署它们时这些构件不会失败。请按照以下步骤操作:

1.  使用 Cloud9 workspace 的终端窗口，运行以下命令将`formHandler`和`createBaseline` Lambda 代码复制到克隆的存储库中:

    ```
    $ cd ~/environment/acme-web-application
    $ cp -R ~/environment/src/Chapter11/Files/lambda/ .
    ```

至此，我们已经为管道的集成阶段创建了所有必要的工件。现在，我们必须通过将这些组件添加到 CDK 管道来创建用于持续集成的自动化组件。

## 自动化持续集成流程

在 [*第十章*](B17649_10_ePub.xhtml#_idTextAnchor133)**机器学习软件开发生命周期(MLSDLC)* 中，我们创建了一个**骨架 CDK 流水线**。这被称为骨架管道，因为我们简单地定义了管道结构，而没有提供管道的主体或阶段。因此，现在大多数堆栈结构、Lambda 函数、脚本、测试和静态 HTML 构件都已经添加到存储库中，我们可以将它们放在一起创建一个自动化的 CI/CD 管道体。请遵循以下步骤:*

 *1.  在您的 Cloud9 终端窗口中，运行以下命令来更新`acme_pipeline_stack.py`构造:

    ```
    $ cd ~/environment/acme-web-application
    $ cp ~/environment/src/Chapter11/Files/cdk/acme_pipeline_stack.py acme_web_application/
    ```

2.  在左侧导航面板中，双击`acme_pipeline_stack.py`文件进行查看。

如果您将新的`acme_pipeline_stack.py`文件与我们在 [*第 10 章*](B17649_10_ePub.xhtml#_idTextAnchor133) 、*机器学习软件开发生命周期介绍(MLSDLC)* 中创建的文件进行比较，您会发现有一些显著的变化。首先，我们已经从`stacks`文件夹中的所有 CDK 栈中导入了`cdk.Construct`类。我们还为每个导入栈结构定义了一个`cdk.Stage`类。例如，如果你参考下面的摘录，你会看到我们从`ml_workflow_stack.py`文件中导入了`MLWorkflowStack`类，该文件可以在`stacks`文件夹中找到:

```
…
from .stacks.ml_workflow_stack import MLWorkflowStack
…
```

然后，我们实例化这个堆栈的一个名为`MLWorklowStage()`的类，作为 CDK 流水线阶段构造。我们还提供了将堆栈实例化为流水线阶段所需的各种参数，并定义了特定的堆栈输出(在这种情况下，是状态机的 ARN):

```
…
class MLWorkflowStage(cdk.Stage):
    def __init__(self, scope: cdk.Construct, id: str, *, group_name: str, threshold: float, data_bucket_name: str, feature_group_name: str, **kwargs):
        super().__init__(scope, id, **kwargs)
        ml_workflow_stack = MLWorkflowStack(
            self,
            "MLWorkflowStack",
            group_name=group_name,
            threshold=threshold,
            data_bucket_name=data_bucket_name,
            feature_group_name=feature_group_name
        )
        self.sfn_arn = ml_workflow_stack.sfn_output
…
```

通过将所有 CDK 堆栈实例化为单独的阶段构造，我们实质上是将每个构造定义为管道体的连续部分。例如，如果你向下滚动到我们已经定义了`PipelineStack()`类的地方，你会看到`MLWorkflow()` stage 构造已经被`ml_workflow_stage`变量定义了。然后，使用 CDK 管道模块的`add_stage()` **方法**将`ml_workflow_stage`变量添加到管道体中。

注意

有关`Stage()`构造以及如何将其纳入 CDK 管道的更多详细信息，请参考以下关于 CDK 管道的 AWS 博客:https://AWS . Amazon . com/blogs/developer/CDK-Pipelines-continuous-delivery-for-AWS-CDK-applications/。请记住，这个博客是基于 CDK 管道模块的预览版本。2021 年 7 月，AWS 发布 CDK 管线为**一般可用** ( **GA** )。要查看预览版和 GA 版的区别，可以参考 API 文档([https://github . com/AWS/AWS-CDK/blob/master/packages/% 40 AWS-CDK/pipelines/ORIGINAL _ API . MD](https://github.com/aws/aws-cdk/blob/master/packages/%40aws-cdk/pipelines/ORIGINAL_API.md))。

此外，您将看到，当我们将`ml_workflow_stage`和`test_stage`变量添加到管道中时，我们还定义了一个`post`参数。通过使用此参数，我们可以定义额外的阶段操作或阶段步骤，这些操作或步骤将在部署阶段构造后执行。在`ml_workflow_stage`变量的情况下，我们实例化了`CodeBuildStep()`类模块的一个实例来运行一个名为`invoke.py`的 Python 文件。该脚本采用 Step Functions 状态机的 ARN(部署在`ml_workflow_stage`构造中)并开始执行工作流。或者，在`test_stage`的情况下，我们实例化`ShellStep()`类模块来运行`system_test.py`文件，该文件测试应用程序的功能。

注意

我们使用`CodeBuildStep()`代表`ml_workflow_stage`和`ShellStep()`代表`test_stage`的原因是，我们可以使用`role_policy_statements`参数来提供必要的 IAM 权限，以启动和监控步骤功能状态机的执行。

您将看到的最后一个变化是管道的`self_mutation`参数现在被设置为`True`。这意味着我们将使管道能够动态适应(自变异)任何代码变化。例如，如果您打开您所在地区的代码管道管理控制台(https://console.aws.amazon.com/codesuite/codepipeline/)并点击 **ACME -WebApp-Pipeline** ，您将看到管道的当前结构只有两个阶段:

![Figure 11.2 – Current structure of the CDK Pipeline
](img/Figure_11.2_B17649.jpg)

图 11.2-CDK 管道的当前结构

当我们将工件更新提交给源代码库时，这些变化已经触发了流水线执行。然而，由于`self_mutation`参数当前被设置为`False`，添加堆栈和阶段代码构造并没有修改流水线结构。

现在，平台团队必须完成 CDK 项目，以实现自变异。请遵循以下步骤:

1.  To finalize the CDK project, go to the Terminal windows in your Cloud9 workspace and run the following command to get the name of the SageMaker Feature Group:

    ```
    $ aws sagemaker list-feature-groups --name-contains abalone
    ```

    注意

    你会记得这个特性组是我们在 [*第十章*](B17649_10_ePub.xhtml#_idTextAnchor133)*机器学习软件开发生命周期(MLSDLC)介绍*的*创建 SageMaker 特性库*部分创建的特性组。

2.  从输出中复制`FeatureGroupName`键的值。
3.  使用 Cloud9 工作区的左侧导航面板，展开`acme-web-application`文件夹并双击`app.py`文件开始编辑它。
4.  用您在*步骤 1* 中运行的命令的输出替换`PLACEHOLDER`变量赋值，如下面的代码片段所示:

    ```
    …
    MODEL_GROUP = f"{MODEL.capitalize()}PackageGroup"
    FEATURE_GROUP = "<Add the name of the SageMaker Feature Group>"
    CODECOMMIT_REPOSITORY = "acme-web-application"
    …
    ```

5.  保存并关闭`app.py`文件。
6.  在您的 Cloud9 终端窗口中使用以下命令，添加最终的管道工件——`invoke.py`文件——并将更改提交到存储库:

    ```
    $ cd ~/environment/acme-web-application/
    $ cp ~/environment/src/Chapter11/Files/scripts/invoke.py scripts/
    $ git add -A
    $ git commit -m "Finalized CDK application"
    $ git push
    ```

7.  因为我们已经更新了 CDK 应用程序，所以运行以下命令来重新部署应用程序:

    ```
    $ cdk deploy
    ```

恭喜你！您刚刚编写了一个自动化的基于 ML 的应用程序。然而，我们仍然没有完成。下一步是监控自动化过程，以确认我们所创建的东西被部署到生产中，并且满足业务用例的功能需求。当我们管理编码解决方案的持续部署时，我们将在下一节中关注这项任务。

# 管理持续部署阶段

到目前为止，我们主要关注参与计划、设计和编写解决方案的人员。然而，您会回忆起 [*第 10 章*](B17649_10_ePub.xhtml#_idTextAnchor133) ，*《机器学习软件开发生命周期(MLSDLC)介绍》*，在这些*人*之外，还有两个因素影响 MLSDLC 实施的成功——技术和过程*。在本节中，我们将重点介绍 MLSDLC 流程本身。因为我们已经使用自变异的 CDK 管道对流程进行了编码，所以我们需要做的就是管理部署直到完成。概括地说，让我们回顾一下我们在这个过程中所处的位置:*

*![Figure 11.3 – The plan and design phases of the MLSDLC process
](img/Figure_11.3_B17649.jpg)

图 11.3–mls DLC 流程的计划和设计阶段

在这里，您可以看到我们已经完成了 MLSDLC 流程的**计划**和**设计**阶段。作为一个跨职能团队，我们已经审查了 *ACME web 应用*的业务目标和需求。使用 CDK，不同的团队已经将他们对应用程序设计的贡献整理成文。既然已经部署了设计，我们可以进入自动化 MLSDLC 流程的下一个阶段——构建**阶段。**

## 回顾构建阶段

要查看构建流程，请打开您当前 aws 区域的 code pipeline([https://console . AWS . Amazon . com/code suite/code pipeline/pipelines/](https://console.aws.amazon.com/codesuite/codepipeline/pipelines/))管理控制台；您将看到 **ACME -WebApp-Pipeline** 。打开管道后，您将立即看到管道已经自我变异，合并了我们定义的阶段。向下滚动管道将显示**资产**阶段，如下面的屏幕截图所示:

![Figure 11.4 – The Assets stage
](img/Figure_11.4_B17649.jpg)

图 11.4–资产阶段

**资产**阶段是mls DLC 构建阶段的第一部分，在这里构建 ML 容器映像、各种 Lambda 函数和静态 HTML web 内容。正如您所看到的，我们不需要创建一个专门的构建阶段来创建这些资产；CDK 管道自动完成这项工作。然而，一旦创建了这些管道资产，构建过程就没有完成。

为了成功执行整个 MLSDLC 过程，构建阶段还需要一个生产级 ML 模型。因此，如下面的屏幕截图所示，进一步向下滚动以显示构建过程的第二部分——构建-MLWorkflow 阶段:

![Figure 11.5 – The Build-MLWorkflow stage
](img/Figure_11.5_B17649.jpg)

图 11.5–构建工作流阶段

如你所见，三个独立的动作组成了**构建工作流**阶段。这些是**准备**、**展开**和**执行**动作。 **Prepare** 动作创建一个 CloudFormation 变更集来检查堆栈正在部署的 AWS 资源，从而保证任何提议的更改不会影响现有的关键 AWS 资源。这实质上是对持续集成环境中的建议资源的内置完整性或集成测试，其中现有的堆栈会随着管道的变化而自动更新。因为这是第一次创建 ML 工作流，所以**准备**阶段继续到**部署**阶段，在这里使用 AWS CloudFormation 部署堆栈。

一旦创建了堆栈，就会运行`invoke.py`脚本。回想一下，`invoke.py`脚本创建了一个阶跃函数状态机的执行。这个状态机反过来训练一个生产级的 ML 模型。

注意

如果你点击**内的`invoke.py`脚本，构建日志**。

如果您打开步进功能控制台([https://console.aws.amazon.com/states/home](https://console.aws.amazon.com/states/home))并点击以 **MLWorkflow…** 开头的状态机名称，您将看到**执行列表**。点击这个按钮可以显示工作流程的当前状态。工作流完成后，执行图应该如下所示:

![Figure 11.6 – State machine execution graph
](img/Figure_11.6_B17649.jpg)

图 11.6-状态机执行图

如您所见，这个是工作流第一次被执行。如果模型的性能低于阈值，它将作为模型包添加到 SageMaker 模型注册中心。下面的屏幕截图显示了注册表中模型版本指标的示例:

![Figure 11.7 – Model version metrics
](img/Figure_11.7_B17649.jpg)

图 11.7–模型版本度量

正如您所看到的，使用 SageMaker Studio UI，ML 团队可以跟踪由工作流产生的各种模型的血统。由于我们还启用了实验跟踪，ML 团队也可以在 SageMaker Studio UI 中对数据处理、模型训练和模型评估试验进行评估。以下屏幕截图显示了由工作流生成的培训实验示例:

![Figure 11.8 – Training experiment details
](img/Figure_11.8_B17649.jpg)

图 11.8-训练实验细节

注意

有关如何使用 SageMaker Studio 比较 SageMaker 实验和试用的更多信息，请参考以下 SageMaker 文档:[https://docs . AWS . Amazon . com/sage maker/latest/DG/experiments-view-compare . html](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-view-compare.html)。

由于执行 ML 工作流是 **Build-MLWorkflow** 阶段的最后一个动作，我们已经完成了 MLSDLC 流程的构建阶段。在这个阶段，流水线自动移动到**测试**阶段。

## 回顾测试阶段

一旦建立了各种管道资产和生产级 ML 模型，我们必须进入测试阶段，如下图所示:

![Figure 11.9 – The test phase of the MLSDLC process
](img/Figure_11.9_B17649.jpg)

图 11.9–mls DLC 流程的测试阶段

在测试阶段，我们的管道将解决方案的伪生产版本部署到测试或 QA 环境中。如果我们在 CodePipeline 控制台中查看管道的这个阶段，您将会看到这个**测试部署**阶段也有三个阶段操作。下面的截图显示了**测试部署**阶段的一个例子:

![Figure 11.10 – The Test-Deployment stage
](img/Figure_11.10_B17649.jpg)

图 11.10–测试部署阶段

如您所见，执行这三个系统测试的`system_test.py`文件。

小费

一旦 **System-Test** stage 动作完成，您可以通过 CloudFormation 控制台(【https://console.aws.amazon.com/cloudformation/home】)删除**Test-Deployment-TestApplicationStack**cloud formation 栈。我们对这些资源没有任何进一步的要求，我们也不希望因为它们闲置而产生任何进一步的 AWS 使用成本。

您可能还记得上一节中的，这三个测试通过访问网站和向年龄计算器模型发送 ML 推断请求来模拟用户对解决方案的体验。通过点击**系统测试**动作的**细节**链接，您将看到运行系统测试的 CodeBuild **构建日志**输出。

注意

如果系统测试脚本由于某种原因失败了，那么**系统测试**动作以及**测试部署**阶段将会失败。这些测试中的任何一个失败并不一定意味着 MLSDLC 过程会失败。自动化 MLSDLC 过程的全部要点，尤其是自动化系统测试，是为了验证一旦解决方案最终部署到生产中，我们可以对其功能充满信心。因此，如果测试失败，我们可以向支持团队提供调试反馈，他们可以反过来解决问题并重新执行管道。

既然管道的**测试-部署**阶段已经完成，我们有了一个经过测试的解决方案，我们就可以将该解决方案部署到生产环境中了。这就是 MLSDLC 的**部署**阶段。

## 审查部署和维护阶段

一旦在伪生产解决方案上运行了所有的系统测试，我们应该有信心为我们的用户准备好生产版本。如下图所示，我们已经准备好最终将解决方案部署到生产环境中。部署后，我们可以管理和维护它:

![Figure 11.11 – The deploy and maintain phases of the MLSDLC process
](img/Figure_11.11_B17649.jpg)

图 11.11–mls DLC 流程的部署和维护阶段

从 CDK 管道的角度来看，负责生产部署的阶段与测试部署阶段相同，该阶段也有**准备**和**部署**阶段动作，但没有系统测试阶段动作。下面的屏幕截图显示了在**生产-部署**阶段中仅执行这两个操作的示例:

![Figure 11.12 – The Production-Deployment stage 
](img/Figure_11.12_B17649.jpg)

图 11.12-生产部署阶段

虽然 pipeline 的阶段可能相似，但是作为 CloudFormation 堆栈部署的解决方案有些不同。首先，生产堆栈部署了更适合生产环境的最佳 AWS 资源。例如，生产堆栈使用优化的 C5 计算资源来托管模型，并实现额外的灵活性，因为这些计算资源可以根据用户需求进行扩展和缩减。

此外，从`production_application_stack.py`文件开始，我们为`CloudFrontDistribution()`类启用了`logging_config`。这使得解决方案部署后的维护更加容易，因为我们将所有的 web 事务日志存储在 S3。这使运营团队能够了解堆栈中的情况，并使用这些信息进行故障排除和调试。

除此之外，您还记得，在`production_application_stack.py`文件中，我们还创建了`createBaseline` Lambda 函数，并使用`CustomResource` CDK 模块调用它。在下面取自 Lambda 函数的`index.py`文件的代码片段中，您可以看到这个函数运行一个 SageMaker 处理作业来执行测试数据的统计分析。它使用由 AWS 提供的`sagemaker-model-monitor-analyze`容器来实现这一点，以便为训练模型的预期性能设定基线:

```
...
image_map = {
    "us-east-1": "156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer",
...
        logger.info(f'Creating Basline Suggestion Job: {request["ProcessingJobName"]}')
        try:
            response = sm.create_processing_job(**request)
            return {
                "PhysicalResourceId": response["ProcessingJobArn"],
                "Data": {
                    "ProcessingJobName": request["ProcessingJobName"],
                    "BaselineResultsUri": f"s3://{logs_bucket}/baselining/results"
                }
            }
...
```

通过将此统计基线分析与从生产模型中捕获的推理响应数据相结合，运营团队可以检测模型是否偏离了其预期目的。

此外，通过促进数据捕获和基线数据，运营团队可以通过实施 sage maker Model Monitor(https://docs . AWS . Amazon . com/sage maker/latest/DG/Model-Monitor . html)来自动化漂移检测流程。Model Monitor 将使用这些数据源，按照预定义的时间表自动检测各种模型漂移。

注意

我们在本例中没有实现自动模型监控功能，因为模型监控模块提供了多种内置漂移检测功能。您可以查看文档以确定数据质量([https://docs . AWS . Amazon . com/sagemaker/latest/DG/model-monitor-data-quality . html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html))、模型质量([https://docs . AWS . Amazon . com/sagemaker/latest/DG/model-monitor-model-quality . html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality.html))、偏差漂移([https://docs . AWS . Amazon . com/sagemaker/latest/DG/clarify-model-monitor-html](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift.html)

一旦管道的**生产-部署**阶段完成，我们将会看到我们关闭了循环并完成了 MLSDLC 流程，如下图所示:

![Figure 11.13 – Completed MLSDLC process
](img/Figure_11.13_B17649.jpg)

图 11.13–完成的 MLSDLC 流程

让我们通过回顾我们的用户在使用 *ACME web 应用*和*年龄计算器*组件时可能经历的事情来看看我们已经构建了什么。

## 回顾应用程序用户体验

要查看生产应用程序，请打开 CloudFormation 控制台([https://console.aws.amazon.com/cloudformation/home](https://console.aws.amazon.com/cloudformation/home))并单击**生产-部署-ProdApplicationStack** 旁边的单选按钮以打开堆栈。点击**输出**选项卡查看堆栈输出，如下图所示:

![Figure 11.14 – CloudFormation stack outputs
](img/Figure_11.14_B17649.jpg)

图 11.14–云形成堆栈输出

如你所见，我们有两个堆栈输出。 **FormAPIURL** 输出是用于处理*年龄计算器*推理请求的 API 网关地址，而 **CloudFrontURL** 输出指向网站的地址。点击 **CloudFrontURL** 的**值**查看网站。以下截图显示了 ACME Fishing Logistics 网站:

![Figure 11.15 – ACME Fishing Logistics website
](img/Figure_11.15_B17649.jpg)

图 11.15-ACME 渔业物流网站

现在，让我们试试*年龄计算器*组件，看看一个渔民如何能够看到他捕获的鲍鱼的预测年龄。下面的截图显示了当一个渔民点击**试试我们的年龄计算器**按钮时出现的年龄计算器表单:

![Figure 11.16 – Age Calculator form
](img/Figure_11.16_B17649.jpg)

图 11.16-年龄计算器表单

如您所见，**计算鲍鱼年龄**表格提供了鲍鱼的各种样本尺寸。输入这些样本尺寸，点击**提交**按钮，查看 ML 模型预测的结果。以下屏幕截图显示了来自已训练模型的示例响应:

![Figure 11.17 – Age Prediction
](img/Figure_11.17_B17649.jpg)

图 11.17–年龄预测

正如你所看到的，根据提供的样本尺寸，模型预测鲍鱼有 10 个 T2 环。根据鲍鱼数据集的 UCI 机器学习知识库(https://archive . ics . UCI . edu/ml/datasets/鲍鱼)，环数**加上 **1.5** 的值给出了以年为单位的年龄。因此，渔民可以看到鲍鱼的年龄是 11.5 岁，从而决定是将捕获物扔回去还是保存起来。**

 **恭喜你！我们现在有一个工作的 web 应用程序和一个内置的 ML 模型供我们的 fisherman 客户使用。我们使用自动化的 MLSDLC 流程来实现这一业务目标。

然而，您会记得 MLSDLC 过程不同于典型的 SDLC 过程，因为我们不仅在业务案例或源代码改变时，而且在训练数据改变时，连续地自动化基于 ML 的应用程序的发布。请记住，ML 模型的好坏取决于它所训练的数据。那么，*当我们有新数据时，我们如何持续自动执行 MLSDLC 流程？*

下一节我们将通过探讨**持续训练** ( **CT** )的概念来回答这个问题。

# 管理持续培训

在 [*第 9 章*](B17649_09_ePub.xhtml#_idTextAnchor123) 、*使用 Amazon Managed Workflow for Apache Airflow 构建 ML 工作流*中，我们了解了如何使用 air flow 创建以数据为中心的 ML 流程，并根据新的鲍鱼调查数据训练年龄计算器模型。在 [*第 10 章*](B17649_10_ePub.xhtml#_idTextAnchor133) 、*机器学习软件开发生命周期(MLSDLC)简介*中，我们了解了数据团队如何通过编写**ACME-Data-workflow**air flow DAG 将这一技术应用于 *ACME web 应用*。下图显示了气流 DAG 的图形表示:

![Figure 11.18 – Data Airflow DAG
](img/Figure_11.18_B17649.jpg)

图 11.18–数据流 DAG

如您所见，当新的鲍鱼调查数据被添加到 S3 桶时，气流 DAG 开始。然后对调查数据进行预处理，以设计相关的训练特征；这些特征随后被吸收到特征存储中。一旦新数据被接收到功能存储中，就会触发 MLSDLC 流程的发布变更，以自动化发布解决方案的新变更集的流程。本质上，这创造了一个持续的培训过程。

此外，在本章的开始，我们看到了平台团队如何通过扩展 CDK 管道来提供管理和执行 **acme-data-workflow** DAG 的必要 AWS 资源，从而将持续培训的概念融入 CI/CD 方法中。例如，如果您在代码管道控制台中打开 **ACME-WebApp-Pipeline** ，您将看到**构建-数据-工作流**阶段，如以下截图所示:

![Figure 11.19 – The Build-DataWorkflow stage
](img/Figure_11.19_B17649.jpg)

图 11.19–构建数据工作流阶段

正如您所看到的， **Build-DataWorkflow** 阶段有一个**准备**和一个**部署**阶段动作，从而准备并部署一个 CloudFormation 变更集。这一部署的结果是在 VPC 内的 MWAA 环境，加上 DAG，以及上传到 S3 的支持资产。由于这是 CDK 管道的最后阶段，我们最终创建了 CI/CD/CT 管道，将持续培训纳入 MLSDLC 流程。

然而，在我们看到完整的端到端 MLSDLC 过程之前，我们需要模拟添加新的鲍鱼调查数据。我们将在下一节中完成这项工作。

## 创建新的鲍鱼调查数据

在 [*第 9 章*](B17649_09_ePub.xhtml#_idTextAnchor123) ，*使用 Amazon Managed Workflow for Apache air flow 构建 ML 工作流*中，我们利用`CTGAN` Python 库在 Jupyter 笔记本中合成新的鲍鱼数据。以下步骤将引导您使用 SageMaker Studio 重现相同的过程，并运行本书的 GitHub 存储库中预先构建的笔记本([https://GitHub . com/packt publishing/Automated-Machine-Learning-on-AWS/tree/main/chapter 11/Notebook](https://github.com/PacktPublishing/Automated-Machine-Learning-on-AWS/tree/main/Chapter11/Notebook)):

1.  打开 SageMaker 管理控制台([https://console.aws.amazon.com/sagemaker/home](https://console.aws.amazon.com/sagemaker/home)，在左侧面板中，点击 **SageMaker 域**部分下的**工作室**链接。
2.  一旦 **SageMaker 域**仪表盘打开，点击**启动应用**下拉菜单并从列表中选择**工作室**打开工作室 IDE。
3.  Within the left-hand file panel, expand the `Notebooks` folder within the `Chapter11` folder of the cloned `src` folder.

    注意

    这本书的 GitHub 存储库文件应该已经克隆到 Studio 环境中供您使用。如果没有，请参考 [*第十章*](B17649_10_ePub.xhtml#_idTextAnchor133)*机器学习软件开发生命周期介绍(MLSDLC)* 的*创建 SageMaker 特征库*部分。

4.  双击`Simulating New Abalone Survey Data.ipynb`文件打开笔记本。
5.  从**内核**菜单中，点击**重启内核并运行所有单元……**选项。
6.  一旦创建了笔记本，就可以关闭 SageMaker Studio UI。

现在，我们已经模拟了新的鲍鱼调查数据，并将数据集上传到 S3，我们可以在行动中回顾连续的训练过程。

## 回顾持续培训流程

当数据团队最初在`continuous_training_pipeline.py`文件中定义气流 DAG 时，他们使用`S3PrefixSensor()`提供者不断检查 S3 桶中的新数据。因此，现在我们已经模拟了新的鲍鱼调查数据，气流 DAG 应该开始运行。

但是，需要手动启用 DAG 才能开始运行。要查看运行中的持续培训流程并启用 DAG，请执行以下步骤:

1.  打开 https://console.aws.amazon.com/mwaa/home MWAA 控制台，点击 **acme-airflow-environment** 的 **Open Airflow UI** 链接。
2.  一旦 Airflow UI 打开，切换 **acme-data-workflow** DAG 旁边的**暂停/取消暂停 DAG** 按钮以启用它。DAG 应该会自动启动。
3.  单击 **DAG** 链接查看运行。DAG 仪表盘打开后，点击**图形视图**按钮，如图*图 11.18* 所示。
4.  您可以跟踪 DAG 的进度，并通过单击特定任务和单击**日志**按钮来查看每个任务的日志。
5.  一旦运行了每个任务,完成的图表应该如下所示:

![Figure 11.20 – Completed data workflow graph
](img/Figure_11.20_B17649.jpg)

图 11.20-完整的数据工作流程图

作为 DAG 运行完成的结果，您可以重新打开代码管道控制台来查看 **ACME-WebApp-Pipeline** 重启。至此，您已经创建了一个 CI/CD/CT 管道，它通过在 AWS 上自动化 MLSDLC 过程来持续构建和部署基于 ML 的应用程序。

## 清理

为了避免不必要的 AWS 使用成本，您可以通过打开 CloudFormation 控制台，然后按照与创建栈相反的顺序删除各个栈，来删除由 CDK 管道创建的资源。例如，选择**构建-数据工作流-数据工作流堆栈**，然后点击**删除**按钮。删除该堆栈后，对**生产-部署-ProdApplicationStack** 执行相同的操作。

注意

根据要删除的堆栈，您可能需要手动清空特定堆栈的 S3 存储桶，然后才能删除该堆栈。

继续沿着 CloudFormation 堆栈列表往下做，直到删除了 **acme-web-application** 堆栈。本章到此结束。

# 总结

在本书的最后一章中，向您介绍了 MLSDLC 的概念，以及如何使用这种方法来创建基于 ML 的应用程序。在前两章中，我们已经关注了创建基于 ML 的应用程序所需的三个主要成功因素中的两个——人和过程。

通过关注跨职能团队和敏捷团队如何合作，我们了解了每个团队如何贡献其领域专业知识来解决 MLSDLC 的业务计划需求和解决方案设计需求。

这项工作的实际成果是一组编码的 CDK 堆栈结构，当平台团队将*与*粘合在一起时，创建了一个 CI/CD/CT 管道。这一 CI/CD/CT 管道发挥了作用，并且是实现 MLSDLC 方法自动化背后的机制。例如，管道的每个阶段对应于 MLSDLC 方法的一个特定阶段，我们看到了执行 CI/CD/CT 管道如何不可避免地自动化 MLSDLC 流程，不仅将应用程序部署到生产中，还建立了持续自动化的永久生命周期。

虽然这些章节没有特别关注成功的 MLSDLC 方法的技术方面，但 AWS 技术如何实现 MLSDLC 过程是显而易见的。

因此，在本章中，通过将这些技术结合起来，我们已经成功地展示了 AWS 上自动化 ML 的端到端示例。

恭喜你！你已经看完了这本书。现在，您应该有足够的代码引用来插入一些 ML 模型，并在 AWS 上自动化它们。

# 延伸阅读

以下是对 AWS 内容的一些参考，强调了跨职能团队作为 AWS 上成功的 ML 自动化的关键的重要性:

*   *机器学习的架构最佳实践*:https://aws.amazon.com/architecture/machine-learning/
*   *在 AWS 上构建安全的企业机器学习平台*:https://docs . AWS . Amazon . com/whites/latest/Build-Secure-Enterprise-ml-Platform/Build-Secure-Enterprise-ml-Platform . html
*   *SageMaker MLOps 文档*:[https://docs . AWS . Amazon . com/sage maker/latest/DG/sage maker-projects-why . html](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-why.html)****