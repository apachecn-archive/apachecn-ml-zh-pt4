# 14.计算机视觉的模型可解释性

由于在提高模型精度方面的不断研究，新框架的演进，以及开源社区的不断发展，图像分类和对象检测等计算机视觉任务正逐渐变得日益完善。最近最先进的机器学习模型的结果比五年前更有希望，这让我们有信心通过处理更复杂的问题来扩展问题的视野。如果我们看看计算机视觉的使用案例，最突出的是零售、农业、公共卫生、汽车行业和游戏行业。这个列表中的一些行业有责任使用人工智能的法律授权。欧盟也在努力规范 AI 的应用和使用。如果图像分类模型生成的预测或分类出错，用户将不会信任该模型及其预测。有必要理解为什么人工智能模型以一种方式而不是另一种方式生成预测或分类。模型可解释性向最终用户展示了图像的哪些特定部分使得模型预测 A 类相对于其他类。

## 为什么图像数据是可解释的？

图像被转换成像素值。像素值随后被用作特征来训练图像最能代表的标签。如果人工智能模型产生了错误的预测/分类，那么组织中有两组人应该负责:建立模型的数据科学家和批准将模型投入生产的利益相关者。图像数据的错误分类是由于两个原因:

*   该模型无法考虑用于预测的正确特征集。相反，它从数据中挑选出错误的线索和信号。培训时没有考虑正确的功能集。

*   没有进行足够的训练来让算法很好地概括看不见的数据。

### 使用 Alibi 的锚点图像

对于物体检测和图像分类等计算机视觉任务，你可以解释区分一个包的图像和一件 t 恤的图像的关键特征。这可以通过使用锚的解释来实现，这在本书的第 [11](11.html) 章中有所涉及。然而，同样的方法可以扩展到其他计算机视觉任务，如伪造图像识别和图像的可能损害。步骤如下:

*   可以为每个领域训练对象检测或图像分类模型，例如名人和流行或普通对象。

*   如果要鉴别另一个人的图像或者裁剪后的图像的真伪，可以得到一个预测，但是概率阈值会低一点。

*   在这种情况下，您可以触发锚点解释，以了解导致预测的关键特征或显著像素。

*   理论上，这是可以的。在实践中，您可以使用以下超级像素公式进行验证。

锚点解释提供的是颜色或对比色，用于区分图像或对象与其他图像。您需要编写一个函数来为任何给定的图像生成超级像素。

### 积分梯度法

集成梯度方法的目标是将特征重要性分数归因于用于训练机器学习或深度学习模型的每个特征。您使用梯度下降来更新深度神经网络模型的权重。当您颠倒该过程时，您可以对归因于特征重要性分数的权重进行积分。梯度可以定义为深度学习模型中输出相对于输入特征的斜率。在图像分类问题中，综合梯度方法可以用来理解像素在识别正确图像中的重要性。通常为相对于输入图像的像素概率最高的类别的输出计算梯度。

```py
import numpy as np
import os

import tensorflow as tf
from tensorflow.keras.layers import Activation, Conv2D, Dense, Dropout
from tensorflow.keras.layers import Flatten, Input, Reshape, MaxPooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical
from alibi.explainers import IntegratedGradients

import matplotlib.pyplot as plt
print('TF version: ', tf.__version__)
print('Eager execution enabled: ', tf.executing_eagerly()) # True

train, test = tf.keras.datasets.mnist.load_data()
X_train, y_train = train
X_test, y_test = test
test_labels = y_test.copy()
train_labels = y_train.copy()

```

为了解释集成梯度方法的工作原理，让我们使用 MNIST 数据集，它很容易理解，许多人都很熟悉。表 [14-1](#Tab1) 说明了模型的参数。

表 14-1

集成渐变参数

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

因素

 | 

说明

 |
| --- | --- |
| `Model` | 张量流或硬模型 |
| `Layer` | 相对于其计算梯度的层。如果没有提供，则根据输入计算梯度。 |
| `Method` | 积分近似法。可用方法:`riemann_left, riemann_right, riemann_middle, riemann_trapezoid`和`gausslegendre`。 |
| `N_steps` | 从基线到输入实例的路径积分近似中的步骤数 |

```py
X_train = X_train.reshape(-1, 28, 28, 1).astype('float64') / 255
X_test = X_test.reshape(-1, 28, 28, 1).astype('float64') / 255
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)
print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)

load_mnist_model = False
save_model = True

filepath = './model_mnist/'  # change to directory where model is saved
if load_mnist_model:
    model = tf.keras.models.load_model(os.path.join(filepath, 'model.h5'))
else:
    # define model
    inputs = Input(shape=(X_train.shape[1:]), dtype=tf.float64)
    x = Conv2D(64, 2, padding='same', activation='relu')(inputs)
    x = MaxPooling2D(pool_size=2)(x)
    x = Dropout(.3)(x)

    x = Conv2D(32, 2, padding='same', activation='relu')(x)
    x = MaxPooling2D(pool_size=2)(x)
    x = Dropout(.3)(x)

    x = Flatten()(x)
    x = Dense(256, activation='relu')(x)
    x = Dropout(.5)(x)
    logits = Dense(10, name='logits')(x)
    outputs = Activation('softmax', name='softmax')(logits)
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])

    # train model
    model.fit(X_train,
              y_train,
              epochs=6,
              batch_size=256,
              verbose=1,
              validation_data=(X_test, y_test)
              )
    if save_model:
        if not os.path.exists(filepath):
            os.makedirs(filepath)
        model.save(os.path.join(filepath, 'model.h5'))

```

为了生成积分梯度，目标变量指定了使用积分方法计算属性时应考虑哪一类输出。

```py
import tensorflow as tf
from alibi.explainers import IntegratedGradients

model = tf.keras.models.load_model(os.path.join(filepath, 'model.h5'))

ig  = IntegratedGradients(model,
                          layer=None,
                          method="gausslegendre",
                          n_steps=50,
                          internal_batch_size=100)

```

从`alibi.explainers`导入集成的梯度模块，加载预训练的 TensorFlow 或 Keras 模型，然后生成梯度。基于图像分类的复杂性，有五种不同的积分近似方法。没有直接的规则或方法来知道哪些方法何时起作用，因此您需要以迭代的方式尝试所有的方法。

```py
# Initialize IntegratedGradients instance
n_steps = 50
method = "gausslegendre"
ig  = IntegratedGradients(model,
                          n_steps=n_steps,
                          method=method)

```

您可以增加的步数取决于机器的计算能力和文件夹中用于训练模型的样本数量。

```py
# Calculate attributions for the first 10 images in the test set
nb_samples = 10
X_test_sample = X_test[:nb_samples]
predictions = model(X_test_sample).numpy().argmax(axis=1)
explanation = ig.explain(X_test_sample,
                         baselines=None,
                         target=predictions)

```

为了计算测试集中前 10 个图像的属性，您可以选择目标作为预测，基线作为无。如果您选择基线为无，它将触发黑色作为基线，这是图像的背景色。

```py
# Metadata from the explanation object
explanation.meta

# Data fields from the explanation object
explanation.data.keys()

# Get attributions values from the explanation object
attrs = explanation.attributions[0]

```

一旦你得到了属性，你就可以用图形的形式显示目标类的积极属性和消极属性。

```py
fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(10, 7))
image_ids = [0, 1, 9]
cmap_bound = np.abs(attrs[[0, 1, 9]]).max()

for row, image_id in enumerate(image_ids):
    # original images
    ax[row, 0].imshow(X_test[image_id].squeeze(), cmap='gray')
    ax[row, 0].set_title(f'Prediction: {predictions[image_id]}')

    # attributions
    attr = attrs[image_id]
    im = ax[row, 1].imshow(attr.squeeze(), vmin=-cmap_bound, vmax=cmap_bound, cmap='PiYG')

    # positive attributions
    attr_pos = attr.clip(0, 1)
    im_pos = ax[row, 2].imshow(attr_pos.squeeze(), vmin=-cmap_bound, vmax=cmap_bound, cmap='PiYG')

    # negative attributions
    attr_neg = attr.clip(-1, 0)
    im_neg = ax[row, 3].imshow(attr_neg.squeeze(), vmin=-cmap_bound, vmax=cmap_bound, cmap='PiYG')

ax[0, 1].set_title('Attributions');
ax[0, 2].set_title('Positive attributions');
ax[0, 3].set_title('Negative attributions');

for ax in fig.axes:
    ax.axis('off')

fig.colorbar(im, cax=fig.add_axes([0.95, 0.25, 0.03, 0.5]));

```

![../images/506619_1_En_14_Chapter/506619_1_En_14_Fig1_HTML.png](../images/506619_1_En_14_Chapter/506619_1_En_14_Fig1_HTML.png)

图 14-1

由综合梯度产生的属性

在图 [14-1](#Fig1) 中，预测位数为 7、2、9。积极的归因大多与最终预测相匹配，而消极的归因相当少。

## 结论

图像属性对于解释某种图像分类的原因是很重要的。可以使用主导像素方法或识别图像的受影响像素来创建图像属性。这在某些行业可能是有用的。在制造业中，它可用于从产品图像中识别有缺陷的产品。在医疗保健中，它可以对各种扫描进行分类，并识别扫描中的异常。在所有领域中，解释为什么模型对一个类进行了分类是很重要的。只要你能够解释这些预测，你就能更好地获得用户对模型的信任，从而增加人工智能模型在行业中的应用，以解决复杂的商业问题。