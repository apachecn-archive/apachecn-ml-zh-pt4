# 8.使用假设情景的人工智能公平模型

本章解释了如何使用假设工具(WIT)来解释人工智能模型中的偏差，如基于机器学习的回归模型、分类模型和多类分类模型。作为一名数据科学家，你不仅要负责开发一个机器学习模型，还要负责确保模型没有偏差，新的观察结果得到公平对待。当务之急是探索决策和验证算法的公平性。谷歌开发了假设工具(WIT)来解决机器学习模型中的模型公平性问题。您将看到 WIT 在三种可能的 ML 模型中的实现:基于回归的任务的 ML、二进制分类模型的 ML 和多名词模型的 ML。

## 机智是什么？

假设工具(What-If Tool，WIT)是谷歌在 2019 年发布的一款开源工具，用于探索机器学习模型。它是为了理解驱动因素和结果变量之间的因果关系以及数据点和结果变量的变化而开发的。这里的驱动因素意味着结果变量的独立预测因素。由于其易用性、吸引人的可视化和可解释性，WIT 工具被广泛接受和采用。通过最少的编码，用户可以直观地探索任何机器学习模型的学习行为。对经过训练的机器学习模型的各种输入进行模拟对于开发可解释的人工智能和负责任的人工智能是必要的。这个 WIT 工具有三种格式:来自 Anaconda Navigator window 的常规 Jupyter 笔记本，Google Colab 笔记本，以及用于任何基于深度学习的模型的基于 TensorBoard 的可视化。该工具的当前可用版本是 1.8.0，该版本克服了早期版本的某些限制。流程见图 [8-1](#Fig1) 。

![../images/506619_1_En_8_Chapter/506619_1_En_8_Fig1_HTML.jpg](../images/506619_1_En_8_Chapter/506619_1_En_8_Fig1_HTML.jpg)

图 8-1

偏差识别流程图

根据您的问题，训练数据可以基于某些受保护的属性进行划分。举个例子，假设你有种族和性别两个属性，你想从一个可解释的角度得到一个答案，比如

*   模型是否偏向某个特定种族？

*   模型是否偏向某一特定性别，假设男性和女性？

我们来看第二点，性别作为保护变量。第一性别有特权，第二性别无特权。您可以准备两个定型模型，并使用这两个模型为定型数据生成预测。如果对于任何特定记录，两个模型的预测都匹配，则该记录或数据点是无偏的；如果它不同，那么它就是有偏见的。基于此，你就可以断定这个模型是偏向于某个性别还是种族。

## 安装 WIT

以下是安装假设分析工具的代码:

```py
import pandas as pd
import warnings
warnings.filterwarnings("ignore")

!pip install witwidget

from witwidget.notebook.visualization import WitConfigBuilder
from witwidget.notebook.visualization import WitWidget

```

在从笔记本环境运行`WitWidget()`功能之前，请从命令行运行以下两行:

```py
jupyter nbextension install --py --symlink --sys-prefix witwidget
jupyter nbextension enable --py --sys-prefix witwidget

```

安装完成后，需要创建以下函数来为模型创建和可视化准备输入数据。以下脚本基于 TensorFlow 规范创建要素规范，因为 WIT 工具依赖 TensorFlow 后端来格式化输入数据:

```py
!pip install xgboost

# if you get error in xgboost
# run

conda install -c conda-forge xgboost

import pandas as pd
import xgboost as xgb
import numpy as np
import collections
import witwidget

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.utils import shuffle
from witwidget.notebook.visualization import WitWidget, WitConfigBuilder

```

您将使用`churn`数据集，因为您在其他章节中使用过它。

```py
df = pd.read_csv('ChurnData.csv')
df.head()

del df['Unnamed: 0']
df.head()

import pandas as pd
import numpy as np
import tensorflow as tf
import functools

 # Creates a tf feature spec from the dataframe and columns specified.
def create_feature_spec(df, columns=None):
    feature_spec = {}
    if columns == None:
        columns = df.columns.values.tolist()
    for f in columns:
        if df[f].dtype is np.dtype(np.int64):
            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.int64)
        elif df[f].dtype is np.dtype(np.float64):
            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.float32)
        else:
            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.string)
    return feature_spec

# Creates simple numeric and categorical feature columns from a feature spec and a
# list of columns from that spec to use.
#
# NOTE: Models might perform better with some feature engineering such as bucketed
# numeric columns and hash-bucket/embedding columns for categorical features.

def create_feature_columns(columns, feature_spec):
    ret = []
    for col in columns:
        if feature_spec[col].dtype is tf.int64 or feature_spec[col].dtype is tf.float32:
            ret.append(tf.feature_column.numeric_column(col))
        else:
            ret.append(tf.feature_column.indicator_column(
                tf.feature_column.categorical_column_with_vocabulary_list(col, list(df[col].unique()))))
    return ret

```

在上面的函数中，给定一个数据集，验证输入数据并格式化整型、浮点型和基于字符串的列。

以下效用函数从基于 TensorFlow 的示例中生成输入，用于模型训练步骤:

```py
# An input function for providing input to a model from tf.Examples
def tfexamples_input_fn(examples, feature_spec, label, mode=tf.estimator.ModeKeys.EVAL,
                       num_epochs=None,
                       batch_size=64):
    def ex_generator():
        for i in range(len(examples)):
            yield examples[i].SerializeToString()
    dataset = tf.data.Dataset.from_generator(
      ex_generator, tf.dtypes.string, tf.TensorShape([]))
    if mode == tf.estimator.ModeKeys.TRAIN:
        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(lambda tf_example: parse_tf_example(tf_example, label, feature_spec))

    dataset = dataset.repeat(num_epochs)
    return dataset

```

以下函数使用功能规范函数定义的功能规范来解析 TensorFlow 示例函数:

```py
 # Parses Tf.Example protos into features for the input function.
def parse_tf_example(example_proto, label, feature_spec):
    parsed_features = tf.io.parse_example(serialized=example_proto, features=feature_spec)
    target = parsed_features.pop(label)
    return parsed_features, target

```

基于张量流的模型需要将输入数据批量输入到训练步骤。

```py
# Converts a dataframe into a list of tf.Example protos.
def df_to_examples(df, columns=None):
    examples = []
    if columns == None:
        columns = df.columns.values.tolist()
    for index, row in df.iterrows():
        example = tf.train.Example()
        for col in columns:
            if df[col].dtype is np.dtype(np.int64):
                example.features.feature[col].int64_list.value.append(int(row[col]))
            elif df[col].dtype is np.dtype(np.float64):
                example.features.feature[col].float_list.value.append(row[col])
            elif row[col] == row[col]:
                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))
        examples.append(example)
    return examples

```

以下函数将用户提供的数据帧转换为一列二进制值(0 和 1)。对于二元分类模型，函数强制标签列为数字。类似地，对于多类分类模型，通过应用标签编码器功能，标签或目标列也变为标签编码器列。

```py
# Converts a dataframe column into a column of 0's and 1's based on the provided test.
# Used to force label columns to be numeric for binary classification using a TF estimator.
def make_label_column_numeric(df, label_column, test):
    df[label_column] = np.where(test(df[label_column]), 1, 0)

```

您在本章中看到的用例是一个电信客户流失分类场景。电信客户的使用历史被考虑在内，例如帐户长度、客户所在地的区号、州代码、是否启用国际计划、语音邮件计划、语音邮件消息的数量、以分钟计的总日间通话时间、总日间通话时间和总日间费用。类似于白天，晚上和夜间的使用细节也被认为是特征。这些特征有助于你预测未来客户流失的可能性。如果你能提前预测正确的结果，那么导致客户流失的因素就能被解决，客户就能被留住。留住一个客户总是比获得一个新客户更好。获取新客户总是成本高昂，而留住现有客户的成本要低得多。因此，在客户流失预测过程中，您可以制定相关策略，通过识别客户流失的原因并提前验证偏差和假设情景来防止客户流失。

```py
import numpy as np

# Set the column in the dataset you wish for the model to predict
label_column = 'churn'

# Make the label column numeric (0 and 1), for use in our model.
# In this case, examples with a target value of 'yes' are considered to be in
# the '1' (positive) class and all other examples are considered to be in the
# '0' (negative) class.
make_label_column_numeric(df, label_column, lambda val: val == 'yes')

# Set list of all columns from the dataset we will use for model input.
input_features = [

  'account_length', 'area_code', 'international_plan',
       'voice_mail_plan', 'number_vmail_messages', 'total_day_minutes',
       'total_day_calls', 'total_day_charge', 'total_eve_minutes',
       'total_eve_calls', 'total_eve_charge', 'total_night_minutes',
       'total_night_calls', 'total_night_charge', 'total_intl_minutes',
       'total_intl_calls', 'total_intl_charge',
       'number_customer_service_calls']

# Create a list containing all input features and the label column
features_and_labels = input_features + [label_column]

features_and_labels

examples = df_to_examples(df)

num_steps = 5000  #@param {type: "number"}

# Create a feature spec for the classifier
feature_spec = create_feature_spec(df, features_and_labels)

# Define and train the classifier
train_inpf = functools.partial(tfexamples_input_fn, examples, feature_spec, label_column)
classifier = tf.estimator.LinearClassifier(
    feature_columns=create_feature_columns(input_features, feature_spec))
classifier.train(train_inpf, steps=num_steps)

test_df = pd.read_csv('churnTest.csv')

num_datapoints = 2000
tool_height_in_px = 700

from witwidget.notebook.visualization import WitConfigBuilder
from witwidget.notebook.visualization import WitWidget

make_label_column_numeric(test_df, label_column, lambda val: val == 'yes')
test_examples = df_to_examples(test_df[0:num_datapoints])

# Setup the tool with the test examples and the trained classifier
config_builder = WitConfigBuilder(test_examples).set_estimator_and_feature_spec(
    classifier, feature_spec).set_label_vocab(['Churn', 'No Churn'])
WitWidget(config_builder, height=tool_height_in_px)

```

测试数据集包含 1667 个样本，您将使用 Google 的假设工具来可视化这些样本。上面的脚本生成了一个带有两个面板的可视化。左侧面板显示了各种选项，如数据点编辑器、性能以及模型和特征的公平性。右侧面板显示可视化和其他选项。

![../images/506619_1_En_8_Chapter/506619_1_En_8_Fig2_HTML.png](../images/506619_1_En_8_Chapter/506619_1_En_8_Fig2_HTML.png)

图 8-2

通过机智探索模范行为

在图 [8-2](#Fig2) 中，左手块有数据点和部分相关性图，它们在数据点编辑器下。第二个选项卡包含性能和公平性选项，第三个选项卡包含功能。在右侧，y 轴显示推理得分，并按推理标签排序。红点是没有流失的客户，蓝点是流失的客户。在这里，标注方式选项是默认选项。

![../images/506619_1_En_8_Chapter/506619_1_En_8_Fig3_HTML.png](../images/506619_1_En_8_Chapter/506619_1_En_8_Fig3_HTML.png)

图 8-3

按预测类型表示流失和非流失

在图 [8-3](#Fig3) 中，蓝色点为无流失案例，红色点为流失案例。从测试数据集来看，如果考虑记录号 1073，流失概率为 0.016%，不流失概率为 98.4%，这是一个很好的预测。但是，当你看示例号 799 时，流失的概率是 49.2%，不流失的概率是 50.8%。这些类型的情况对于模型来说是相当不明确的。你的预测模型不知道如何区分客户流失和非客户流失。默认情况下，WIT 工具使用 0.5 的分类阈值。如果概率阈值超过大于 0.5，则它预测肯定的类别；否则，它预测负类。这里，积极的类别是没有客户流失，消极的类别是客户流失。在面板的右侧，散点图显示推理得分，即概率得分。如果推理得分大于 0.5，那么就是正类；否则就是负类。有一些边界情况，所以需要额外的模型微调。因此，为了获得更好的结果，使用各种超参数对模型进行微调至关重要。见图 [8-4](#Fig4) 。

![../images/506619_1_En_8_Chapter/506619_1_En_8_Fig4_HTML.png](../images/506619_1_En_8_Chapter/506619_1_En_8_Fig4_HTML.png)

图 8-4

数据点 799 分析

左侧面板上的数据点编辑器显示了记录的单个值的查看和编辑，并显示了预测推断的结果。由此可见模型推断的强大，以及对预测结果的详细解释。对于相同的 799 示例号码，当您将帐户长度的单个值更改为 210、总日呼叫数更改为 227 以及某些其他参数，然后单击左侧菜单上的预测按钮时，您可以看到客户流失推断得分从 49.2%下降到 25.8%，而无客户流失的概率从 50.8%上升到 74.2%，这对应于模拟的运行 2。参见图 [8-5](#Fig5) 。

![../images/506619_1_En_8_Chapter/506619_1_En_8_Fig5_HTML.png](../images/506619_1_En_8_Chapter/506619_1_En_8_Fig5_HTML.png)

图 8-5

由于特征值的微小变化而导致的推理得分的变化

您还可以看到单个特性的部分相关性图(PDP)。简而言之，PDP 图显示了一个或两个特征对机器学习模型预测结果的边际贡献。

图 [8-6](#Fig6) 显示了模型预测的流失和未流失案例的分布。通过考虑 X 轴上的推断分数，推断分数小于 10%。所有案例都被预测为流失。这里要注意的一点是，在推理得分为 49%到 59%的情况下，您可以看到客户流失和非客户流失情况的存在，这表明模型缺乏预测能力，因为您的模型没有了解该桶中客户流失和非客户流失类别之间的差异。

![../images/506619_1_En_8_Chapter/506619_1_En_8_Fig6_HTML.png](../images/506619_1_En_8_Chapter/506619_1_En_8_Fig6_HTML.png)

图 8-6

用于流失预测的推理分数桶视图

在图 [8-6](#Fig6) 中，推理分数被分成 10 组，视图显示每个组中存在两个类别。该视图帮助您选择用于分类目标类的阈值。阈值应用于概率值。

图 [8-7](#Fig7) 给出了模型中用作输入变量的所有独立变量的部分相关图。PDP 按变化排序。

![../images/506619_1_En_8_Chapter/506619_1_En_8_Fig7_HTML.png](../images/506619_1_En_8_Chapter/506619_1_En_8_Fig7_HTML.png)

图 8-7

帐户长度的部分相关性图

随着账户长度的增加，推理得分逐渐降低。参见图 [8-8](#Fig8) 。

![../images/506619_1_En_8_Chapter/506619_1_En_8_Fig8_HTML.png](../images/506619_1_En_8_Chapter/506619_1_En_8_Fig8_HTML.png)

图 8-8

区号变量的 PDP

在评估模型的整体性能时，您可以考虑混淆矩阵，它说明了模型中流失和非流失案例之间的匹配和不匹配。

![../images/506619_1_En_8_Chapter/506619_1_En_8_Fig9_HTML.png](../images/506619_1_En_8_Chapter/506619_1_En_8_Fig9_HTML.png)

图 8-9

绩效和公平性屏幕

在图 [8-9](#Fig9) 所示的性能和公平性屏幕中，您可以看到 ROC 曲线、AUC 曲线、混淆矩阵和成本比率。您可以更改阈值概率值来更改分类矩阵。

### 评估指标

精确度:你的模型正确预测阳性标签的频率

回忆:模型正确预测了数据集中的多少个正类？

![../images/506619_1_En_8_Chapter/506619_1_En_8_Fig10_HTML.png](../images/506619_1_En_8_Chapter/506619_1_En_8_Fig10_HTML.png)

图 8-10

显示模型准确性的评估屏幕

## 结论

本章讨论了如何使用假设分析工具解释分类模型结果的推断，以及如何识别在客户流失和非客户流失案例分类中起关键作用的特征。此外，您还使用了对单个数据点进行局部解释的方法。