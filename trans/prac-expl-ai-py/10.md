# 10.XAI 模型的反事实解释

本章解释了如何使用假设工具(WIT)来解释人工智能模型中的反事实定义，如基于机器学习的回归模型、分类模型和多类分类模型。作为一名数据科学家，你不只是开发一个机器学习模型；你要确保你的模型是没有偏见的，并且它对新的观察所做的决定是公平的，这些观察是对未来的预测。探测决策和验证算法的公平性是非常重要的。谷歌开发了假设工具来解决机器学习模型中的模型公平性问题。您将看到 WIT 在三个 ML 模型中的实现:ML 用于基于回归的任务，ML 用于二项式分类模型，ML 用于多名词模型。

## 什么是 cfe？

反事实解释是 ML 模型预测过程中的因果关系。我将用一个例子来说明预测或分类。反事实解释是一种创造假设情景并在这些假设情景下产生预测的方法。这对于业务用户、非数据科学家以及没有预测建模背景的普通人来说是可以理解的。有时我们发现输入和输出之间的关系不是因果关系，但我们仍然希望建立因果关系来生成预测。反事实解释是对预测的局部解释，这意味着对于个别预测，它们会产生相关的解释。

## 《欧洲常规武装力量条约》的实施

回归和分类任务都可以产生反事实的解释。您将使用基于 Python 的库 Alibi。Alibi 适用于 Python 版本 3.6 及更高版本。以下命令可用于安装:

```
!pip install alibi
!pip install alibi[ray]
import alibi
alibi.__version__

```

安装后，请使用下面几行代码检查版本，以确保安装完成:`alibi.__version__`

## CFEs 使用不在场证明

模型预测的反事实解释可以使用 Alibi 生成。安装后，您可以使用 Alibi 函数遵循类似的初始化、拟合和预测过程。Alibi 库需要一个经过训练的模型和一个需要生成预测的新数据集。例如，您可以使用极端梯度增强模型来获得经过训练的模型对象，该对象可以进一步与 Alibi 库一起使用来生成反事实解释。以下脚本安装 xgboost 模型和 witwidget 库。如果 xgboost 模型显示错误，下面给出的 conda 命令可以用来安装基于 Python 的 xgboost 库。

```
import pandas as pd
!pip install xgboost

import pandas as pd
import xgboost as xgb
import numpy as np
import collections
import witwidget

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.utils import shuffle
from witwidget.notebook.visualization import WitWidget, WitConfigBuilder

# if you get error in xgboost
# run
# conda install -c conda-forge xgboost

data = pd.read_csv('diabetes.csv')
data.head()
data.columns

from sklearn.model_selection import train_test_split

```

您正在使用`diabetes.csv`数据集。使用表 [10-1](#Tab1) 中显示的特征，你必须预测某人是否会有糖尿病。特性如表 [10-1](#Tab1) 所示。

表 10-1

特征的数据字典

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

功能名称

 | 

描述

 |
| --- | --- |
| **怀孕** | 怀孕次数 |
| **葡萄糖** | 血糖水平 |
| **血压** | 舒张压水平 |
| **皮肤厚度** | 以毫米为单位测量的表皮厚度 |
| **胰岛素** | 施用的胰岛素剂量 |
| **身体质量指数** | 受试者的体重指数 |
| **糖尿病谱系** | 受试者的糖尿病谱系功能 |
| **年龄** | 受试者年龄 |
| **结果** | 无糖尿病，1-糖尿病 |

```
# Split the data into train / test sets
y = data['Outcome']

x = data[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]
x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1234)

```

总数据被分成训练和测试对象`x_train`和`y_train`，以开发训练的模型对象。在以下脚本中，您将使用极端梯度增强分类器通过逻辑回归模型进行训练。极端梯度增强分类器有许多超参数，但您将继续使用超参数的默认选择。超参数是帮助微调模型以获得模型的最佳版本的参数。

```
# Train the model, this will take a few minutes to run
bst = xgb.XGBClassifier(
    objective='reg:logistic'
)

bst.fit(x_train, y_train)
# Get predictions on the test set and print the accuracy score
y_pred = bst.predict(x_test)
acc = accuracy_score(np.array(y_test), y_pred)
print(acc, '\n')

# Print a confusion matrix
print('Confusion matrix:')
cm = confusion_matrix(y_test, y_pred)
print(cm)

```

被训练的模型对象被存储为`bst`。使用相同的对象，您可以为模型生成精度。基本准确率为 72.9%。

最佳模型精确度为 72.9%，您可以存储或保存最佳模型，并将其上传到 Alibi 以生成预测，并将其用于填充反事实解释。

```
# Save the model so we can deploy it
bst.save_model('model.bst')
bst
x_train.head()
bst.predict(x_train.head())
y_train.head()
x_train.iloc[3] = x_train.iloc[1]
x_train.head()
bst.predict(x_train.head())

```

对于记录号为 8 的人，模型预测为糖尿病，而实际也是糖尿病。从第 651 号`y_train`记录可以看出，第 651 行(训练数据集中的第三条记录)没有糖尿病。

如果稍微改变第 651 行的值，该记录的预测也会改变(表 [10-2](#Tab2) )。在下面的脚本中，您进行了更改。

表 10-2

特征值的变化会影响预测

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

功能名称

 | 

旧值 651

 | 

新值 651

 |
| --- | --- | --- |
| **怀孕** | one | five |
| **葡萄糖** | One hundred and seventeen | Ninety-seven |
| **血压** | Sixty | Seventy-six |
| **皮肤厚度** | Twenty-three | Twenty-seven |
| **胰岛素** | One hundred and six | Zero |
| **身体质量指数** | Thirty-three point eight | Thirty-five point six |
| **糖尿病谱系** | Zero point four four six | Zero point three seven eight |
| **年龄** | Twenty-seven | fifty-two |

以下脚本显示了特征在预测一个人的糖尿病中的重要性。葡萄糖水平被认为是最重要的特征，其次是身体质量指数水平、年龄和胰岛素水平。

```
bst.predict(x_train.head())
x_train.iloc[3] = [1, 117, 60, 23, 106, 33.8, 0.466, 27]
x_train.head()

result = pd.DataFrame()
result['features_importance'] = bst.feature_importances_
result['feature_names'] = x_train.columns
result.sort_values(by=['features_importance'],ascending=False)

```

您可以对特征值进行小的更改，并观察结果变量的变化。随着小的变化，预测没有改变。

```
# we will make small changes to the values
x_train.iloc[2] = [2, 146, 70, 38, 360, 28.0, 0.337, 29]
x_train.iloc[2]
x_train.columns

bst.predict(x_train.head())
y_train.head()
# if we change the important features such as Glucose and Age

x_train.iloc[2] = [3, 117, 76, 36, 245, 31.6, 0.851, 27]
x_train.iloc[2]
x_train.columns

bst.predict(x_train.head())
y_train.head()

```

随着输入特征值的另一轮改变，糖尿病类别的预测没有改变。随着您不断地更改特征值，您会发现一个地方，在这个地方，一个特征值的微小变化可能会导致类预测的变化。手动重复所有这些场景既麻烦又困难。即使最重要的特征值发生变化，也不会对目标类预测产生影响。因此，有必要通过某种框架来确定这种边缘情况。这个框架是由 Alibi 提供的。

```
# if we change the important features such as Glucose, BMI and Age

x_train.iloc[2] = [3, 117, 76, 36, 245, 30.6, 0.851, 29]
x_train.iloc[2]
x_train.columns

bst.predict(x_train.head())

y_train.head()

import tensorflow as tf
tf.get_logger().setLevel(40) # suppress deprecation messages
tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.utils import to_categorical
import matplotlib
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import os
from alibi.explainers import CounterFactualProto

print('TF version: ', tf.__version__)
print('Eager execution enabled: ', tf.executing_eagerly()) # False

```

可以使用带有 TensorFlow 的 Keras 层作为后端来训练神经网络模型对象。Alibi 提供了 explainers 类，它有一个生成反事实原型结果的模块。以下脚本将神经网络模型类创建为用户定义的函数。此`nn_model()`功能接受输入并应用一个整流线性单元激活功能。然后，它创建另一个具有 40 个神经元的隐藏层，应用相同的激活函数，并使用随机梯度下降作为优化器，使用损失函数作为分类交叉熵。

```
x_train.shape, y_train.shape, x_test.shape, y_test.shape
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

np.random.seed(42)
tf.random.set_seed(42)

def nn_model():
    x_in = Input(shape=(8,))
    x = Dense(40, activation='relu')(x_in)
    x = Dense(40, activation='relu')(x)
    x_out = Dense(2, activation='softmax')(x)
    nn = Model(inputs=x_in, outputs=x_out)
    nn.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
    return nn

```

以下脚本显示了神经网络模型摘要。模型训练使用 64 和 500 个时期的批量大小。在模型训练之后，模型被保存为 h5 格式。h5 格式是一种可移植的模型对象，用于将模型从一个平台加载和转移到另一个平台。

```
nn = nn_model()
nn.summary()
nn.fit(x_train, y_train, batch_size=64, epochs=500, verbose=0)
nn.save('nn_diabetes.h5', save_format='h5')

```

以下脚本加载已定型的模型对象，使用测试数据集，并产生 71.8%的测试准确度:

```
nn = load_model('nn_diabetes.h5')
score = nn.evaluate(x_test, y_test, verbose=0)
print('Test accuracy: ', score[1])

```

反事实的生成是由最近的类原型引导的。您从包含八个特征的测试集中选取一行，并以反事实原型生成函数可接受的方式进行整形。

```
#Generate counterfactual guided by the nearest class prototype
X = np.array(x_test)[1].reshape((1,) + np.array(x_test)[1].shape)
shape = X.shape
shape

```

以下脚本采用神经网络模型对象。使用 lambda 函数，您可以创建一个预测函数。然后你使用反事实原型函数(表 [10-3](#Tab3) )。

表 10-3

反事实原型超参数

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

因素

 | 

说明

 |
| --- | --- |
| `predict_fn` | Keras 或 TensorFlow 模型或任何其他模型的预测函数返回类别概率 |
| `Shape` | 从批次大小开始的输入数据的形状 |
| `use_kdtree` | 如果没有编码器可用，是否对原型损失项使用 k-d 树 |
| `Theta` | 原型搜索损失项的常数 |
| `max_iterations` | 寻找反事实的最大迭代次数 |
| `feature_range` | 允许扰动实例的具有最小和最大范围的元组 |
| `c_init, c_steps` | 用于缩放攻击损失项的初始值，用于调整攻击损失项的常数缩放的迭代次数 |

```
# define model
nn = load_model('nn_diabetes.h5')

predict_fn = lambda x: nn.predict(x)

# initialize explainer, fit and generate counterfactual
cf = CounterFactualProto(predict_fn, shape, use_kdtree=False, theta=10., max_iterations=1000,
                         feature_range=(np.array(x_train).min(axis=0), np.array(x_train).max(axis=0)),
                         c_init=1., c_steps=10)
cf.fit(x_train)

```

上述结果是在反事实拟合过程中或在训练过程中产生的。以下脚本显示了所有要素中可能的最低特征值:

```
x_train.min(axis=0)

```

`explain`方法获取输入数据并生成表 [10-4](#Tab4) 所示的反事实解释。`explain`方法还产生以下本地解释输出:

表 10-4

反事实的解释

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

输出

 | 

解释

 |
| --- | --- |
| `Cf.X` | 反事实的例子 |
| `Cf.class` | 反事实的预测类 |
| `Cf.proba` | 反事实的预测类别概率 |
| `Cf. grads_graph` | 根据 TF 图计算出的相对于反事实输入要素的梯度值 |
| `Cf. grads_num` | 反事实处输入要素的数值梯度值 |
| `orig_class` | 原始实例的预测类 |
| `orig_proba` | 原始实例的预测类概率 |
| `All` | 以迭代为关键字的字典，对于每次迭代，以在该迭代中找到的反事实为值的列表 |

```
explanation = cf.explain(X)
print(explanation)

```

```
print(f'Original prediction: {explanation.orig_class}')
print('Counterfactual prediction: {}'.format(explanation.cf['class']))

Original prediction: 0
Counterfactual prediction: 1

```

在上面的脚本中，all key 提供了寻找反事实值的迭代结果。在第三次迭代中，你得到了反事实的值。其余的九次迭代结果没有反事实值。最初的预测是没有糖尿病，而基于反事实信息的预测是糖尿病。

```
explanation = cf.explain(X)
explanation.all
explanation.cf

{'X': array([[2.5628092e+00, 1.7726180e+02, 7.6516624e+01, 2.4388657e+01,
         7.2130630e+01, 2.6932917e+01, 7.8000002e-02, 2.2944651e+01]],
       dtype=float32),
 'class': 1,
 'proba': array([[0.4956944, 0.5043056]], dtype=float32),
 'grads_graph': array([[ -0.7179985 ,  -5.005951  ,  23.374054  ,  -0.96334076,
           3.8287811 , -13.371899  ,  -0.38599998,  -5.9150696 ]],
       dtype=float32),
 'grads_num': array([[  18.74566078,   38.92183304, -117.42114276,   24.19948392, -35.82239151,   62.04843149,   93.54948252,   25.92801861]])}

explanation.orig_class
explanation.orig_proba
X

```

## 回归任务的反事实

在回归场景中，可以通过使用波士顿房价数据集查看神经网络模型来查看反事实解释。当目标列是连续变量时，回归是一项任务，您可以混合使用变量，如连续变量和分类变量。波士顿房价数据集是学习回归的常用数据集，所以我选择它来展示反事实，因为用户更熟悉这个数据集。

```
import tensorflow as tf
tf.get_logger().setLevel(40) # suppress deprecation messages
tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.utils import to_categorical
import matplotlib
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import os
from sklearn.datasets import load_boston
from alibi.explainers import CounterFactualProto

print('TF version: ', tf.__version__)
print('Eager execution enabled: ', tf.executing_eagerly()) # False

boston = load_boston()
data = boston.data
target = boston.target
feature_names = boston.feature_names

y = np.zeros((target.shape[0],))
y[np.where(target > np.median(target))[0]] = 1

data = np.delete(data, 3, 1)
feature_names = np.delete(feature_names, 3)

mu = data.mean(axis=0)
sigma = data.std(axis=0)
data = (data - mu) / sigma

idx = 475
x_train,y_train = data[:idx,:], y[:idx]
x_test, y_test = data[idx:,:], y[idx:]
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

np.random.seed(42)
tf.random.set_seed(42)

def nn_model():
    x_in = Input(shape=(12,))
    x = Dense(40, activation='relu')(x_in)
    x = Dense(40, activation='relu')(x)
    x_out = Dense(2, activation='softmax')(x)
    nn = Model(inputs=x_in, outputs=x_out)
    nn.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
    return nn

```

上面的脚本是用于回归的神经网络模型。下面的脚本是神经网络架构总结:

```
nn = nn_model()
nn.summary()
nn.fit(x_train, y_train, batch_size=64, epochs=500, verbose=0)
nn.save('nn_boston.h5', save_format='h5')

```

保存训练好的模型对象`nn_boston.h5`以生成反事实。

```
nn = load_model('nn_boston.h5')
score = nn.evaluate(x_test, y_test, verbose=0)
print('Test accuracy: ', score[1])

X = x_test[1].reshape((1,) + x_test[1].shape)
shape = X.shape

# define model
nn = load_model('nn_boston.h5')

# initialize explainer, fit and generate counterfactual
cf = CounterFactualProto(nn, shape, use_kdtree=True, theta=10., max_iterations=1000,
                         feature_range=(x_train.min(axis=0), x_train.max(axis=0)),
                         c_init=1., c_steps=10)

cf.fit(x_train)
explanation = cf.explain(X)

```

从反事实得出的结果可以解释为表 [10-4](#Tab4) 中的解释。1940 年以前建造的自有住房占 93.6%，较低人口占 18.68%。为了提高房价，1940 年以前建造的自住单位的比例应减少 5.95%，人口的较低地位应减少 4.85%。

```
print(f'Original prediction: {explanation.orig_class}')
print('Counterfactual prediction: {}'.format(explanation.cf['class']))
Original prediction: 0
Counterfactual prediction: 1

orig = X * sigma + mu
counterfactual = explanation.cf['X'] * sigma + mu
delta = counterfactual - orig
for i, f in enumerate(feature_names):
    if np.abs(delta[0][i]) > 1e-4:
        print('{}: {}'.format(f, delta[0][i]))

print('% owner-occupied units built prior to 1940: {}'.format(orig[0][5]))
print('% lower status of the population: {}'.format(orig[0][11]))
% owner-occupied units built prior to 1940: 93.6
% lower status of the population: 18.68

```

## 结论

在这一章中，你探索了回归相关问题和分类相关问题的反事实解释。反事实的目的是在训练数据中找到相似的数据点，该数据点产生与标记类不同的预测。反事实解释中的推理是，如果两个数据点非常相似，那么两者应该有相似的预测或相似的结果。目标类中不应该有不同的输出。在糖尿病预测用例中，如果两个人有相似的特征，那么他们要么都没有糖尿病，要么都有糖尿病。不应该出现一个有糖尿病，一个没有糖尿病的情况。不同的反事实信息的存在实际上从最终用户的角度来看造成了混乱，这将导致对人工智能模型缺乏信任。为了在人工智能模型中建立信任，产生反事实的解释是很重要的。